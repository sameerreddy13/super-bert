{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f9f6d8b",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2987ced5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilee300/workspace/nlp_ofa/transformers/src/transformers/models/bert/modeling_bert.py:874: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(self.encoder != None, \"the encoder cannot be None\")\n",
      "/home/ilee300/workspace/nlp_ofa/transformers/src/transformers/models/bert/modeling_bert.py:877: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(self.encoder.config.num_hidden_layers >= max_encoder_num, \"the max encoder number should not exceed defined hidden layer\")\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "# Preliminaries\n",
    "\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "\n",
    "# Models\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Training\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea50da",
   "metadata": {},
   "source": [
    "### Check available GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b472598d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug  5 17:14:42 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  On   | 00000000:1B:00.0 Off |                  N/A |\r\n",
      "| 34%   55C    P2   157W / 250W |   1579MiB / 11019MiB |     51%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 208...  On   | 00000000:1C:00.0 Off |                  N/A |\r\n",
      "| 24%   22C    P8    16W / 250W |     12MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  GeForce RTX 208...  On   | 00000000:1D:00.0 Off |                  N/A |\r\n",
      "| 23%   21C    P8     2W / 250W |     12MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  GeForce RTX 208...  On   | 00000000:1E:00.0 Off |                  N/A |\r\n",
      "| 29%   23C    P8    18W / 250W |     12MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   4  GeForce RTX 208...  On   | 00000000:B2:00.0 Off |                  N/A |\r\n",
      "| 24%   22C    P8    16W / 250W |     12MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   5  GeForce RTX 208...  On   | 00000000:B3:00.0 Off |                  N/A |\r\n",
      "| 31%   49C    P2   119W / 250W |   1579MiB / 11019MiB |     45%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   6  GeForce RTX 208...  On   | 00000000:B4:00.0 Off |                  N/A |\r\n",
      "| 30%   47C    P2   113W / 250W |   1573MiB / 11019MiB |     45%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   7  GeForce RTX 208...  On   | 00000000:B5:00.0 Off |                  N/A |\r\n",
      "| 24%   21C    P8    20W / 250W |     12MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     23797      C   python                                      1567MiB |\r\n",
      "|    5     23879      C   python                                      1567MiB |\r\n",
      "|    6     28935      C   python                                      1561MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2655408c",
   "metadata": {},
   "source": [
    "### Select device for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b8274d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b741b5b",
   "metadata": {},
   "source": [
    "### set source and destination folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23435f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = os.getcwd()\n",
    "\n",
    "source_folder = os.path.join(dirname,'../data/imdb')\n",
    "destination_folder =os.path.join(dirname,'../model/progressive_shrinking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aafa0a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ilee300/workspace/nlp_ofa/transformers/notebooks/../data/imdb\n",
      "/home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking\n"
     ]
    }
   ],
   "source": [
    "## check source and desitnation folder\n",
    "print(source_folder)\n",
    "print(destination_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77b0a31",
   "metadata": {},
   "source": [
    "## Prepare data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9daeb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f60f1547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Model parameter\n",
    "MAX_SEQ_LEN = 128\n",
    "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
    "\n",
    "# Fields\n",
    "\n",
    "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
    "text_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True,\n",
    "                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n",
    "# fields = [('label', label_field), ('title', text_field), ('text', text_field), ('titletext', text_field)]\n",
    "fields = [('text', text_field),('sentiment', label_field)]\n",
    "\n",
    "# TabularDataset\n",
    "\n",
    "train, valid, test = TabularDataset.splits(path=source_folder, train='train.csv', validation='valid.csv',\n",
    "                                           test='test.csv', format='CSV', fields=fields, skip_header=True)\n",
    "\n",
    "# Iterators\n",
    "\n",
    "train_iter = BucketIterator(train, batch_size=16, sort_key=lambda x: len(x.text),\n",
    "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
    "valid_iter = BucketIterator(valid, batch_size=16, sort_key=lambda x: len(x.text),\n",
    "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
    "test_iter = Iterator(test, batch_size=16, device=device, train=False, shuffle=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf5e4e4",
   "metadata": {},
   "source": [
    "## Define Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57aa536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "\n",
    "        options_name = \"bert-base-uncased\"\n",
    "        self.encoder = BertForSequenceClassification.from_pretrained(options_name)\n",
    "\n",
    "    def forward(self, text, label):\n",
    "        loss, text_fea = self.encoder(text, labels=label)[:2]\n",
    "\n",
    "        return loss, text_fea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe54268a",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92d40cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_checkpoint(save_path, model, valid_loss):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_checkpoint(load_path, model):\n",
    "    \n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_metrics(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']\n",
    "\n",
    "def save_accuracy_log(save_path, train_accuracy_list, valid_accuracy_list, global_steps_list):\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_accuracy_list': train_accuracy_list,\n",
    "                  'valid_accuracy_list': valid_accuracy_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Accuracy log saved to ==> {save_path}')\n",
    "    \n",
    "def load_accuracy_log(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Accuracy log loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_accuracy_list'], state_dict['valid_accuracy_list'], state_dict['global_steps_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2cba7c",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b01b9ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "\n",
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.BCELoss(),\n",
    "          train_loader = train_iter,\n",
    "          valid_loader = valid_iter,\n",
    "          num_epochs = 5,\n",
    "          eval_every = len(train_iter) // 2,\n",
    "          file_path = destination_folder,\n",
    "          best_valid_loss = float(\"Inf\"),\n",
    "         max_encoder_num = None,\n",
    "         num_subnets = 2,\n",
    "         sandwich=False):\n",
    "    if sandwich:\n",
    "        print(\"Sandwich training is on\")\n",
    "    print(\"a total of \", num_subnets, \"subnets would be used for training\")\n",
    "\n",
    "    \n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    \n",
    "    val_acc = 0.0\n",
    "    train_acc = 0.0\n",
    "    valid_accuracy_list = []\n",
    "    train_accuracy_list = []\n",
    "    val_y_pred = []\n",
    "    val_y_true = []\n",
    "    train_y_pred = []\n",
    "    train_y_true = []\n",
    "    \n",
    "    \n",
    "    if max_encoder_num is None:\n",
    "        max_encoder_num = model.encoder.config.num_hidden_layers\n",
    "        print(\"because max_encoder_num is none, it is set to\", max_encoder_num) \n",
    "#     model.encoder.set_max_encoder_num(max_encoder_num)\n",
    "#     print(\"training the model with encoder number of \" , max_encoder_num)\n",
    "\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    \n",
    "    ##TODO\n",
    "    change_subnet_every = len(train_iter) // num_subnets\n",
    "   \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        ##Set the list of subnets to train\n",
    "        subnet_depth_list = []\n",
    "        subnet_counter = 0\n",
    "        if sandwich:\n",
    "            subnet_depth_list = [model.encoder.config.num_hidden_layers, max_encoder_num]\n",
    "        subnet_depth_list.extend(random.choices(list(range(max_encoder_num, model.encoder.config.num_hidden_layers+1)), k=(num_subnets - len(subnet_depth_list))))\n",
    "        random.shuffle(subnet_depth_list)\n",
    "        print(\"subnet depths for training in epoch\", epoch, \" : \", subnet_depth_list)\n",
    "        \n",
    "        \n",
    "        for (text,sentiment), _ in train_loader:\n",
    "            if global_step % change_subnet_every == 0 and subnet_counter < num_subnets:\n",
    "                print(\"at global step of \", global_step, \" switching the subnet depth\")\n",
    "                model.encoder.set_max_encoder_num(subnet_depth_list[subnet_counter])\n",
    "                print(\"training the model with encoder number of \" , subnet_depth_list[subnet_counter])\n",
    "                subnet_counter+=1\n",
    "                \n",
    "            \n",
    "            text = text.type(torch.LongTensor)           \n",
    "            text = text.to(device)\n",
    "            sentiment = sentiment.type(torch.LongTensor)  \n",
    "            sentiment = sentiment.to(device)\n",
    "            output = model(text, sentiment)\n",
    "            loss, output = output\n",
    "            \n",
    "            ##update the prediction and true list.\n",
    "            train_y_pred.extend(torch.argmax(output, 1).tolist())\n",
    "            train_y_true.extend(sentiment.tolist())\n",
    "            train_acc +=accuracy_score(train_y_pred,train_y_true)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            \n",
    "            # update running values\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "                    \n",
    "            \n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_every == 0:\n",
    "                ##run validation on the smallest and the largest\n",
    "                \n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "\n",
    "                    ## Change the number of encoder layers to max\n",
    "                    model.encoder.set_max_encoder_num(model.encoder.config.num_hidden_layers)\n",
    "                    \n",
    "                    # Evaluation done on the largest subnet only while training.\n",
    "                    # validation loop\n",
    "                    for (text,sentiment), _ in valid_loader:\n",
    "                        text = text.type(torch.LongTensor)           \n",
    "                        text = text.to(device)\n",
    "                        sentiment = sentiment.type(torch.LongTensor)  \n",
    "                        sentiment = sentiment.to(device)\n",
    "                        output = model(text, sentiment)\n",
    "                        loss, output = output\n",
    "                        \n",
    "                        valid_running_loss += loss.item()\n",
    "                        \n",
    "                        ##update the prediction and true list.\n",
    "                        val_y_pred.extend(torch.argmax(output, 1).tolist())\n",
    "                        val_y_true.extend(sentiment.tolist())\n",
    "                        val_acc += accuracy_score(val_y_pred,val_y_true)\n",
    "\n",
    "                    # changethe number of encoder layers back \n",
    "                    model.encoder.set_max_encoder_num(subnet_depth_list[subnet_counter-1])\n",
    "\n",
    "                    \n",
    "                # evaluation\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "                \n",
    "                average_train_accuracy = train_acc / eval_every\n",
    "                average_valid_accuracy = val_acc / eval_every\n",
    "                train_accuracy_list.append(average_train_accuracy)\n",
    "                valid_accuracy_list.append(average_valid_accuracy)\n",
    "                \n",
    "\n",
    "                # resetting running values\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                train_acc = 0.0\n",
    "                val_acc = 0.0\n",
    "                model.train()\n",
    "\n",
    "                # print progress\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                # checkpoint\n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint(file_path + '/' +str(max_encoder_num)+ 'model.pt', model, best_valid_loss)\n",
    "                    save_metrics(file_path + '/' + str(max_encoder_num)+ 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "\n",
    "\n",
    "                \n",
    "    save_metrics(file_path + '/' +str(max_encoder_num)+ 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    save_accuracy_log(file_path + '/' +str(max_encoder_num)+ 'acc_log.pt', train_accuracy_list, valid_accuracy_list, global_steps_list)\n",
    "\n",
    "    print('Finished Training!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca59b8",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68ac6f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "\n",
    "def evaluate(model, test_loader,max_encoder_num=None ):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    if max_encoder_num:\n",
    "        model.encoder.set_max_encoder_num(max_encoder_num)\n",
    "    else:\n",
    "        max_encoder_num = model.encoder.config.num_hidden_layers\n",
    "        model.encoder.set_max_encoder_num(model.encoder.config.num_hidden_layers)\n",
    "    \n",
    "    print(\"evaluating with max encoder number of \", max_encoder_num)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (text,sentiment), _ in test_loader:\n",
    "                text = text.type(torch.LongTensor)           \n",
    "                text = text.to(device)\n",
    "                sentiment = sentiment.type(torch.LongTensor)  \n",
    "                sentiment = sentiment.to(device)\n",
    "                output = model(text, sentiment)\n",
    "\n",
    "                _, output = output\n",
    "                y_pred.extend(torch.argmax(output, 1).tolist())\n",
    "                y_true.extend(sentiment.tolist())\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['NEG', 'POS'])\n",
    "    ax.yaxis.set_ticklabels(['NEG', 'POS'])\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    return accuracy_score(y_pred,y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd038d08",
   "metadata": {},
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81209a22",
   "metadata": {},
   "source": [
    "### Train without sandwich\n",
    "- Train each stage of shrinking for 1 epoch.\n",
    "- evaluate the accuracy for all layers after each stage of training. Get the accuracy using the last model as well as the model with the highest largest supernet accuracy\n",
    "- varying number of subnets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361d0799",
   "metadata": {},
   "source": [
    "#### Train using 4 subnets per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9755e8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = BERT().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b714b7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing encoder number :  12  =>  12\n"
     ]
    }
   ],
   "source": [
    "# check if the encoder setting works\n",
    "model.encoder.set_max_encoder_num(model.encoder.config.num_hidden_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ee8de42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****starting with layer number of  12 ****\n",
      "a total of  4 subnets would be used for training\n",
      "subnet depths for training in epoch 0  :  [12, 12, 12, 12]\n",
      "at global step of  0  switching the subnet depth\n",
      "changing encoder number :  12  =>  12\n",
      "training the model with encoder number of  12\n",
      "at global step of  312  switching the subnet depth\n",
      "changing encoder number :  12  =>  12\n",
      "training the model with encoder number of  12\n",
      "at global step of  624  switching the subnet depth\n",
      "changing encoder number :  12  =>  12\n",
      "training the model with encoder number of  12\n",
      "changing encoder number :  12  =>  12\n",
      "changing encoder number :  12  =>  12\n",
      "Epoch [1/1], Step [625/1250], Train Loss: 0.3265, Valid Loss: 0.3873\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/12model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/12metrics.pt\n",
      "at global step of  936  switching the subnet depth\n",
      "changing encoder number :  12  =>  12\n",
      "training the model with encoder number of  12\n",
      "changing encoder number :  12  =>  12\n",
      "changing encoder number :  12  =>  12\n",
      "Epoch [1/1], Step [1250/1250], Train Loss: 0.3957, Valid Loss: 0.3297\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/12model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/12metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/12metrics.pt\n",
      "Accuracy log saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/12acc_log.pt\n",
      "Finished Training!\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5015    0.9993    0.6679     12500\n",
      "           0     0.9053    0.0069    0.0137     12500\n",
      "\n",
      "    accuracy                         0.5031     25000\n",
      "   macro avg     0.7034    0.5031    0.3408     25000\n",
      "weighted avg     0.7034    0.5031    0.3408     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.50308\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5054    0.9988    0.6712     12500\n",
      "           0     0.9497    0.0226    0.0442     12500\n",
      "\n",
      "    accuracy                         0.5107     25000\n",
      "   macro avg     0.7275    0.5107    0.3577     25000\n",
      "weighted avg     0.7275    0.5107    0.3577     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.51072\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5931    0.9620    0.7338     12500\n",
      "           0     0.8995    0.3401    0.4936     12500\n",
      "\n",
      "    accuracy                         0.6510     25000\n",
      "   macro avg     0.7463    0.6510    0.6137     25000\n",
      "weighted avg     0.7463    0.6510    0.6137     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.65104\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6888    0.8750    0.7708     12500\n",
      "           0     0.8287    0.6046    0.6992     12500\n",
      "\n",
      "    accuracy                         0.7398     25000\n",
      "   macro avg     0.7588    0.7398    0.7350     25000\n",
      "weighted avg     0.7588    0.7398    0.7350     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.73984\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8590    0.6902    0.7654     12500\n",
      "           0     0.7411    0.8867    0.8074     12500\n",
      "\n",
      "    accuracy                         0.7884     25000\n",
      "   macro avg     0.8000    0.7884    0.7864     25000\n",
      "weighted avg     0.8000    0.7884    0.7864     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.78844\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9195    0.7440    0.8225     12500\n",
      "           0     0.7850    0.9349    0.8534     12500\n",
      "\n",
      "    accuracy                         0.8394     25000\n",
      "   macro avg     0.8523    0.8394    0.8380     25000\n",
      "weighted avg     0.8523    0.8394    0.8380     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.83944\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9126    0.7893    0.8465     12500\n",
      "           0     0.8144    0.9244    0.8659     12500\n",
      "\n",
      "    accuracy                         0.8568     25000\n",
      "   macro avg     0.8635    0.8568    0.8562     25000\n",
      "weighted avg     0.8635    0.8568    0.8562     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.85684\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9039    0.8088    0.8537     12500\n",
      "           0     0.8270    0.9140    0.8683     12500\n",
      "\n",
      "    accuracy                         0.8614     25000\n",
      "   macro avg     0.8654    0.8614    0.8610     25000\n",
      "weighted avg     0.8654    0.8614    0.8610     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.8614\n",
      "results of the model trained using  12  layers \n",
      "5  ->  0.50308\n",
      "6  ->  0.51072\n",
      "7  ->  0.65104\n",
      "8  ->  0.73984\n",
      "9  ->  0.78844\n",
      "10  ->  0.83944\n",
      "11  ->  0.85684\n",
      "12  ->  0.8614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the best model\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/12model.pt\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5015    0.9993    0.6679     12500\n",
      "           0     0.9053    0.0069    0.0137     12500\n",
      "\n",
      "    accuracy                         0.5031     25000\n",
      "   macro avg     0.7034    0.5031    0.3408     25000\n",
      "weighted avg     0.7034    0.5031    0.3408     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.50308\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5054    0.9988    0.6712     12500\n",
      "           0     0.9497    0.0226    0.0442     12500\n",
      "\n",
      "    accuracy                         0.5107     25000\n",
      "   macro avg     0.7275    0.5107    0.3577     25000\n",
      "weighted avg     0.7275    0.5107    0.3577     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.51072\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5931    0.9620    0.7338     12500\n",
      "           0     0.8995    0.3401    0.4936     12500\n",
      "\n",
      "    accuracy                         0.6510     25000\n",
      "   macro avg     0.7463    0.6510    0.6137     25000\n",
      "weighted avg     0.7463    0.6510    0.6137     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.65104\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6888    0.8750    0.7708     12500\n",
      "           0     0.8287    0.6046    0.6992     12500\n",
      "\n",
      "    accuracy                         0.7398     25000\n",
      "   macro avg     0.7588    0.7398    0.7350     25000\n",
      "weighted avg     0.7588    0.7398    0.7350     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.73984\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8590    0.6902    0.7654     12500\n",
      "           0     0.7411    0.8867    0.8074     12500\n",
      "\n",
      "    accuracy                         0.7884     25000\n",
      "   macro avg     0.8000    0.7884    0.7864     25000\n",
      "weighted avg     0.8000    0.7884    0.7864     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.78844\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9195    0.7440    0.8225     12500\n",
      "           0     0.7850    0.9349    0.8534     12500\n",
      "\n",
      "    accuracy                         0.8394     25000\n",
      "   macro avg     0.8523    0.8394    0.8380     25000\n",
      "weighted avg     0.8523    0.8394    0.8380     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.83944\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9126    0.7893    0.8465     12500\n",
      "           0     0.8144    0.9244    0.8659     12500\n",
      "\n",
      "    accuracy                         0.8568     25000\n",
      "   macro avg     0.8635    0.8568    0.8562     25000\n",
      "weighted avg     0.8635    0.8568    0.8562     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.85684\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9039    0.8088    0.8537     12500\n",
      "           0     0.8270    0.9140    0.8683     12500\n",
      "\n",
      "    accuracy                         0.8614     25000\n",
      "   macro avg     0.8654    0.8614    0.8610     25000\n",
      "weighted avg     0.8654    0.8614    0.8610     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.8614\n",
      "results of the model trained using  12  layers \n",
      "5  ->  0.50308\n",
      "6  ->  0.51072\n",
      "7  ->  0.65104\n",
      "8  ->  0.73984\n",
      "9  ->  0.78844\n",
      "10  ->  0.83944\n",
      "11  ->  0.85684\n",
      "12  ->  0.8614\n",
      "\n",
      "\n",
      "****starting with layer number of  11 ****\n",
      "a total of  4 subnets would be used for training\n",
      "subnet depths for training in epoch 0  :  [11, 11, 12, 12]\n",
      "at global step of  0  switching the subnet depth\n",
      "changing encoder number :  12  =>  11\n",
      "training the model with encoder number of  11\n",
      "at global step of  312  switching the subnet depth\n",
      "changing encoder number :  12  =>  11\n",
      "training the model with encoder number of  11\n",
      "at global step of  624  switching the subnet depth\n",
      "changing encoder number :  12  =>  12\n",
      "training the model with encoder number of  12\n",
      "changing encoder number :  12  =>  12\n",
      "changing encoder number :  12  =>  12\n",
      "Epoch [1/1], Step [625/1250], Train Loss: 0.1561, Valid Loss: 0.3650\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/11model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/11metrics.pt\n",
      "at global step of  936  switching the subnet depth\n",
      "changing encoder number :  12  =>  12\n",
      "training the model with encoder number of  12\n",
      "changing encoder number :  12  =>  12\n",
      "changing encoder number :  12  =>  12\n",
      "Epoch [1/1], Step [1250/1250], Train Loss: 0.2465, Valid Loss: 0.3305\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/11model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/11metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/11metrics.pt\n",
      "Accuracy log saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/11acc_log.pt\n",
      "Finished Training!\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5012    0.9998    0.6677     12500\n",
      "           0     0.9545    0.0050    0.0100     12500\n",
      "\n",
      "    accuracy                         0.5024     25000\n",
      "   macro avg     0.7279    0.5024    0.3389     25000\n",
      "weighted avg     0.7279    0.5024    0.3389     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.5024\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5173    0.9950    0.6807     12500\n",
      "           0     0.9351    0.0714    0.1327     12500\n",
      "\n",
      "    accuracy                         0.5332     25000\n",
      "   macro avg     0.7262    0.5332    0.4067     25000\n",
      "weighted avg     0.7262    0.5332    0.4067     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.53324\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6796    0.8838    0.7683     12500\n",
      "           0     0.8338    0.5833    0.6864     12500\n",
      "\n",
      "    accuracy                         0.7335     25000\n",
      "   macro avg     0.7567    0.7335    0.7274     25000\n",
      "weighted avg     0.7567    0.7335    0.7274     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.73352\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7878    0.7058    0.7446     12500\n",
      "           0     0.7336    0.8099    0.7699     12500\n",
      "\n",
      "    accuracy                         0.7579     25000\n",
      "   macro avg     0.7607    0.7579    0.7572     25000\n",
      "weighted avg     0.7607    0.7579    0.7572     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.75788\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8539    0.6590    0.7439     12500\n",
      "           0     0.7224    0.8872    0.7964     12500\n",
      "\n",
      "    accuracy                         0.7731     25000\n",
      "   macro avg     0.7881    0.7731    0.7701     25000\n",
      "weighted avg     0.7881    0.7731    0.7701     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.77312\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8882    0.7831    0.8324     12500\n",
      "           0     0.8061    0.9014    0.8511     12500\n",
      "\n",
      "    accuracy                         0.8423     25000\n",
      "   macro avg     0.8471    0.8423    0.8417     25000\n",
      "weighted avg     0.8471    0.8423    0.8417     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.84228\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8860    0.8096    0.8461     12500\n",
      "           0     0.8247    0.8958    0.8588     12500\n",
      "\n",
      "    accuracy                         0.8527     25000\n",
      "   macro avg     0.8554    0.8527    0.8524     25000\n",
      "weighted avg     0.8554    0.8527    0.8524     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.85272\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8632    0.8388    0.8508     12500\n",
      "           0     0.8432    0.8670    0.8550     12500\n",
      "\n",
      "    accuracy                         0.8529     25000\n",
      "   macro avg     0.8532    0.8529    0.8529     25000\n",
      "weighted avg     0.8532    0.8529    0.8529     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.85292\n",
      "results of the model trained using  11  layers \n",
      "5  ->  0.5024\n",
      "6  ->  0.53324\n",
      "7  ->  0.73352\n",
      "8  ->  0.75788\n",
      "9  ->  0.77312\n",
      "10  ->  0.84228\n",
      "11  ->  0.85272\n",
      "12  ->  0.85292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the best model\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/11model.pt\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5012    0.9998    0.6677     12500\n",
      "           0     0.9545    0.0050    0.0100     12500\n",
      "\n",
      "    accuracy                         0.5024     25000\n",
      "   macro avg     0.7279    0.5024    0.3389     25000\n",
      "weighted avg     0.7279    0.5024    0.3389     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.5024\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5173    0.9950    0.6807     12500\n",
      "           0     0.9351    0.0714    0.1327     12500\n",
      "\n",
      "    accuracy                         0.5332     25000\n",
      "   macro avg     0.7262    0.5332    0.4067     25000\n",
      "weighted avg     0.7262    0.5332    0.4067     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.53324\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6796    0.8838    0.7683     12500\n",
      "           0     0.8338    0.5833    0.6864     12500\n",
      "\n",
      "    accuracy                         0.7335     25000\n",
      "   macro avg     0.7567    0.7335    0.7274     25000\n",
      "weighted avg     0.7567    0.7335    0.7274     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.73352\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7878    0.7058    0.7446     12500\n",
      "           0     0.7336    0.8099    0.7699     12500\n",
      "\n",
      "    accuracy                         0.7579     25000\n",
      "   macro avg     0.7607    0.7579    0.7572     25000\n",
      "weighted avg     0.7607    0.7579    0.7572     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.75788\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8539    0.6590    0.7439     12500\n",
      "           0     0.7224    0.8872    0.7964     12500\n",
      "\n",
      "    accuracy                         0.7731     25000\n",
      "   macro avg     0.7881    0.7731    0.7701     25000\n",
      "weighted avg     0.7881    0.7731    0.7701     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.77312\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8882    0.7831    0.8324     12500\n",
      "           0     0.8061    0.9014    0.8511     12500\n",
      "\n",
      "    accuracy                         0.8423     25000\n",
      "   macro avg     0.8471    0.8423    0.8417     25000\n",
      "weighted avg     0.8471    0.8423    0.8417     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.84228\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8860    0.8096    0.8461     12500\n",
      "           0     0.8247    0.8958    0.8588     12500\n",
      "\n",
      "    accuracy                         0.8527     25000\n",
      "   macro avg     0.8554    0.8527    0.8524     25000\n",
      "weighted avg     0.8554    0.8527    0.8524     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.85272\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8632    0.8388    0.8508     12500\n",
      "           0     0.8432    0.8670    0.8550     12500\n",
      "\n",
      "    accuracy                         0.8529     25000\n",
      "   macro avg     0.8532    0.8529    0.8529     25000\n",
      "weighted avg     0.8532    0.8529    0.8529     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.85292\n",
      "results of the model trained using  11  layers \n",
      "5  ->  0.5024\n",
      "6  ->  0.53324\n",
      "7  ->  0.73352\n",
      "8  ->  0.75788\n",
      "9  ->  0.77312\n",
      "10  ->  0.84228\n",
      "11  ->  0.85272\n",
      "12  ->  0.85292\n",
      "\n",
      "\n",
      "****starting with layer number of  10 ****\n",
      "a total of  4 subnets would be used for training\n",
      "subnet depths for training in epoch 0  :  [12, 10, 11, 10]\n",
      "at global step of  0  switching the subnet depth\n",
      "changing encoder number :  12  =>  12\n",
      "training the model with encoder number of  12\n",
      "at global step of  312  switching the subnet depth\n",
      "changing encoder number :  12  =>  10\n",
      "training the model with encoder number of  10\n",
      "at global step of  624  switching the subnet depth\n",
      "changing encoder number :  12  =>  11\n",
      "training the model with encoder number of  11\n",
      "changing encoder number :  12  =>  12\n",
      "changing encoder number :  12  =>  11\n",
      "Epoch [1/1], Step [625/1250], Train Loss: 0.0922, Valid Loss: 0.5187\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/10model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/10metrics.pt\n",
      "at global step of  936  switching the subnet depth\n",
      "changing encoder number :  12  =>  10\n",
      "training the model with encoder number of  10\n",
      "changing encoder number :  12  =>  12\n",
      "changing encoder number :  12  =>  10\n",
      "Epoch [1/1], Step [1250/1250], Train Loss: 0.1609, Valid Loss: 0.4612\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/10model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/10metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/10metrics.pt\n",
      "Accuracy log saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/10acc_log.pt\n",
      "Finished Training!\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5333    0.9898    0.6931     12500\n",
      "           0     0.9288    0.1337    0.2337     12500\n",
      "\n",
      "    accuracy                         0.5617     25000\n",
      "   macro avg     0.7311    0.5617    0.4634     25000\n",
      "weighted avg     0.7311    0.5617    0.4634     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.56172\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5422    0.9877    0.7001     12500\n",
      "           0     0.9309    0.1661    0.2819     12500\n",
      "\n",
      "    accuracy                         0.5769     25000\n",
      "   macro avg     0.7366    0.5769    0.4910     25000\n",
      "weighted avg     0.7366    0.5769    0.4910     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.57688\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6737    0.9071    0.7732     12500\n",
      "           0     0.8579    0.5607    0.6782     12500\n",
      "\n",
      "    accuracy                         0.7339     25000\n",
      "   macro avg     0.7658    0.7339    0.7257     25000\n",
      "weighted avg     0.7658    0.7339    0.7257     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.73392\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7477    0.8354    0.7891     12500\n",
      "           0     0.8136    0.7181    0.7628     12500\n",
      "\n",
      "    accuracy                         0.7768     25000\n",
      "   macro avg     0.7806    0.7768    0.7760     25000\n",
      "weighted avg     0.7806    0.7768    0.7760     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.77676\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8707    0.7670    0.8156     12500\n",
      "           0     0.7918    0.8861    0.8363     12500\n",
      "\n",
      "    accuracy                         0.8266     25000\n",
      "   macro avg     0.8313    0.8266    0.8259     25000\n",
      "weighted avg     0.8313    0.8266    0.8259     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.82656\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9078    0.7927    0.8463     12500\n",
      "           0     0.8160    0.9194    0.8647     12500\n",
      "\n",
      "    accuracy                         0.8561     25000\n",
      "   macro avg     0.8619    0.8561    0.8555     25000\n",
      "weighted avg     0.8619    0.8561    0.8555     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.85608\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9102    0.7865    0.8438     12500\n",
      "           0     0.8120    0.9224    0.8637     12500\n",
      "\n",
      "    accuracy                         0.8544     25000\n",
      "   macro avg     0.8611    0.8544    0.8538     25000\n",
      "weighted avg     0.8611    0.8544    0.8538     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.85444\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9085    0.7880    0.8440     12500\n",
      "           0     0.8128    0.9206    0.8634     12500\n",
      "\n",
      "    accuracy                         0.8543     25000\n",
      "   macro avg     0.8607    0.8543    0.8537     25000\n",
      "weighted avg     0.8607    0.8543    0.8537     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.85432\n",
      "results of the model trained using  10  layers \n",
      "5  ->  0.56172\n",
      "6  ->  0.57688\n",
      "7  ->  0.73392\n",
      "8  ->  0.77676\n",
      "9  ->  0.82656\n",
      "10  ->  0.85608\n",
      "11  ->  0.85444\n",
      "12  ->  0.85432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the best model\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/10model.pt\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5333    0.9898    0.6931     12500\n",
      "           0     0.9288    0.1337    0.2337     12500\n",
      "\n",
      "    accuracy                         0.5617     25000\n",
      "   macro avg     0.7311    0.5617    0.4634     25000\n",
      "weighted avg     0.7311    0.5617    0.4634     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.56172\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5422    0.9877    0.7001     12500\n",
      "           0     0.9309    0.1661    0.2819     12500\n",
      "\n",
      "    accuracy                         0.5769     25000\n",
      "   macro avg     0.7366    0.5769    0.4910     25000\n",
      "weighted avg     0.7366    0.5769    0.4910     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.57688\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6737    0.9071    0.7732     12500\n",
      "           0     0.8579    0.5607    0.6782     12500\n",
      "\n",
      "    accuracy                         0.7339     25000\n",
      "   macro avg     0.7658    0.7339    0.7257     25000\n",
      "weighted avg     0.7658    0.7339    0.7257     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.73392\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7477    0.8354    0.7891     12500\n",
      "           0     0.8136    0.7181    0.7628     12500\n",
      "\n",
      "    accuracy                         0.7768     25000\n",
      "   macro avg     0.7806    0.7768    0.7760     25000\n",
      "weighted avg     0.7806    0.7768    0.7760     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.77676\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8707    0.7670    0.8156     12500\n",
      "           0     0.7918    0.8861    0.8363     12500\n",
      "\n",
      "    accuracy                         0.8266     25000\n",
      "   macro avg     0.8313    0.8266    0.8259     25000\n",
      "weighted avg     0.8313    0.8266    0.8259     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.82656\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9078    0.7927    0.8463     12500\n",
      "           0     0.8160    0.9194    0.8647     12500\n",
      "\n",
      "    accuracy                         0.8561     25000\n",
      "   macro avg     0.8619    0.8561    0.8555     25000\n",
      "weighted avg     0.8619    0.8561    0.8555     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.85608\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9102    0.7865    0.8438     12500\n",
      "           0     0.8120    0.9224    0.8637     12500\n",
      "\n",
      "    accuracy                         0.8544     25000\n",
      "   macro avg     0.8611    0.8544    0.8538     25000\n",
      "weighted avg     0.8611    0.8544    0.8538     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.85444\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9085    0.7880    0.8440     12500\n",
      "           0     0.8128    0.9206    0.8634     12500\n",
      "\n",
      "    accuracy                         0.8543     25000\n",
      "   macro avg     0.8607    0.8543    0.8537     25000\n",
      "weighted avg     0.8607    0.8543    0.8537     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.85432\n",
      "results of the model trained using  10  layers \n",
      "5  ->  0.56172\n",
      "6  ->  0.57688\n",
      "7  ->  0.73392\n",
      "8  ->  0.77676\n",
      "9  ->  0.82656\n",
      "10  ->  0.85608\n",
      "11  ->  0.85444\n",
      "12  ->  0.85432\n",
      "\n",
      "\n",
      "****starting with layer number of  9 ****\n",
      "a total of  4 subnets would be used for training\n",
      "subnet depths for training in epoch 0  :  [9, 11, 10, 11]\n",
      "at global step of  0  switching the subnet depth\n",
      "changing encoder number :  12  =>  9\n",
      "training the model with encoder number of  9\n",
      "at global step of  312  switching the subnet depth\n",
      "changing encoder number :  12  =>  11\n",
      "training the model with encoder number of  11\n",
      "at global step of  624  switching the subnet depth\n",
      "changing encoder number :  12  =>  10\n",
      "training the model with encoder number of  10\n",
      "changing encoder number :  12  =>  12\n",
      "changing encoder number :  12  =>  10\n",
      "Epoch [1/1], Step [625/1250], Train Loss: 0.0847, Valid Loss: 0.4885\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/9model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/9metrics.pt\n",
      "at global step of  936  switching the subnet depth\n",
      "changing encoder number :  12  =>  11\n",
      "training the model with encoder number of  11\n",
      "changing encoder number :  12  =>  12\n",
      "changing encoder number :  12  =>  11\n",
      "Epoch [1/1], Step [1250/1250], Train Loss: 0.1083, Valid Loss: 0.6246\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/9metrics.pt\n",
      "Accuracy log saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/9acc_log.pt\n",
      "Finished Training!\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5551    0.9802    0.7088     12500\n",
      "           0     0.9156    0.2142    0.3472     12500\n",
      "\n",
      "    accuracy                         0.5972     25000\n",
      "   macro avg     0.7353    0.5972    0.5280     25000\n",
      "weighted avg     0.7353    0.5972    0.5280     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.59724\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5698    0.9785    0.7202     12500\n",
      "           0     0.9239    0.2611    0.4072     12500\n",
      "\n",
      "    accuracy                         0.6198     25000\n",
      "   macro avg     0.7468    0.6198    0.5637     25000\n",
      "weighted avg     0.7468    0.6198    0.5637     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.6198\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6718    0.9280    0.7794     12500\n",
      "           0     0.8836    0.5466    0.6754     12500\n",
      "\n",
      "    accuracy                         0.7373     25000\n",
      "   macro avg     0.7777    0.7373    0.7274     25000\n",
      "weighted avg     0.7777    0.7373    0.7274     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.73728\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7300    0.9078    0.8092     12500\n",
      "           0     0.8781    0.6642    0.7563     12500\n",
      "\n",
      "    accuracy                         0.7860     25000\n",
      "   macro avg     0.8041    0.7860    0.7828     25000\n",
      "weighted avg     0.8041    0.7860    0.7828     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.786\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8759    0.8381    0.8566     12500\n",
      "           0     0.8448    0.8813    0.8626     12500\n",
      "\n",
      "    accuracy                         0.8597     25000\n",
      "   macro avg     0.8604    0.8597    0.8596     25000\n",
      "weighted avg     0.8604    0.8597    0.8596     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.85968\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9143    0.7672    0.8343     12500\n",
      "           0     0.7995    0.9281    0.8590     12500\n",
      "\n",
      "    accuracy                         0.8476     25000\n",
      "   macro avg     0.8569    0.8476    0.8466     25000\n",
      "weighted avg     0.8569    0.8476    0.8466     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.84764\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9344    0.7066    0.8047     12500\n",
      "           0     0.7641    0.9504    0.8471     12500\n",
      "\n",
      "    accuracy                         0.8285     25000\n",
      "   macro avg     0.8493    0.8285    0.8259     25000\n",
      "weighted avg     0.8493    0.8285    0.8259     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.82852\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9387    0.6882    0.7942     12500\n",
      "           0     0.7539    0.9550    0.8426     12500\n",
      "\n",
      "    accuracy                         0.8216     25000\n",
      "   macro avg     0.8463    0.8216    0.8184     25000\n",
      "weighted avg     0.8463    0.8216    0.8184     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.82164\n",
      "results of the model trained using  9  layers \n",
      "5  ->  0.59724\n",
      "6  ->  0.6198\n",
      "7  ->  0.73728\n",
      "8  ->  0.786\n",
      "9  ->  0.85968\n",
      "10  ->  0.84764\n",
      "11  ->  0.82852\n",
      "12  ->  0.82164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the best model\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/9model.pt\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5386    0.9737    0.6936     12500\n",
      "           0     0.8631    0.1660    0.2784     12500\n",
      "\n",
      "    accuracy                         0.5698     25000\n",
      "   macro avg     0.7009    0.5698    0.4860     25000\n",
      "weighted avg     0.7009    0.5698    0.4860     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.56984\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5399    0.9744    0.6948     12500\n",
      "           0     0.8690    0.1698    0.2840     12500\n",
      "\n",
      "    accuracy                         0.5721     25000\n",
      "   macro avg     0.7045    0.5721    0.4894     25000\n",
      "weighted avg     0.7045    0.5721    0.4894     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.57208\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5888    0.9684    0.7323     12500\n",
      "           0     0.9110    0.3236    0.4776     12500\n",
      "\n",
      "    accuracy                         0.6460     25000\n",
      "   macro avg     0.7499    0.6460    0.6049     25000\n",
      "weighted avg     0.7499    0.6460    0.6049     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.646\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6245    0.9741    0.7611     12500\n",
      "           0     0.9411    0.4143    0.5753     12500\n",
      "\n",
      "    accuracy                         0.6942     25000\n",
      "   macro avg     0.7828    0.6942    0.6682     25000\n",
      "weighted avg     0.7828    0.6942    0.6682     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.6942\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8083    0.9239    0.8623     12500\n",
      "           0     0.9112    0.7809    0.8410     12500\n",
      "\n",
      "    accuracy                         0.8524     25000\n",
      "   macro avg     0.8598    0.8524    0.8516     25000\n",
      "weighted avg     0.8598    0.8524    0.8516     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.8524\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8300    0.9217    0.8734     12500\n",
      "           0     0.9120    0.8112    0.8586     12500\n",
      "\n",
      "    accuracy                         0.8664     25000\n",
      "   macro avg     0.8710    0.8664    0.8660     25000\n",
      "weighted avg     0.8710    0.8664    0.8660     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.86644\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8409    0.9139    0.8759     12500\n",
      "           0     0.9057    0.8270    0.8646     12500\n",
      "\n",
      "    accuracy                         0.8705     25000\n",
      "   macro avg     0.8733    0.8705    0.8702     25000\n",
      "weighted avg     0.8733    0.8705    0.8702     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.87048\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8442    0.9126    0.8771     12500\n",
      "           0     0.9049    0.8316    0.8667     12500\n",
      "\n",
      "    accuracy                         0.8721     25000\n",
      "   macro avg     0.8745    0.8721    0.8719     25000\n",
      "weighted avg     0.8745    0.8721    0.8719     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.87208\n",
      "results of the model trained using  9  layers \n",
      "5  ->  0.56984\n",
      "6  ->  0.57208\n",
      "7  ->  0.646\n",
      "8  ->  0.6942\n",
      "9  ->  0.8524\n",
      "10  ->  0.86644\n",
      "11  ->  0.87048\n",
      "12  ->  0.87208\n",
      "\n",
      "\n",
      "****starting with layer number of  8 ****\n",
      "a total of  4 subnets would be used for training\n",
      "subnet depths for training in epoch 0  :  [8, 11, 10, 8]\n",
      "at global step of  0  switching the subnet depth\n",
      "changing encoder number :  12  =>  8\n",
      "training the model with encoder number of  8\n",
      "at global step of  312  switching the subnet depth\n",
      "changing encoder number :  12  =>  11\n",
      "training the model with encoder number of  11\n",
      "at global step of  624  switching the subnet depth\n",
      "changing encoder number :  12  =>  10\n",
      "training the model with encoder number of  10\n",
      "changing encoder number :  12  =>  12\n",
      "changing encoder number :  12  =>  10\n",
      "Epoch [1/1], Step [625/1250], Train Loss: 0.0831, Valid Loss: 0.5821\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/8model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/8metrics.pt\n",
      "at global step of  936  switching the subnet depth\n",
      "changing encoder number :  12  =>  8\n",
      "training the model with encoder number of  8\n",
      "changing encoder number :  12  =>  12\n",
      "changing encoder number :  12  =>  8\n",
      "Epoch [1/1], Step [1250/1250], Train Loss: 0.1532, Valid Loss: 0.5339\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/8model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/8metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/8metrics.pt\n",
      "Accuracy log saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/8acc_log.pt\n",
      "Finished Training!\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7401    0.8040    0.7707     12500\n",
      "           0     0.7855    0.7177    0.7501     12500\n",
      "\n",
      "    accuracy                         0.7608     25000\n",
      "   macro avg     0.7628    0.7608    0.7604     25000\n",
      "weighted avg     0.7628    0.7608    0.7604     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.76084\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7503    0.8467    0.7956     12500\n",
      "           0     0.8241    0.7182    0.7675     12500\n",
      "\n",
      "    accuracy                         0.7824     25000\n",
      "   macro avg     0.7872    0.7824    0.7815     25000\n",
      "weighted avg     0.7872    0.7824    0.7815     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.78244\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8813    0.6866    0.7719     12500\n",
      "           0     0.7433    0.9075    0.8173     12500\n",
      "\n",
      "    accuracy                         0.7971     25000\n",
      "   macro avg     0.8123    0.7971    0.7946     25000\n",
      "weighted avg     0.8123    0.7971    0.7946     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.79708\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9243    0.7026    0.7983     12500\n",
      "           0     0.7601    0.9425    0.8415     12500\n",
      "\n",
      "    accuracy                         0.8225     25000\n",
      "   macro avg     0.8422    0.8225    0.8199     25000\n",
      "weighted avg     0.8422    0.8225    0.8199     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.82252\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9083    0.7873    0.8435     12500\n",
      "           0     0.8123    0.9206    0.8630     12500\n",
      "\n",
      "    accuracy                         0.8539     25000\n",
      "   macro avg     0.8603    0.8539    0.8533     25000\n",
      "weighted avg     0.8603    0.8539    0.8533     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.85392\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8860    0.8424    0.8636     12500\n",
      "           0     0.8498    0.8916    0.8702     12500\n",
      "\n",
      "    accuracy                         0.8670     25000\n",
      "   macro avg     0.8679    0.8670    0.8669     25000\n",
      "weighted avg     0.8679    0.8670    0.8669     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.867\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8869    0.8461    0.8660     12500\n",
      "           0     0.8528    0.8921    0.8720     12500\n",
      "\n",
      "    accuracy                         0.8691     25000\n",
      "   macro avg     0.8699    0.8691    0.8690     25000\n",
      "weighted avg     0.8699    0.8691    0.8690     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.86908\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8832    0.8553    0.8690     12500\n",
      "           0     0.8597    0.8869    0.8731     12500\n",
      "\n",
      "    accuracy                         0.8711     25000\n",
      "   macro avg     0.8715    0.8711    0.8710     25000\n",
      "weighted avg     0.8715    0.8711    0.8710     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.87108\n",
      "results of the model trained using  8  layers \n",
      "5  ->  0.76084\n",
      "6  ->  0.78244\n",
      "7  ->  0.79708\n",
      "8  ->  0.82252\n",
      "9  ->  0.85392\n",
      "10  ->  0.867\n",
      "11  ->  0.86908\n",
      "12  ->  0.87108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the best model\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/8model.pt\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7401    0.8040    0.7707     12500\n",
      "           0     0.7855    0.7177    0.7501     12500\n",
      "\n",
      "    accuracy                         0.7608     25000\n",
      "   macro avg     0.7628    0.7608    0.7604     25000\n",
      "weighted avg     0.7628    0.7608    0.7604     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.76084\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7503    0.8467    0.7956     12500\n",
      "           0     0.8241    0.7182    0.7675     12500\n",
      "\n",
      "    accuracy                         0.7824     25000\n",
      "   macro avg     0.7872    0.7824    0.7815     25000\n",
      "weighted avg     0.7872    0.7824    0.7815     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.78244\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8813    0.6866    0.7719     12500\n",
      "           0     0.7433    0.9075    0.8173     12500\n",
      "\n",
      "    accuracy                         0.7971     25000\n",
      "   macro avg     0.8123    0.7971    0.7946     25000\n",
      "weighted avg     0.8123    0.7971    0.7946     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.79708\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9243    0.7026    0.7983     12500\n",
      "           0     0.7601    0.9425    0.8415     12500\n",
      "\n",
      "    accuracy                         0.8225     25000\n",
      "   macro avg     0.8422    0.8225    0.8199     25000\n",
      "weighted avg     0.8422    0.8225    0.8199     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.82252\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9083    0.7873    0.8435     12500\n",
      "           0     0.8123    0.9206    0.8630     12500\n",
      "\n",
      "    accuracy                         0.8539     25000\n",
      "   macro avg     0.8603    0.8539    0.8533     25000\n",
      "weighted avg     0.8603    0.8539    0.8533     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.85392\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8860    0.8424    0.8636     12500\n",
      "           0     0.8498    0.8916    0.8702     12500\n",
      "\n",
      "    accuracy                         0.8670     25000\n",
      "   macro avg     0.8679    0.8670    0.8669     25000\n",
      "weighted avg     0.8679    0.8670    0.8669     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.867\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8869    0.8461    0.8660     12500\n",
      "           0     0.8528    0.8921    0.8720     12500\n",
      "\n",
      "    accuracy                         0.8691     25000\n",
      "   macro avg     0.8699    0.8691    0.8690     25000\n",
      "weighted avg     0.8699    0.8691    0.8690     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.86908\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8832    0.8553    0.8690     12500\n",
      "           0     0.8597    0.8869    0.8731     12500\n",
      "\n",
      "    accuracy                         0.8711     25000\n",
      "   macro avg     0.8715    0.8711    0.8710     25000\n",
      "weighted avg     0.8715    0.8711    0.8710     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.87108\n",
      "results of the model trained using  8  layers \n",
      "5  ->  0.76084\n",
      "6  ->  0.78244\n",
      "7  ->  0.79708\n",
      "8  ->  0.82252\n",
      "9  ->  0.85392\n",
      "10  ->  0.867\n",
      "11  ->  0.86908\n",
      "12  ->  0.87108\n",
      "\n",
      "\n",
      "****starting with layer number of  7 ****\n",
      "a total of  4 subnets would be used for training\n",
      "subnet depths for training in epoch 0  :  [8, 11, 11, 8]\n",
      "at global step of  0  switching the subnet depth\n",
      "changing encoder number :  12  =>  8\n",
      "training the model with encoder number of  8\n",
      "at global step of  312  switching the subnet depth\n",
      "changing encoder number :  12  =>  11\n",
      "training the model with encoder number of  11\n",
      "at global step of  624  switching the subnet depth\n",
      "changing encoder number :  12  =>  11\n",
      "training the model with encoder number of  11\n",
      "changing encoder number :  12  =>  12\n",
      "changing encoder number :  12  =>  11\n",
      "Epoch [1/1], Step [625/1250], Train Loss: 0.0404, Valid Loss: 0.5827\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/7model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/7metrics.pt\n",
      "at global step of  936  switching the subnet depth\n",
      "changing encoder number :  12  =>  8\n",
      "training the model with encoder number of  8\n",
      "changing encoder number :  12  =>  12\n",
      "changing encoder number :  12  =>  8\n",
      "Epoch [1/1], Step [1250/1250], Train Loss: 0.0661, Valid Loss: 0.6867\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/7metrics.pt\n",
      "Accuracy log saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/7acc_log.pt\n",
      "Finished Training!\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7848    0.7062    0.7434     12500\n",
      "           0     0.7330    0.8063    0.7679     12500\n",
      "\n",
      "    accuracy                         0.7563     25000\n",
      "   macro avg     0.7589    0.7563    0.7557     25000\n",
      "weighted avg     0.7589    0.7563    0.7557     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.75628\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7995    0.7993    0.7994     12500\n",
      "           0     0.7993    0.7995    0.7994     12500\n",
      "\n",
      "    accuracy                         0.7994     25000\n",
      "   macro avg     0.7994    0.7994    0.7994     25000\n",
      "weighted avg     0.7994    0.7994    0.7994     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.7994\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8516    0.7582    0.8021     12500\n",
      "           0     0.7821    0.8678    0.8227     12500\n",
      "\n",
      "    accuracy                         0.8130     25000\n",
      "   macro avg     0.8168    0.8130    0.8124     25000\n",
      "weighted avg     0.8168    0.8130    0.8124     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.813\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8980    0.7727    0.8307     12500\n",
      "           0     0.8005    0.9122    0.8528     12500\n",
      "\n",
      "    accuracy                         0.8425     25000\n",
      "   macro avg     0.8493    0.8425    0.8417     25000\n",
      "weighted avg     0.8493    0.8425    0.8417     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.84248\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8868    0.8277    0.8562     12500\n",
      "           0     0.8384    0.8943    0.8655     12500\n",
      "\n",
      "    accuracy                         0.8610     25000\n",
      "   macro avg     0.8626    0.8610    0.8608     25000\n",
      "weighted avg     0.8626    0.8610    0.8608     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.861\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8646    0.8790    0.8717     12500\n",
      "           0     0.8769    0.8623    0.8696     12500\n",
      "\n",
      "    accuracy                         0.8706     25000\n",
      "   macro avg     0.8707    0.8706    0.8706     25000\n",
      "weighted avg     0.8707    0.8706    0.8706     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.87064\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8659    0.8762    0.8710     12500\n",
      "           0     0.8747    0.8643    0.8695     12500\n",
      "\n",
      "    accuracy                         0.8702     25000\n",
      "   macro avg     0.8703    0.8702    0.8702     25000\n",
      "weighted avg     0.8703    0.8702    0.8702     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.87024\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8611    0.8856    0.8732     12500\n",
      "           0     0.8823    0.8572    0.8695     12500\n",
      "\n",
      "    accuracy                         0.8714     25000\n",
      "   macro avg     0.8717    0.8714    0.8714     25000\n",
      "weighted avg     0.8717    0.8714    0.8714     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.8714\n",
      "results of the model trained using  7  layers \n",
      "5  ->  0.75628\n",
      "6  ->  0.7994\n",
      "7  ->  0.813\n",
      "8  ->  0.84248\n",
      "9  ->  0.861\n",
      "10  ->  0.87064\n",
      "11  ->  0.87024\n",
      "12  ->  0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the best model\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/7model.pt\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5825    0.9810    0.7310     12500\n",
      "           0     0.9400    0.2968    0.4511     12500\n",
      "\n",
      "    accuracy                         0.6389     25000\n",
      "   macro avg     0.7612    0.6389    0.5911     25000\n",
      "weighted avg     0.7612    0.6389    0.5911     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.63892\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6107    0.9778    0.7518     12500\n",
      "           0     0.9444    0.3766    0.5384     12500\n",
      "\n",
      "    accuracy                         0.6772     25000\n",
      "   macro avg     0.7775    0.6772    0.6451     25000\n",
      "weighted avg     0.7775    0.6772    0.6451     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.6772\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7212    0.9451    0.8181     12500\n",
      "           0     0.9204    0.6347    0.7513     12500\n",
      "\n",
      "    accuracy                         0.7899     25000\n",
      "   macro avg     0.8208    0.7899    0.7847     25000\n",
      "weighted avg     0.8208    0.7899    0.7847     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.78992\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8375    0.9052    0.8700     12500\n",
      "           0     0.8969    0.8244    0.8591     12500\n",
      "\n",
      "    accuracy                         0.8648     25000\n",
      "   macro avg     0.8672    0.8648    0.8646     25000\n",
      "weighted avg     0.8672    0.8648    0.8646     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.8648\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8536    0.8990    0.8757     12500\n",
      "           0     0.8934    0.8458    0.8689     12500\n",
      "\n",
      "    accuracy                         0.8724     25000\n",
      "   macro avg     0.8735    0.8724    0.8723     25000\n",
      "weighted avg     0.8735    0.8724    0.8723     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.8724\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8622    0.8951    0.8784     12500\n",
      "           0     0.8910    0.8570    0.8736     12500\n",
      "\n",
      "    accuracy                         0.8760     25000\n",
      "   macro avg     0.8766    0.8760    0.8760     25000\n",
      "weighted avg     0.8766    0.8760    0.8760     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.87604\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8732    0.8859    0.8795     12500\n",
      "           0     0.8842    0.8714    0.8778     12500\n",
      "\n",
      "    accuracy                         0.8786     25000\n",
      "   macro avg     0.8787    0.8786    0.8786     25000\n",
      "weighted avg     0.8787    0.8786    0.8786     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.87864\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8761    0.8860    0.8810     12500\n",
      "           0     0.8847    0.8747    0.8797     12500\n",
      "\n",
      "    accuracy                         0.8804     25000\n",
      "   macro avg     0.8804    0.8804    0.8804     25000\n",
      "weighted avg     0.8804    0.8804    0.8804     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.88036\n",
      "results of the model trained using  7  layers \n",
      "5  ->  0.63892\n",
      "6  ->  0.6772\n",
      "7  ->  0.78992\n",
      "8  ->  0.8648\n",
      "9  ->  0.8724\n",
      "10  ->  0.87604\n",
      "11  ->  0.87864\n",
      "12  ->  0.88036\n",
      "\n",
      "\n",
      "****starting with layer number of  6 ****\n",
      "a total of  4 subnets would be used for training\n",
      "subnet depths for training in epoch 0  :  [10, 11, 10, 9]\n",
      "at global step of  0  switching the subnet depth\n",
      "changing encoder number :  12  =>  10\n",
      "training the model with encoder number of  10\n",
      "at global step of  312  switching the subnet depth\n",
      "changing encoder number :  12  =>  11\n",
      "training the model with encoder number of  11\n",
      "at global step of  624  switching the subnet depth\n",
      "changing encoder number :  12  =>  10\n",
      "training the model with encoder number of  10\n",
      "changing encoder number :  12  =>  12\n",
      "changing encoder number :  12  =>  10\n",
      "Epoch [1/1], Step [625/1250], Train Loss: 0.0279, Valid Loss: 0.6473\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/6model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/6metrics.pt\n",
      "at global step of  936  switching the subnet depth\n",
      "changing encoder number :  12  =>  9\n",
      "training the model with encoder number of  9\n",
      "changing encoder number :  12  =>  12\n",
      "changing encoder number :  12  =>  9\n",
      "Epoch [1/1], Step [1250/1250], Train Loss: 0.0559, Valid Loss: 0.6808\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/6metrics.pt\n",
      "Accuracy log saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/6acc_log.pt\n",
      "Finished Training!\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8559    0.5285    0.6535     12500\n",
      "           0     0.6590    0.9110    0.7648     12500\n",
      "\n",
      "    accuracy                         0.7198     25000\n",
      "   macro avg     0.7574    0.7198    0.7091     25000\n",
      "weighted avg     0.7574    0.7198    0.7091     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.71976\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8925    0.5634    0.6908     12500\n",
      "           0     0.6810    0.9322    0.7871     12500\n",
      "\n",
      "    accuracy                         0.7478     25000\n",
      "   macro avg     0.7868    0.7478    0.7389     25000\n",
      "weighted avg     0.7868    0.7478    0.7389     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.7478\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9244    0.5419    0.6833     12500\n",
      "           0     0.6760    0.9557    0.7919     12500\n",
      "\n",
      "    accuracy                         0.7488     25000\n",
      "   macro avg     0.8002    0.7488    0.7376     25000\n",
      "weighted avg     0.8002    0.7488    0.7376     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.7488\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9102    0.7306    0.8105     12500\n",
      "           0     0.7750    0.9279    0.8446     12500\n",
      "\n",
      "    accuracy                         0.8292     25000\n",
      "   macro avg     0.8426    0.8292    0.8276     25000\n",
      "weighted avg     0.8426    0.8292    0.8276     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.82924\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9034    0.7900    0.8429     12500\n",
      "           0     0.8134    0.9155    0.8615     12500\n",
      "\n",
      "    accuracy                         0.8528     25000\n",
      "   macro avg     0.8584    0.8528    0.8522     25000\n",
      "weighted avg     0.8584    0.8528    0.8522     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.85276\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8732    0.8658    0.8694     12500\n",
      "           0     0.8669    0.8742    0.8705     12500\n",
      "\n",
      "    accuracy                         0.8700     25000\n",
      "   macro avg     0.8700    0.8700    0.8700     25000\n",
      "weighted avg     0.8700    0.8700    0.8700     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.87\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8722    0.8667    0.8694     12500\n",
      "           0     0.8675    0.8730    0.8702     12500\n",
      "\n",
      "    accuracy                         0.8698     25000\n",
      "   macro avg     0.8699    0.8698    0.8698     25000\n",
      "weighted avg     0.8699    0.8698    0.8698     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.86984\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8724    0.8677    0.8700     12500\n",
      "           0     0.8684    0.8731    0.8708     12500\n",
      "\n",
      "    accuracy                         0.8704     25000\n",
      "   macro avg     0.8704    0.8704    0.8704     25000\n",
      "weighted avg     0.8704    0.8704    0.8704     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.8704\n",
      "results of the model trained using  6  layers \n",
      "5  ->  0.71976\n",
      "6  ->  0.7478\n",
      "7  ->  0.7488\n",
      "8  ->  0.82924\n",
      "9  ->  0.85276\n",
      "10  ->  0.87\n",
      "11  ->  0.86984\n",
      "12  ->  0.8704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the best model\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/6model.pt\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8178    0.6670    0.7347     12500\n",
      "           0     0.7188    0.8514    0.7795     12500\n",
      "\n",
      "    accuracy                         0.7592     25000\n",
      "   macro avg     0.7683    0.7592    0.7571     25000\n",
      "weighted avg     0.7683    0.7592    0.7571     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.7592\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7972    0.8109    0.8040     12500\n",
      "           0     0.8076    0.7937    0.8006     12500\n",
      "\n",
      "    accuracy                         0.8023     25000\n",
      "   macro avg     0.8024    0.8023    0.8023     25000\n",
      "weighted avg     0.8024    0.8023    0.8023     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.80228\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7994    0.8608    0.8290     12500\n",
      "           0     0.8492    0.7840    0.8153     12500\n",
      "\n",
      "    accuracy                         0.8224     25000\n",
      "   macro avg     0.8243    0.8224    0.8221     25000\n",
      "weighted avg     0.8243    0.8224    0.8221     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.8224\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8751    0.8298    0.8519     12500\n",
      "           0     0.8382    0.8815    0.8593     12500\n",
      "\n",
      "    accuracy                         0.8557     25000\n",
      "   macro avg     0.8566    0.8557    0.8556     25000\n",
      "weighted avg     0.8566    0.8557    0.8556     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.85568\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8692    0.8637    0.8665     12500\n",
      "           0     0.8645    0.8701    0.8673     12500\n",
      "\n",
      "    accuracy                         0.8669     25000\n",
      "   macro avg     0.8669    0.8669    0.8669     25000\n",
      "weighted avg     0.8669    0.8669    0.8669     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.86688\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8625    0.8889    0.8755     12500\n",
      "           0     0.8854    0.8583    0.8716     12500\n",
      "\n",
      "    accuracy                         0.8736     25000\n",
      "   macro avg     0.8739    0.8736    0.8736     25000\n",
      "weighted avg     0.8739    0.8736    0.8736     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.8736\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8675    0.8863    0.8768     12500\n",
      "           0     0.8838    0.8646    0.8741     12500\n",
      "\n",
      "    accuracy                         0.8755     25000\n",
      "   macro avg     0.8757    0.8755    0.8755     25000\n",
      "weighted avg     0.8757    0.8755    0.8755     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.87548\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8673    0.8899    0.8785     12500\n",
      "           0     0.8870    0.8638    0.8753     12500\n",
      "\n",
      "    accuracy                         0.8769     25000\n",
      "   macro avg     0.8771    0.8769    0.8769     25000\n",
      "weighted avg     0.8771    0.8769    0.8769     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.87688\n",
      "results of the model trained using  6  layers \n",
      "5  ->  0.7592\n",
      "6  ->  0.80228\n",
      "7  ->  0.8224\n",
      "8  ->  0.85568\n",
      "9  ->  0.86688\n",
      "10  ->  0.8736\n",
      "11  ->  0.87548\n",
      "12  ->  0.87688\n",
      "\n",
      "\n",
      "****starting with layer number of  5 ****\n",
      "a total of  4 subnets would be used for training\n",
      "subnet depths for training in epoch 0  :  [12, 12, 5, 9]\n",
      "at global step of  0  switching the subnet depth\n",
      "changing encoder number :  12  =>  12\n",
      "training the model with encoder number of  12\n",
      "at global step of  312  switching the subnet depth\n",
      "changing encoder number :  12  =>  12\n",
      "training the model with encoder number of  12\n",
      "at global step of  624  switching the subnet depth\n",
      "changing encoder number :  12  =>  5\n",
      "training the model with encoder number of  5\n",
      "changing encoder number :  12  =>  12\n",
      "changing encoder number :  12  =>  5\n",
      "Epoch [1/1], Step [625/1250], Train Loss: 0.0328, Valid Loss: 0.5028\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/5model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/5metrics.pt\n",
      "at global step of  936  switching the subnet depth\n",
      "changing encoder number :  12  =>  9\n",
      "training the model with encoder number of  9\n",
      "changing encoder number :  12  =>  12\n",
      "changing encoder number :  12  =>  9\n",
      "Epoch [1/1], Step [1250/1250], Train Loss: 0.1992, Valid Loss: 0.6745\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/5metrics.pt\n",
      "Accuracy log saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/5acc_log.pt\n",
      "Finished Training!\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8118    0.8654    0.8377     12500\n",
      "           0     0.8559    0.7994    0.8267     12500\n",
      "\n",
      "    accuracy                         0.8324     25000\n",
      "   macro avg     0.8339    0.8324    0.8322     25000\n",
      "weighted avg     0.8339    0.8324    0.8322     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.8324\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8111    0.8690    0.8390     12500\n",
      "           0     0.8589    0.7976    0.8271     12500\n",
      "\n",
      "    accuracy                         0.8333     25000\n",
      "   macro avg     0.8350    0.8333    0.8331     25000\n",
      "weighted avg     0.8350    0.8333    0.8331     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.83328\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8674    0.7893    0.8265     12500\n",
      "           0     0.8067    0.8794    0.8415     12500\n",
      "\n",
      "    accuracy                         0.8343     25000\n",
      "   macro avg     0.8371    0.8343    0.8340     25000\n",
      "weighted avg     0.8371    0.8343    0.8340     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.83432\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9199    0.7294    0.8136     12500\n",
      "           0     0.7758    0.9365    0.8486     12500\n",
      "\n",
      "    accuracy                         0.8329     25000\n",
      "   macro avg     0.8478    0.8329    0.8311     25000\n",
      "weighted avg     0.8478    0.8329    0.8311     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.83292\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9254    0.7397    0.8222     12500\n",
      "           0     0.7832    0.9404    0.8546     12500\n",
      "\n",
      "    accuracy                         0.8400     25000\n",
      "   macro avg     0.8543    0.8400    0.8384     25000\n",
      "weighted avg     0.8543    0.8400    0.8384     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.84004\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9091    0.8002    0.8512     12500\n",
      "           0     0.8215    0.9200    0.8680     12500\n",
      "\n",
      "    accuracy                         0.8601     25000\n",
      "   macro avg     0.8653    0.8601    0.8596     25000\n",
      "weighted avg     0.8653    0.8601    0.8596     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.86008\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9161    0.7884    0.8475     12500\n",
      "           0     0.8143    0.9278    0.8674     12500\n",
      "\n",
      "    accuracy                         0.8581     25000\n",
      "   macro avg     0.8652    0.8581    0.8574     25000\n",
      "weighted avg     0.8652    0.8581    0.8574     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.85812\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9215    0.7742    0.8415     12500\n",
      "           0     0.8053    0.9340    0.8649     12500\n",
      "\n",
      "    accuracy                         0.8541     25000\n",
      "   macro avg     0.8634    0.8541    0.8532     25000\n",
      "weighted avg     0.8634    0.8541    0.8532     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.85412\n",
      "results of the model trained using  5  layers \n",
      "5  ->  0.8324\n",
      "6  ->  0.83328\n",
      "7  ->  0.83432\n",
      "8  ->  0.83292\n",
      "9  ->  0.84004\n",
      "10  ->  0.86008\n",
      "11  ->  0.85812\n",
      "12  ->  0.85412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the best model\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/progressive_shrinking/5model.pt\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7970    0.6890    0.7391     12500\n",
      "           0     0.7261    0.8245    0.7722     12500\n",
      "\n",
      "    accuracy                         0.7568     25000\n",
      "   macro avg     0.7616    0.7568    0.7556     25000\n",
      "weighted avg     0.7616    0.7568    0.7556     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.75676\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7947    0.7886    0.7916     12500\n",
      "           0     0.7902    0.7962    0.7932     12500\n",
      "\n",
      "    accuracy                         0.7924     25000\n",
      "   macro avg     0.7925    0.7924    0.7924     25000\n",
      "weighted avg     0.7925    0.7924    0.7924     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.79244\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8574    0.7578    0.8045     12500\n",
      "           0     0.7830    0.8740    0.8260     12500\n",
      "\n",
      "    accuracy                         0.8159     25000\n",
      "   macro avg     0.8202    0.8159    0.8153     25000\n",
      "weighted avg     0.8202    0.8159    0.8153     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.81588\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8866    0.8123    0.8478     12500\n",
      "           0     0.8268    0.8961    0.8601     12500\n",
      "\n",
      "    accuracy                         0.8542     25000\n",
      "   macro avg     0.8567    0.8542    0.8539     25000\n",
      "weighted avg     0.8567    0.8542    0.8539     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.8542\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8859    0.8402    0.8624     12500\n",
      "           0     0.8480    0.8918    0.8693     12500\n",
      "\n",
      "    accuracy                         0.8660     25000\n",
      "   macro avg     0.8669    0.8660    0.8659     25000\n",
      "weighted avg     0.8669    0.8660    0.8659     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.86596\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8731    0.8766    0.8749     12500\n",
      "           0     0.8761    0.8726    0.8744     12500\n",
      "\n",
      "    accuracy                         0.8746     25000\n",
      "   macro avg     0.8746    0.8746    0.8746     25000\n",
      "weighted avg     0.8746    0.8746    0.8746     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.87464\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8803    0.8690    0.8746     12500\n",
      "           0     0.8706    0.8818    0.8762     12500\n",
      "\n",
      "    accuracy                         0.8754     25000\n",
      "   macro avg     0.8755    0.8754    0.8754     25000\n",
      "weighted avg     0.8755    0.8754    0.8754     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.8754\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8847    0.8614    0.8729     12500\n",
      "           0     0.8650    0.8877    0.8762     12500\n",
      "\n",
      "    accuracy                         0.8746     25000\n",
      "   macro avg     0.8748    0.8746    0.8745     25000\n",
      "weighted avg     0.8748    0.8746    0.8745     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.87456\n",
      "results of the model trained using  5  layers \n",
      "5  ->  0.75676\n",
      "6  ->  0.79244\n",
      "7  ->  0.81588\n",
      "8  ->  0.8542\n",
      "9  ->  0.86596\n",
      "10  ->  0.87464\n",
      "11  ->  0.8754\n",
      "12  ->  0.87456\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BERT().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "last_model_acc = np.zeros((8,8))\n",
    "best_model_acc = np.zeros((8,8))\n",
    "for i in range(12,4,-1):\n",
    "    print(\"\\n\\n****starting with layer number of \",i,\"****\")\n",
    "    train(model=model, optimizer=optimizer, max_encoder_num=i,num_epochs = 1,num_subnets=4)\n",
    "    \n",
    "    ## Evaluation using the last model\n",
    "    for j in range(5,13):\n",
    "        acc = evaluate(model, test_iter, max_encoder_num=j)\n",
    "        last_model_acc[i-5][j-5] = acc\n",
    "        print(\"accuracy when using \", j, \" layers : \", acc)\n",
    "    print(\"results of the model trained using \",i,\" layers \")\n",
    "    for j in range(5,13):\n",
    "        print(j, \" -> \", last_model_acc[i-5][j-5])\n",
    "    \n",
    "    \n",
    "    ## Evaluation using the best model (highest accuracy when using all 12 layers)\n",
    "    best_model = BERT().to(device)\n",
    "    print(\"loading the best model\")\n",
    "    load_checkpoint(destination_folder +\"/\"+ str(i)+ 'model.pt', best_model)\n",
    "    for j in range(5,13):\n",
    "        acc = evaluate(best_model, test_iter, max_encoder_num=j)\n",
    "        best_model_acc[i-5][j-5] = acc\n",
    "        print(\"accuracy when using \", j, \" layers : \", acc)\n",
    "    print(\"results of the model trained using \",i,\" layers \")\n",
    "    for j in range(5,13):\n",
    "        print(j, \" -> \", best_model_acc[i-5][j-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "382a6680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4subnet_noSandwich_1epoch_last.npy\n",
    "# 4subnet_noSandwich_1epoch_best.npy\n",
    "\n",
    "with open('4subnet_noSandwich_1epoch_last.npy', 'wb') as f:\n",
    "    np.save(f, last_model_acc)\n",
    "with open('4subnet_noSandwich_1epoch_best.npy', 'wb') as f:    \n",
    "    np.save(f, best_model_acc)\n",
    "# with open('test.npy', 'rb') as f:\n",
    "#     a = np.load(f)\n",
    "#     b = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8706004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(last_model_acc,  linewidth=0.5,xticklabels=list(range(5,13)), yticklabels=list(range(5,13)))\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('num layers used for eval')\n",
    "ax.set_ylabel('num layers for the trained model')\n",
    "# ax.axis([5, 12,5,12])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07b0c216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(best_model_acc,  linewidth=0.5,xticklabels=list(range(5,13)), yticklabels=list(range(5,13)))\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('num layers used for eval')\n",
    "ax.set_ylabel('num layers for the trained model')\n",
    "# ax.axis([5, 12,5,12])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8e1efc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(last_model_acc,  linewidth=0.5,xticklabels=list(range(5,13)), yticklabels=list(range(5,13)))\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('num layers used for eval')\n",
    "ax.set_ylabel('num layers for the trained model')\n",
    "# ax.axis([5, 12,5,12])\n",
    "plt.title(\"4 subnets; no sandwich; 1 epoch per layer; last model\")\n",
    "plt.savefig('4subnet_noSandwich_1epoch_last_heatmap.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50fc1420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(best_model_acc,  linewidth=0.5,xticklabels=list(range(5,13)), yticklabels=list(range(5,13)))\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('num layers used for eval')\n",
    "ax.set_ylabel('num layers for the trained model')\n",
    "# ax.axis([5, 12,5,12])\n",
    "plt.title(\"4 subnets; no sandwich; 1 epoch per layer; best model\")\n",
    "plt.savefig('4subnet_noSandwich_1epoch_best_heatmap.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bac4745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
