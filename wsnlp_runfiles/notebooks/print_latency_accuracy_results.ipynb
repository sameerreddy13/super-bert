{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaf33995",
   "metadata": {},
   "source": [
    "## How to use\n",
    "\n",
    "### Variables to specify\n",
    "- `NUM_TRIALS`  : number of trials used to measure latency\n",
    "- `LATENCY_DIR` : the directory for the latency measurement ex) latency_script.get_outputs_dir(id=\"main\")\n",
    "- `PERCENTILE` : the percentile for the tail latency ex) 0.95\n",
    "- `input_list` : the list of model names (should be the same for both latency measurement and accuracy measurement. does not include the suffix such as `_test_acc.pt` or `_times_tamp.log`\n",
    "- `acc_dir` : directory where the accuracy measurements are saved. use `get_{run_type}_output_dir` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e80a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics \n",
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys; sys.path.append('../runscripts')\n",
    "import constants\n",
    "import run_individual as acc_script\n",
    "import run_perf as latency_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b7fa94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set num trials based on number of trials used in perf_eval\n",
    "\n",
    "NUM_TRIALS = 3\n",
    "# LATENCY_DIR = os.path.abspath(os.path.join(os.path.abspath(os.getcwd()),\"..\",\"runscripts\",\"outputs_perf_eval\",\"main\"))\n",
    "LATENCY_DIR = latency_script.get_outputs_dir(id=\"main\")\n",
    "# Percentile to use for latency points\n",
    "PERCENTILE = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63517571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latency(model_name: str) -> List[float]:\n",
    "    '''\n",
    "    Return percentile latency for that model\n",
    "    '''\n",
    "\n",
    "    latencies = []\n",
    "    for j in range(1, NUM_TRIALS+1):\n",
    "        log_dir = os.path.join(LATENCY_DIR, \"Trial\"+str(j), model_name)\n",
    "#         log_dir = os.path.join(LATENCY_DIR, \"Trial\"+str(j), model_name+\"_time_stamp.log\")\n",
    "\n",
    "        if not os.path.isfile(log_dir):\n",
    "            print(log_dir, \"not found\")\n",
    "            return 'N/A'\n",
    "        data_file = pd.read_csv(log_dir,header=None)[0].tolist()\n",
    "        data = [x for x in data_file]\n",
    "        latencies.append(np.percentile(data, PERCENTILE))\n",
    "    return np.mean(latencies)\n",
    "    \n",
    "def get_accuracy(model_name: str, output_dir: Path) -> List[float]:\n",
    "    pt_file = model_name + '_test_acc.pt'\n",
    "    pt_file = output_dir / pt_file\n",
    "    if not os.path.isfile(pt_file):\n",
    "        return 'N/A'\n",
    "    acc = np.max(torch.load(pt_file))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "074bc0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_list(input_list,acc_output_dir):\n",
    "    for model_name in input_list:\n",
    "        acc, lat = get_accuracy(model_name, acc_output_dir), get_latency(model_name)\n",
    "        s='{model: <30} {acc: <20}  {lat: <20}'.format(model=model_name,acc=acc,lat=lat)\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8a606a",
   "metadata": {},
   "source": [
    "## Print latencies "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25be1a16",
   "metadata": {},
   "source": [
    "### vary encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60c5876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = [x.split(\"/\")[-1] for x in constants.VARY_ENCODER_LAYER]\n",
    "acc_dir = acc_script.get_layer_output_dir(id=\"11_12\")\n",
    "title = \"Accuracy - Latency for varying encoder layer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d3e5b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_uncased_L-2_H-768_A-12    0.8508928571428571  54.609611271999995  \n",
      "bert_uncased_L-4_H-768_A-12    0.8897321428571429  108.55607914133333  \n",
      "bert_uncased_L-6_H-768_A-12    0.8957589285714286  162.56444011733333  \n",
      "bert_uncased_L-8_H-768_A-12    0.9053571428571429  216.2380845253333   \n",
      "bert_uncased_L-10_H-768_A-12   0.9154017857142858  270.153784376       \n",
      "bert_uncased_L-12_H-768_A-12   0.9180803571428572  323.90019500266663  \n"
     ]
    }
   ],
   "source": [
    "print_list(input_list,acc_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde81197",
   "metadata": {},
   "source": [
    "### vary hidden dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "880686af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_uncased_L-12_H-128_A-2    0.8049107142857144    29.20371252         \n",
      "bert_uncased_L-12_H-256_A-4    0.8642857142857142    62.55714296266666   \n",
      "bert_uncased_L-12_H-512_A-8    N/A                   168.81853832533332  \n",
      "bert_uncased_L-12_H-768_A-12   N/A                   323.90019500266663  \n"
     ]
    }
   ],
   "source": [
    "input_list = [x.split(\"/\")[-1] for x in constants.VARY_HIDDEN_DIM]\n",
    "acc_dir = acc_script.get_hidden_dim_output_dir(id=\"11_12\")\n",
    "print_list(input_list,acc_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3626a0",
   "metadata": {},
   "source": [
    "### miniatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a109f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiny                           0.7823660714285714    5.170050047999999   \n",
      "mini                           0.8125                21.013924453333335  \n",
      "small                          0.8553571428571428    56.221618408000005  \n",
      "medium                         0.8883928571428571    112.52036641333332  \n",
      "base                           0.9180803571428572    324.0740922106666   \n",
      "large                          N/A                   1060.6418483626667  \n"
     ]
    }
   ],
   "source": [
    "input_list = [x.split(\"/\")[-1] for x in constants.VARY_MINIATURES.keys()]\n",
    "acc_dir = acc_script.get_miniature_output_dir(id=\"11_12\")\n",
    "print_list(input_list,acc_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868f33bd",
   "metadata": {},
   "source": [
    "### Elastic Attention Head -- this section is potentially outdated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5509d647",
   "metadata": {},
   "source": [
    "#### Head number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afb92432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_head_num_0.2         N/A                   269.459537856       \n",
      "attention_head_num_0.4         N/A                   275.395959976       \n",
      "attention_head_num_0.6         N/A                   273.905371152       \n",
      "attention_head_num_0.8         N/A                   274.76665103199997  \n",
      "attention_head_num_1.0         N/A                   273.58369588        \n"
     ]
    }
   ],
   "source": [
    "NUM_TRIALS = 1\n",
    "LATENCY_DIR = latency_script.get_outputs_dir(id=\"main\")\n",
    "attention_ratio_list=[i/constants.ATT_K for i in range(1,constants.ATT_K+1)]\n",
    "approach=\"head_num\"\n",
    "input_list=[\"attention_\" + str(approach) + \"_\" + str(attention_ratio) for attention_ratio in attention_ratio_list]\n",
    "acc_dir=Path(\"\")\n",
    "print_list(input_list,acc_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcea16d6",
   "metadata": {},
   "source": [
    "#### Head size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c29d3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_head_size_1_0.2      N/A                   272.12044126399996  \n",
      "attention_head_size_1_0.4      N/A                   283.77910764        \n",
      "attention_head_size_1_0.6      N/A                   291.67275775999997  \n",
      "attention_head_size_1_0.8      N/A                   294.28063163999997  \n",
      "attention_head_size_1_1.0      N/A                   300.534277096       \n"
     ]
    }
   ],
   "source": [
    "NUM_TRIALS = 1\n",
    "LATENCY_DIR = latency_script.get_outputs_dir(id=\"main\")\n",
    "attention_ratio_list=[i/constants.ATT_K for i in range(1,constants.ATT_K+1)]\n",
    "approach=\"head_size_1\"\n",
    "input_list=[\"attention_\" + str(approach) + \"_\" + str(attention_ratio) for attention_ratio in attention_ratio_list]\n",
    "acc_dir=Path(\"\")\n",
    "print_list(input_list,acc_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0e5a7f",
   "metadata": {},
   "source": [
    "#### Head size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d4dd405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_head_size_2_0.2      0.8375                728.003598624       \n",
      "attention_head_size_2_0.4      0.8340909090909091    789.0469323120001   \n",
      "attention_head_size_2_0.6      0.8318181818181818    849.7803931440001   \n",
      "attention_head_size_2_0.8      0.8386363636363636    938.621509016       \n",
      "attention_head_size_2_1.0      0.8375                1019.4757405839999  \n"
     ]
    }
   ],
   "source": [
    "NUM_TRIALS = 1\n",
    "LATENCY_DIR = latency_script.get_outputs_dir(id=\"main\")\n",
    "TAG=\"main\"\n",
    "attention_ratio_list=[i/constants.ATT_K for i in range(1,constants.ATT_K+1)]\n",
    "approach=\"head_size_2\"\n",
    "input_list=[\"attention_\" + str(approach) + \"_\" + str(attention_ratio) for attention_ratio in attention_ratio_list]\n",
    "acc_dir=acc_script.get_attention_output_dir(attention_approach=approach)\n",
    "# acc_dir=Path(\"\")\n",
    "print_list(input_list,acc_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1d1967",
   "metadata": {},
   "source": [
    "### Joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7329122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-large-uncased_layer_2_attention_0.2 0.8245535714285713    22.445771520000005  \n",
      "bert-large-uncased_layer_4_attention_0.4 0.8267857142857142    47.40298606933334   \n",
      "bert-large-uncased_layer_8_attention_0.6 0.8745535714285715    107.238931744       \n",
      "bert-large-uncased_layer_16_attention_0.8 0.9120535714285715    229.97596330666667  \n",
      "bert-large-uncased_layer_24_attention_1.0 0.9354910714285715    371.9971071946666   \n"
     ]
    }
   ],
   "source": [
    "NUM_TRIALS = 3\n",
    "attention_config=[0.2, 0.4, 0.6 ,0.8, 1.0]\n",
    "layer_config =[2 ,4, 8, 16, 24]\n",
    "LATENCY_DIR = latency_script.get_outputs_dir(id=\"main\")\n",
    "\n",
    "input_list= [\"bert-large-uncased\"+\"_layer_\" + str(layer_config[i])+\"_attention_\"+str(attention_config[i])for i in range(len(layer_config))]\n",
    "acc_dir=acc_script.get_joint_output_dir()\n",
    "print_list(input_list,acc_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa906970",
   "metadata": {},
   "source": [
    "## Scratch Work\n",
    "ignore below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "799134e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ilee300/workspace/ofa_transformers_runfiles/runscripts/outputs_perf_eval/test/Trial1/layer_2_time_stamp.log not found\n",
      "layer_2                        0.8388392857142858    N/A                 \n",
      "/home/ilee300/workspace/ofa_transformers_runfiles/runscripts/outputs_perf_eval/test/Trial1/layer_4_time_stamp.log not found\n",
      "layer_4                        0.8310267857142858    N/A                 \n",
      "/home/ilee300/workspace/ofa_transformers_runfiles/runscripts/outputs_perf_eval/test/Trial1/layer_6_time_stamp.log not found\n",
      "layer_6                        0.8357142857142856    N/A                 \n",
      "/home/ilee300/workspace/ofa_transformers_runfiles/runscripts/outputs_perf_eval/test/Trial1/layer_8_time_stamp.log not found\n",
      "layer_8                        0.8354910714285715    N/A                 \n",
      "/home/ilee300/workspace/ofa_transformers_runfiles/runscripts/outputs_perf_eval/test/Trial1/layer_10_time_stamp.log not found\n",
      "layer_10                       0.8377232142857143    N/A                 \n",
      "/home/ilee300/workspace/ofa_transformers_runfiles/runscripts/outputs_perf_eval/test/Trial1/layer_12_time_stamp.log not found\n",
      "layer_12                       0.8359375             N/A                 \n"
     ]
    }
   ],
   "source": [
    "## trained on the elastic attention heads branch.\n",
    "LATENCY_DIR = os.path.abspath(os.path.join(os.path.abspath(os.getcwd()),\"..\",\"runscripts\",\"outputs_perf_eval\",\"test\"))\n",
    "layer_list=[i for i in range(2,13,2)]\n",
    "input_list = [\"layer\" + \"_\" + str(i) for i in layer_list]\n",
    "acc_dir=acc_script.get_elastic_layer_output_dir(id=\"disparity_check_2\")\n",
    "print_list(input_list,acc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cacc34b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ilee300/workspace/ofa_transformers_runfiles/runscripts/outputs_perf_eval/test/Trial1/bert_uncased_L-2_H-768_A-12_time_stamp.log not found\n",
      "bert_uncased_L-2_H-768_A-12    0.8622767857142858    N/A                 \n",
      "/home/ilee300/workspace/ofa_transformers_runfiles/runscripts/outputs_perf_eval/test/Trial1/bert_uncased_L-4_H-768_A-12_time_stamp.log not found\n",
      "bert_uncased_L-4_H-768_A-12    0.8950892857142857    N/A                 \n",
      "/home/ilee300/workspace/ofa_transformers_runfiles/runscripts/outputs_perf_eval/test/Trial1/bert_uncased_L-6_H-768_A-12_time_stamp.log not found\n",
      "bert_uncased_L-6_H-768_A-12    0.9013392857142858    N/A                 \n",
      "/home/ilee300/workspace/ofa_transformers_runfiles/runscripts/outputs_perf_eval/test/Trial1/bert_uncased_L-8_H-768_A-12_time_stamp.log not found\n",
      "bert_uncased_L-8_H-768_A-12    0.9118303571428571    N/A                 \n",
      "/home/ilee300/workspace/ofa_transformers_runfiles/runscripts/outputs_perf_eval/test/Trial1/bert_uncased_L-10_H-768_A-12_time_stamp.log not found\n",
      "bert_uncased_L-10_H-768_A-12   0.9205357142857142    N/A                 \n",
      "/home/ilee300/workspace/ofa_transformers_runfiles/runscripts/outputs_perf_eval/test/Trial1/bert_uncased_L-12_H-768_A-12_time_stamp.log not found\n",
      "bert_uncased_L-12_H-768_A-12   0.9187500000000001    N/A                 \n"
     ]
    }
   ],
   "source": [
    "## trained on the master branch -> has elastic encoder layer\n",
    "input_list = [x.split(\"/\")[-1] for x in constants.VARY_ENCODER_LAYER]\n",
    "acc_dir = acc_script.get_layer_output_dir(id=\"disparity_check\")\n",
    "title = \"Accuracy - Latency for varying encoder layer\"\n",
    "print_list(input_list,acc_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f570ed3",
   "metadata": {},
   "source": [
    "Observation : when using ofa_transformers, the individual ones don't get trained fully. not sure why. probably cuase of attention layer? the master branch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be31d43e",
   "metadata": {},
   "source": [
    "Try training on the elastic layer branch in a weight shared fashion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
