{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "328d0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "# Preliminaries\n",
    "\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "\n",
    "# Models\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Training\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c95a663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c76de9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 15 13:05:36 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  On   | 00000000:1B:00.0 Off |                  N/A |\r\n",
      "| 33%   54C    P2   153W / 250W |   1573MiB / 11019MiB |     55%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 208...  On   | 00000000:1C:00.0 Off |                  N/A |\r\n",
      "| 31%   51C    P2   155W / 250W |   1573MiB / 11019MiB |     56%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  GeForce RTX 208...  On   | 00000000:1D:00.0 Off |                  N/A |\r\n",
      "| 23%   20C    P8     2W / 250W |     12MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  GeForce RTX 208...  On   | 00000000:1E:00.0 Off |                  N/A |\r\n",
      "| 29%   23C    P8    17W / 250W |     12MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   4  GeForce RTX 208...  On   | 00000000:B2:00.0 Off |                  N/A |\r\n",
      "| 24%   20C    P8    16W / 250W |     12MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   5  GeForce RTX 208...  On   | 00000000:B3:00.0 Off |                  N/A |\r\n",
      "| 24%   20C    P8     2W / 250W |     12MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   6  GeForce RTX 208...  On   | 00000000:B4:00.0 Off |                  N/A |\r\n",
      "| 24%   19C    P8     1W / 250W |     12MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   7  GeForce RTX 208...  On   | 00000000:B5:00.0 Off |                  N/A |\r\n",
      "| 24%   19C    P8    20W / 250W |     12MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     19137      C   python                                      1561MiB |\r\n",
      "|    1     19264      C   python                                      1561MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94febf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking time :  1629047136.9031153\n",
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "print(\"checking time : \" , time.time())\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b716e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = os.getcwd()\n",
    "\n",
    "source_folder = os.path.join(dirname,'../data/imdb')\n",
    "destination_folder =os.path.join(dirname,'../model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2658d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ilee300/workspace/nlp_ofa/transformers/notebooks/../data/imdb\n",
      "/home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model\n"
     ]
    }
   ],
   "source": [
    "## check source and desitnation folder\n",
    "print(source_folder)\n",
    "print(destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "939f7998",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58dd8fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Model parameter\n",
    "MAX_SEQ_LEN = 128\n",
    "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
    "\n",
    "# Fields\n",
    "\n",
    "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
    "text_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True,\n",
    "                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n",
    "# fields = [('label', label_field), ('title', text_field), ('text', text_field), ('titletext', text_field)]\n",
    "fields = [('text', text_field),('sentiment', label_field)]\n",
    "\n",
    "# TabularDataset\n",
    "\n",
    "train, valid, test = TabularDataset.splits(path=source_folder, train='train.csv', validation='valid.csv',\n",
    "                                           test='test.csv', format='CSV', fields=fields, skip_header=True)\n",
    "\n",
    "# Iterators\n",
    "\n",
    "train_iter = BucketIterator(train, batch_size=16, sort_key=lambda x: len(x.text),\n",
    "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
    "valid_iter = BucketIterator(valid, batch_size=16, sort_key=lambda x: len(x.text),\n",
    "                            device=device, train=True, sort=True, sort_within_batch=True)\n",
    "test_iter = Iterator(test, batch_size=16, device=device, train=False, shuffle=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee5b5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "\n",
    "        options_name = \"bert-base-uncased\"\n",
    "        self.encoder = BertForSequenceClassification.from_pretrained(options_name)\n",
    "\n",
    "    def forward(self, text, label):\n",
    "        loss, text_fea = self.encoder(text, labels=label)[:2]\n",
    "\n",
    "        return loss, text_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f6f520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_checkpoint(save_path, model, valid_loss):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_checkpoint(load_path, model):\n",
    "    \n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_metrics(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']\n",
    "\n",
    "def save_accuracy_log(save_path, train_accuracy_list, valid_accuracy_list, global_steps_list):\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_accuracy_list': train_accuracy_list,\n",
    "                  'valid_accuracy_list': valid_accuracy_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Accuracy log saved to ==> {save_path}')\n",
    "    \n",
    "def load_accuracy_log(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Accuracy log loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_accuracy_list'], state_dict['valid_accuracy_list'], state_dict['global_steps_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e57471a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "\n",
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.BCELoss(),\n",
    "          train_loader = train_iter,\n",
    "          valid_loader = valid_iter,\n",
    "          num_epochs = 5,\n",
    "          eval_every = len(train_iter) // 2,\n",
    "          file_path = destination_folder,\n",
    "          best_valid_loss = float(\"Inf\"),\n",
    "         max_encoder_num = None,\n",
    "         random_elasticity = False):\n",
    "    print(file_path + '/' +str(max_encoder_num)+ 'metrics.pt')\n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    \n",
    "    val_acc = 0.0\n",
    "    train_acc = 0.0\n",
    "    valid_accuracy_list = []\n",
    "    train_accuracy_list = []\n",
    "    val_y_pred = []\n",
    "    val_y_true = []\n",
    "    train_y_pred = []\n",
    "    train_y_true = []\n",
    "    \n",
    "    \n",
    "    if not random_elasticity:\n",
    "        if max_encoder_num is None:\n",
    "            max_encoder_num = model.encoder.config.num_hidden_layers\n",
    "        model.encoder.set_max_encoder_num(max_encoder_num)\n",
    "        print(\"training the model with encoder number of \" , max_encoder_num)\n",
    "\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        if random_elasticity:\n",
    "            max_encoder_num = random.randint(5,12)\n",
    "            model.encoder.set_max_encoder_num(max_encoder_num)\n",
    "            print(\"training for epoch \", epoch,\" with encoder number of \" , max_encoder_num)\n",
    "\n",
    "\n",
    "        for (text,sentiment), _ in train_loader:\n",
    "            text = text.type(torch.LongTensor)           \n",
    "            text = text.to(device)\n",
    "            sentiment = sentiment.type(torch.LongTensor)  \n",
    "            sentiment = sentiment.to(device)\n",
    "            output = model(text, sentiment)\n",
    "            loss, output = output\n",
    "            \n",
    "            ##update the prediction and true list.\n",
    "            train_y_pred.extend(torch.argmax(output, 1).tolist())\n",
    "            train_y_true.extend(sentiment.tolist())\n",
    "            train_acc +=accuracy_score(train_y_pred,train_y_true)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            \n",
    "            # update running values\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "                    \n",
    "            \n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_every == 0:\n",
    "                \n",
    "                \n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "\n",
    "                        \n",
    "                    # validation loop\n",
    "                    for (text,sentiment), _ in valid_loader:\n",
    "                        text = text.type(torch.LongTensor)           \n",
    "                        text = text.to(device)\n",
    "                        sentiment = sentiment.type(torch.LongTensor)  \n",
    "                        sentiment = sentiment.to(device)\n",
    "                        output = model(text, sentiment)\n",
    "                        loss, output = output\n",
    "                        \n",
    "                        valid_running_loss += loss.item()\n",
    "                        \n",
    "                        ##update the prediction and true list.\n",
    "                        val_y_pred.extend(torch.argmax(output, 1).tolist())\n",
    "                        val_y_true.extend(sentiment.tolist())\n",
    "                        val_acc += accuracy_score(val_y_pred,val_y_true)\n",
    "\n",
    "                # evaluation\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "                \n",
    "                average_train_accuracy = train_acc / eval_every\n",
    "                average_valid_accuracy = val_acc / eval_every\n",
    "                train_accuracy_list.append(average_train_accuracy)\n",
    "                valid_accuracy_list.append(average_valid_accuracy)\n",
    "                \n",
    "\n",
    "                # resetting running values\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                train_acc = 0.0\n",
    "                val_acc = 0.0\n",
    "                model.train()\n",
    "\n",
    "                # print progress\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                # checkpoint\n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    if random_elasticity:\n",
    "                        save_checkpoint(file_path + '/' +'random_elasticity_model.pt', model, best_valid_loss)\n",
    "                        save_metrics(file_path +  'random_elasticity_metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "                    else:\n",
    "                        save_checkpoint(file_path + '/' +str(max_encoder_num)+ 'model.pt', model, best_valid_loss)\n",
    "                        save_metrics(file_path + '/' + str(max_encoder_num)+ 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    if random_elasticity:\n",
    "        save_accuracy_log(file_path + '/' +'random_elasticity_acc_log.pt', train_accuracy_list, valid_accuracy_list, global_steps_list)\n",
    "        save_metrics(file_path +  'random_elasticity_metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "                    \n",
    "    save_metrics(file_path + '/' +str(max_encoder_num)+ 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    save_accuracy_log(file_path + '/' +str(max_encoder_num)+ 'acc_log.pt', train_accuracy_list, valid_accuracy_list, global_steps_list)\n",
    "\n",
    "    print('Finished Training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ae57bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "\n",
    "def evaluate(model, test_loader,max_encoder_num=None ):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    if max_encoder_num:\n",
    "        model.encoder.set_max_encoder_num(max_encoder_num)\n",
    "    else:\n",
    "        max_encoder_num = model.encoder.config.num_hidden_layers\n",
    "        model.encoder.set_max_encoder_num(model.encoder.config.num_hidden_layers)\n",
    "    \n",
    "    print(\"evaluating with max encoder number of \", max_encoder_num)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (text,sentiment), _ in test_loader:\n",
    "                text = text.type(torch.LongTensor)           \n",
    "                text = text.to(device)\n",
    "                sentiment = sentiment.type(torch.LongTensor)  \n",
    "                sentiment = sentiment.to(device)\n",
    "                output = model(text, sentiment)\n",
    "\n",
    "                _, output = output\n",
    "                y_pred.extend(torch.argmax(output, 1).tolist())\n",
    "                y_true.extend(sentiment.tolist())\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['NEG', 'POS'])\n",
    "    ax.yaxis.set_ticklabels(['NEG', 'POS'])\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    return accuracy_score(y_pred,y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1954cc69",
   "metadata": {},
   "source": [
    "## Train BERT with layers 5 - 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b2c0719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/9metrics.pt\n",
      "changing encoder number :  12  =>  9\n",
      "training the model with encoder number of  9\n",
      "Epoch [1/5], Step [625/6250], Train Loss: 0.3591, Valid Loss: 0.3758\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/9model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/9metrics.pt\n",
      "Epoch [1/5], Step [1250/6250], Train Loss: 0.4043, Valid Loss: 0.3458\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/9model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/9metrics.pt\n",
      "Epoch [2/5], Step [1875/6250], Train Loss: 0.1599, Valid Loss: 0.4415\n",
      "Epoch [2/5], Step [2500/6250], Train Loss: 0.2572, Valid Loss: 0.3420\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/9model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/9metrics.pt\n",
      "Epoch [3/5], Step [3125/6250], Train Loss: 0.0840, Valid Loss: 0.4585\n",
      "Epoch [3/5], Step [3750/6250], Train Loss: 0.1423, Valid Loss: 0.5261\n",
      "Epoch [4/5], Step [4375/6250], Train Loss: 0.0486, Valid Loss: 0.5106\n",
      "Epoch [4/5], Step [5000/6250], Train Loss: 0.0818, Valid Loss: 0.7013\n",
      "Epoch [5/5], Step [5625/6250], Train Loss: 0.0405, Valid Loss: 0.5494\n",
      "Epoch [5/5], Step [6250/6250], Train Loss: 0.0542, Valid Loss: 0.6649\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/9metrics.pt\n",
      "Accuracy log saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/9acc_log.pt\n",
      "Finished Training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model trained with 9 number of layers\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/9model.pt\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8966    0.8002    0.8456     12500\n",
      "           0     0.8196    0.9077    0.8614     12500\n",
      "\n",
      "    accuracy                         0.8539     25000\n",
      "   macro avg     0.8581    0.8539    0.8535     25000\n",
      "weighted avg     0.8581    0.8539    0.8535     25000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/10metrics.pt\n",
      "changing encoder number :  12  =>  10\n",
      "training the model with encoder number of  10\n",
      "Epoch [1/5], Step [625/6250], Train Loss: 0.3607, Valid Loss: 0.3874\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/10model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/10metrics.pt\n",
      "Epoch [1/5], Step [1250/6250], Train Loss: 0.3971, Valid Loss: 0.3445\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/10model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/10metrics.pt\n",
      "Epoch [2/5], Step [1875/6250], Train Loss: 0.1629, Valid Loss: 0.3975\n",
      "Epoch [2/5], Step [2500/6250], Train Loss: 0.2485, Valid Loss: 0.3390\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/10model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/10metrics.pt\n",
      "Epoch [3/5], Step [3125/6250], Train Loss: 0.0824, Valid Loss: 0.4409\n",
      "Epoch [3/5], Step [3750/6250], Train Loss: 0.1440, Valid Loss: 0.5405\n",
      "Epoch [4/5], Step [4375/6250], Train Loss: 0.0556, Valid Loss: 0.4746\n",
      "Epoch [4/5], Step [5000/6250], Train Loss: 0.0764, Valid Loss: 0.6695\n",
      "Epoch [5/5], Step [5625/6250], Train Loss: 0.0384, Valid Loss: 0.5456\n",
      "Epoch [5/5], Step [6250/6250], Train Loss: 0.0586, Valid Loss: 0.5160\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/10metrics.pt\n",
      "Accuracy log saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/10acc_log.pt\n",
      "Finished Training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model trained with 10 number of layers\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/10model.pt\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9167    0.7665    0.8349     12500\n",
      "           0     0.7994    0.9303    0.8599     12500\n",
      "\n",
      "    accuracy                         0.8484     25000\n",
      "   macro avg     0.8580    0.8484    0.8474     25000\n",
      "weighted avg     0.8580    0.8484    0.8474     25000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/11metrics.pt\n",
      "changing encoder number :  12  =>  11\n",
      "training the model with encoder number of  11\n",
      "Epoch [1/5], Step [625/6250], Train Loss: 0.3271, Valid Loss: 0.3991\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/11model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/11metrics.pt\n",
      "Epoch [1/5], Step [1250/6250], Train Loss: 0.3944, Valid Loss: 0.3220\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/11model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/11metrics.pt\n",
      "Epoch [2/5], Step [1875/6250], Train Loss: 0.1515, Valid Loss: 0.4018\n",
      "Epoch [2/5], Step [2500/6250], Train Loss: 0.2551, Valid Loss: 0.3203\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/11model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/11metrics.pt\n",
      "Epoch [3/5], Step [3125/6250], Train Loss: 0.0773, Valid Loss: 0.4614\n",
      "Epoch [3/5], Step [3750/6250], Train Loss: 0.1299, Valid Loss: 0.5370\n",
      "Epoch [4/5], Step [4375/6250], Train Loss: 0.0513, Valid Loss: 0.4875\n",
      "Epoch [4/5], Step [5000/6250], Train Loss: 0.0849, Valid Loss: 0.4552\n",
      "Epoch [5/5], Step [5625/6250], Train Loss: 0.0409, Valid Loss: 0.5269\n",
      "Epoch [5/5], Step [6250/6250], Train Loss: 0.0636, Valid Loss: 0.5316\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/11metrics.pt\n",
      "Accuracy log saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/11acc_log.pt\n",
      "Finished Training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model trained with 11 number of layers\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/11model.pt\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8973    0.8055    0.8490     12500\n",
      "           0     0.8236    0.9078    0.8637     12500\n",
      "\n",
      "    accuracy                         0.8567     25000\n",
      "   macro avg     0.8605    0.8567    0.8563     25000\n",
      "weighted avg     0.8605    0.8567    0.8563     25000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/12metrics.pt\n",
      "changing encoder number :  12  =>  12\n",
      "training the model with encoder number of  12\n",
      "Epoch [1/5], Step [625/6250], Train Loss: 0.3482, Valid Loss: 0.3467\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/12model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/12metrics.pt\n",
      "Epoch [1/5], Step [1250/6250], Train Loss: 0.3923, Valid Loss: 0.3513\n",
      "Epoch [2/5], Step [1875/6250], Train Loss: 0.1594, Valid Loss: 0.4179\n",
      "Epoch [2/5], Step [2500/6250], Train Loss: 0.2437, Valid Loss: 0.3488\n",
      "Epoch [3/5], Step [3125/6250], Train Loss: 0.0807, Valid Loss: 0.5636\n",
      "Epoch [3/5], Step [3750/6250], Train Loss: 0.1402, Valid Loss: 0.5340\n",
      "Epoch [4/5], Step [4375/6250], Train Loss: 0.0583, Valid Loss: 0.5249\n",
      "Epoch [4/5], Step [5000/6250], Train Loss: 0.0818, Valid Loss: 0.5152\n",
      "Epoch [5/5], Step [5625/6250], Train Loss: 0.0322, Valid Loss: 0.5689\n",
      "Epoch [5/5], Step [6250/6250], Train Loss: 0.0599, Valid Loss: 0.6232\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/12metrics.pt\n",
      "Accuracy log saved to ==> /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/12acc_log.pt\n",
      "Finished Training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model trained with 12 number of layers\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/transformers/notebooks/../model/12model.pt\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7961    0.9384    0.8614     12500\n",
      "           0     0.9250    0.7596    0.8342     12500\n",
      "\n",
      "    accuracy                         0.8490     25000\n",
      "   macro avg     0.8605    0.8490    0.8478     25000\n",
      "weighted avg     0.8605    0.8490    0.8478     25000\n",
      "\n",
      "{9: 0.85392, 10: 0.8484, 11: 0.85668, 12: 0.849}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_dict = {}\n",
    "for i in range(9,13):\n",
    "    model = BERT().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "    train(model=model, optimizer=optimizer, num_epochs=5,max_encoder_num=i)\n",
    "    best_model = BERT().to(device)\n",
    "    print(\"loading model trained with \" + str(i) + \" number of layers\")\n",
    "    load_checkpoint(destination_folder +\"/\"+ str(i)+ 'model.pt', best_model)\n",
    "    acc = evaluate(best_model, test_iter, max_encoder_num=i)\n",
    "    acc_dict[i] = acc\n",
    "print(acc_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e758f9f",
   "metadata": {},
   "source": [
    "## Train Plain BERT base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5731148a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing bertforsequenceclassification\n",
      "initializing weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.10.0.dev0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERT().to(device)\n",
    "model.encoder.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3119dcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ilee300/workspace/nlp_ofa/notebooks/../model/Nonemetrics.pt\n",
      "changing encoder number :  12  =>  12\n",
      "training the model with encoder number of  12\n",
      "Epoch [1/8], Step [625/10000], Train Loss: 0.2726, Valid Loss: 0.3753\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/12model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/12metrics.pt\n",
      "Epoch [1/8], Step [1250/10000], Train Loss: 0.3955, Valid Loss: 0.3486\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/12model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/12metrics.pt\n",
      "Epoch [2/8], Step [1875/10000], Train Loss: 0.1538, Valid Loss: 0.4097\n",
      "Epoch [2/8], Step [2500/10000], Train Loss: 0.2558, Valid Loss: 0.3479\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/12model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/12metrics.pt\n",
      "Epoch [3/8], Step [3125/10000], Train Loss: 0.0800, Valid Loss: 0.4570\n",
      "Epoch [3/8], Step [3750/10000], Train Loss: 0.1499, Valid Loss: 0.4259\n",
      "Epoch [4/8], Step [4375/10000], Train Loss: 0.0535, Valid Loss: 0.4650\n",
      "Epoch [4/8], Step [5000/10000], Train Loss: 0.0951, Valid Loss: 0.5068\n",
      "Epoch [5/8], Step [5625/10000], Train Loss: 0.0391, Valid Loss: 0.5054\n",
      "Epoch [5/8], Step [6250/10000], Train Loss: 0.0697, Valid Loss: 0.4290\n",
      "Epoch [6/8], Step [6875/10000], Train Loss: 0.0240, Valid Loss: 0.5847\n",
      "Epoch [6/8], Step [7500/10000], Train Loss: 0.0547, Valid Loss: 0.5900\n",
      "Epoch [7/8], Step [8125/10000], Train Loss: 0.0235, Valid Loss: 0.6049\n",
      "Epoch [7/8], Step [8750/10000], Train Loss: 0.0473, Valid Loss: 0.5486\n",
      "Epoch [8/8], Step [9375/10000], Train Loss: 0.0206, Valid Loss: 0.6323\n",
      "Epoch [8/8], Step [10000/10000], Train Loss: 0.0295, Valid Loss: 0.5632\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/12metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/12acc_log.pt\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "## Train Plain BERT base model -> 8 Epochs, using 12 encoder layers\n",
    "model = BERT().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "train(model=model, optimizer=optimizer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3de21ca0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing bertforsequenceclassification\n",
      "initializing weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/notebooks/../model/12model.pt\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9214    0.7457    0.8243     12500\n",
      "           0     0.7864    0.9364    0.8549     12500\n",
      "\n",
      "    accuracy                         0.8410     25000\n",
      "   macro avg     0.8539    0.8410    0.8396     25000\n",
      "weighted avg     0.8539    0.8410    0.8396     25000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEWCAYAAACHVDePAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmQklEQVR4nO3dd5xV1bn/8c+XJijdTjGooBE1KhYQy7UFgWgs0Wg0iuVeorHFmGtJ/IWI3WhMvBpzsUWNohixxQJcRY0VEFEDRsWCgGIBBARRyvP7Y68hh8nMcGaYc2bmnO/b13nN3mvvvfZzAJ+zZu111lJEYGZmpa1ZQwdgZmaF52RvZlYGnOzNzMqAk72ZWRlwsjczKwNO9mZmZcDJ3taapDaSHpG0QNJ9a1HPsZLG1mdsDUHS45KGNHQcZrmc7MuIpGMkTZL0paSPU1Lasx6qPgLYGFg/Io6sayURcVdEDKiHeFYjaR9JIemBSuU7pPKn86znN5L+sqbzImJQRNxex3DNCsLJvkxI+jnwe+AyssS8GfBH4JB6qP5bwNsRsbwe6iqUz4DdJa2fUzYEeLu+bqCM/5+yRsn/MMuApA7AcOC0iBgdEYsjYllEPBIR/53OWUfS7yV9lF6/l7ROOraPpFmSzpH0afqt4MR07CLg18BR6TeGkyu3gCX1SC3oFmn/BEnvSVok6X1Jx+aUP5dzXX9JE1P30ERJ/XOOPS3pYknPp3rGStqghj+Gb4AHgaPT9c2Bo4C7Kv1Z/UHSTEkLJb0iaa9UPhD4Zc77fC0njkslPQ8sAbZIZf+Zjt8o6f6c+q+U9KQk5fv3Z1YfnOzLw+5Aa+CBGs75FdAP2BHYAdgNuDDn+CZAB6ArcDJwg6ROETGM7LeFeyOibUTcUlMgktYDrgMGRUQ7oD8wpYrzOgOPpnPXB34HPFqpZX4McCKwEdAK+EVN9wbuAI5P2wcC/wA+qnTORLI/g87A3cB9klpHxBOV3ucOOdccBwwF2gEzKtV3DrB9+iDbi+zPbkh4nhIrMif78rA+8PkaulmOBYZHxKcR8RlwEVkSq7AsHV8WEY8BXwJb1zGelcB2ktpExMcRMbWKc74HvBMRd0bE8ogYCfwTODjnnNsi4u2I+AoYRZakqxURLwCdJW1NlvTvqOKcv0TE3HTPa4B1WPP7/HNETE3XLKtU3xKyP8ffAX8BzoiIWWuoz6zeOdmXh7nABhXdKNXowuqt0hmpbFUdlT4slgBtaxtIRCwm6z45BfhY0qOSvp1HPBUxdc3Zn1OHeO4ETgf2pYrfdCT9QtKbqevoC7LfZmrqHgKYWdPBiHgZeA8Q2YeSWdE52ZeHF4GvgUNrOOcjsgetFTbj37s48rUYWDdnf5PcgxExJiK+C2xK1lq/KY94KmKaXceYKtwJ/BR4LLW6V0ndLOcCPwQ6RURHYAFZkgaoruulxi4ZSaeR/YbwUarfrOic7MtARCwge4h6g6RDJa0rqaWkQZKuSqeNBC6UtGF60Plrsm6HupgC7C1ps/Rw+IKKA5I2lnRI6rv/mqw7aGUVdTwGbJWGi7aQdBTQG/hbHWMCICLeB/6D7BlFZe2A5WQjd1pI+jXQPuf4J0CP2oy4kbQVcAnwY7LunHMl7Vi36M3qzsm+TKT+55+TPXT9jKzr4XSyESqQJaRJwOvAG8DkVFaXe40D7k11vcLqCbpZiuMjYB5Z4j21ijrmAgeRPeCcS9YiPigiPq9LTJXqfi4iqvqtZQzwBNlwzBnAUlbvoqn4wthcSZPXdJ/UbfYX4MqIeC0i3iEb0XNnxUgns2KRBwWYmZU+t+zNzMqAk72ZWRlwsjczKwNO9mZmZaCmL9k0qK6nPuAnx/ZvHjlv/4YOwRqhPj3ar/VcQ212Oj3vnPPVq9c3ubmNGm2yNzMrqhKfsNTJ3swMoMQnInWyNzMDt+zNzMqCW/ZmZmWgWfOGjqCgnOzNzMDdOGZmZcHdOGZmZcAtezOzMuCWvZlZGXDL3sysDHg0jplZGXDL3sysDDRzn72ZWelzy97MrAx4NI6ZWRnwA1ozszLgbhwzszLgbhwzszLglr2ZWRlwy97MrAy4ZW9mVgY8GsfMrAy4ZW9mVgbcZ29mVgbcsjczKwNu2ZuZlQG37M3MSp+aOdmbmZU8uRvHzKwMlHaup7R/bzEzy5OkvF951HWrpE8l/SOnrLOkcZLeST87pXJJuk7SdEmvS+qTc82QdP47kobklO8s6Y10zXXKIygnezMz6jfZA38GBlYqOx94MiJ6AU+mfYBBQK/0GgrcmOLpDAwD+gK7AcMqPiDSOf+Vc13le/0bJ3szM6BZs2Z5v9YkIp4F5lUqPgS4PW3fDhyaU35HZF4COkraFDgQGBcR8yJiPjAOGJiOtY+IlyIigDty6qr+/a0xajOzcqD8X5KGSpqU8xqaxx02joiP0/YcYOO03RWYmXPerFRWU/msKspr5Ae0ZmbUbjRORIwARtT1XhERkqKu19eFW/ZmZtR7n31VPkldMKSfn6by2UD3nPO6pbKayrtVUV4jJ3szM4qS7B8GKkbUDAEeyik/Po3K6QcsSN09Y4ABkjqlB7MDgDHp2EJJ/dIonONz6qqWu3HMzKjfL1VJGgnsA2wgaRbZqJorgFGSTgZmAD9Mpz8GDAamA0uAEwEiYp6ki4GJ6bzhEVHx0PenZCN+2gCPp1eNnOzNzAA1q79kHxE/qubQ/lWcG8Bp1dRzK3BrFeWTgO1qE5OTvZkZni7BzKwsONmbmZWD0s71TvZmZuCWvZlZWXCyNzMrA/nMedOUOdmbmYH77M3MyoG7cczMyoCTvZlZGXCyNzMrA/U5XUJj5GTfQE7ed0uO2bMHAu5+/gNufupd/vvgbRjwnU2JCD5f9DVn3zGZTxYs5bBdu/HTAVshweKly7lg5BSmzV4IwDXH9eGA7Tfh80Vfs//FTzbsm7K18s03XzP8nKEsW7aMFSuW03ev/Tny+J8w5qFRPP7ASD75eBb/O2oc7Tt0BOCR++7k+aey+a9WrFjB7JkfMOLesbRt34HHHxjJU48/SESw36BDGXz4MQ34zpoGt+yt3m3dpR3H7NmD713xNMtWrOSuM/rzf2/M4cZx7/DbR94E4KR9t+Dswd/m/JFTmDl3CUdc+3cWLFnGvttuzJXH7sTBVz0DwKgXZ3Db0+/yhxN2aci3ZPWgZctWXHjVjbRusy7Lly/nNz//T3bctT9bbbsDffruyfBzT1nt/IOPPI6DjzwOgFdeepbHRo+kbfsOzPxgOk89/iCXXHc7LVq24IpfnkmfvnuxSdfuVd3WklJP9qU9sLSR6rVJO159fx5Ll61gxcrgpbc/Z9COXfhy6fJV56zbqgVBtpDNpPfmsWDJMgAmvz+PTTu1WXXey9Pn8sXiZcV9A1YQkmjdZl0AVixfzooVy5HE5j23ZsNNutR47Qvjx9J/nwEAzP7wA3p+ezvWad2a5s1bsM13+jDh+fEFj7+pK8J89g2qIMle0raSvp+zf62kW9OrTyHu2ZT886NF9O25AZ3Wa0Xrls3Zb7tN6JIS+Hnf783ESw/ksN26r2rl5zq6/7cYP/WTYodsRbJyxQrOP/UYfnLUALbfqS89v73mWWy/XrqU1ya9SN899wOge48t+ec/prBo4Rd8vXQpUya+wNzP/G9mjWqxBm1TVKiW/RXA5zn7BwKPAuOBX1d3Ue4ivounjS1QaA1v+pxF3DD2be4+sz93ndGfqbO+YGVkrfgrH57Grr8awwMTZnLiPlusdl3/rTbgR/17cNkDUxsibCuCZs2bc8WNd3PDXY/y7ltTmfnB9DVeM/mlZ9l62+/Qtn0HALputjnf/+HxXH7BGVzxqzP51hZblfy3Q+uDW/Z1s2lEvJCzvzAi7o+IO4ENqrsoIkZExC4Rsct6vQcUKLTG4Z4XZjDo8qf5we+yvvj3PvlyteOjJ8xk8E7/WjB+m67t+e2Pd+KkP73E/MXfFDtcK7L12raj9w4789rEF9d47gvPjKP/PgeuVrbvwEO47IY7GXbNCNZr245Nu21WqFBLRrNmyvvVFBUq2bfL3YmIfjm7GxXonk3K+u1aAdClUxsG7diFBybOYvMN11t1/MAdNuXdOYtWnXPT0L6c9edXeO/TL6usz5q+hV/MZ/GX2d/5N18v5Y3JE+jSvUeN1yxZ/CVvvj6Znfv/x2rlC77IVq/7/NM5THx+PHvsO7AgMZeSUm/ZF2o0zkeS+kbEy7mFaTHdjwp0zyblpqF96bReK5avCH51z2ss/GoZVx+3E1tu3I6VK4PZ85Zw/t1TADj7e9+mU9tWXHb0DgAsXxkMvuJpAG44aRd232pDOrdtxaTLBnL1397knhdmNNC7srUxf97n3Hj1b1i5ciWxciX99j6APv324okH7+GR++7ki3lzOe+UH7HTbnsw9OwLAZj4/Hi+s3NfWrdus1pd1w4/jy8XLaB58xacePq5rNe2XVW3tBxNNIfnTZH6iuu1Umk34F6yBXEnp+KdyVZUPyoiJqypjq6nPlD/gVmT98h5/7aEpxl9erRf61S99Xlj8s45b115YJP7aChIN05K5n2B5sAJ6dUM6JdPojczKzYp/1dTVJBuHEntI+JTqhh5I2mziPiwEPc1M6urpvrgNV+FekD7dMWGpMrf4X+wQPc0M6uzUh+NU6gHtLl/Gp1rOGZm1ig01e6ZfBUq2Uc121Xtm5k1uKY6pDJfhUr2G0n6OVkrvmKbtL9hge5pZlZnTvZ1cxP/+mJV7jbAzQW6p5lZnZV4ri9Mso+IiwpRr5lZoTTVB6/5KtTQy2onOwMiIi4uxH3NzOrK3Th1s7iKsvWAk4H1ASd7M2tUSjzXF6wb55qKbUntgLOAE4F7gGuqu87MrKGUesu+YJNcS+os6RLgdbIPlT4RcV76Zq2ZWaNSn9MlSDpb0lRJ/5A0UlJrSZtLelnSdEn3SmqVzl0n7U9Px3vk1HNBKn9L0oHV3jAPhVqp6rfARGARsH1E/CYi5hfiXmZm9aG+pjiW1BU4E9glIrYjmyPsaOBK4NqI6AnMJ+vWJv2cn8qvTechqXe6bltgIPBHSc3r+v4K1bI/B+gCXEg23fHC9FokaWGB7mlmVmf1PF1CC6CNpBbAusDHwH7AX9Px24FD0/YhaZ90fH9lnyiHAPdExNcR8T4wHditru+vUH32XgPNzJqU2nTZSxoKDM0pGhERIwAiYrakq4EPga+AscArwBcRsTydPwuoWIquKzAzXbtc0gKygSxdgZdy7pF7Ta0VajSOmVmTUpsHtCmxj6imnk5krfLNgS+A+8i6YRqUW+BmZtTrA9oDgPcj4rOIWAaMBvYAOqZuHYBuwOy0PRvonsWgFkAHYG5ueRXX1JqTvZkZ9boG7YdAP0nrpr73/YFpwHjgiHTOEOChtP1w2icdfyqyJQQfBo5Oo3U2B3oBdV78yd04ZmbU3zj7iHhZ0l/JlmRdDrxK1uXzKHBPGpL+KnBLuuQW4E5J04F5ZCNwiIipkkaRfVAsB06LiBV1jcvJ3syM+p0bJyKGAcMqFb9HFaNpImIpcGQ19VwKXFofMTnZm5nh6RLMzMpCqU+X4GRvZkbpt+zXOBpH0lmS2itzi6TJkgYUIzgzs2JpJuX9aoryGXp5UkQsBAYAnYDjgCsKGpWZWZHV83QJjU4+3TgV72wwcGcaDtQ0362ZWTWaaA7PWz7J/hVJY8m++ntBmp9+ZWHDMjMrrlJvw+aT7E8GdgTei4glktYnW4jEzKxklHiurz7ZS+pTqWiLUv/kM7PyJUo7v9XUsq9p+cAgm5vZzKwklG2ffUTsW8xAzMwaUlMdZZOvfMbZryvpQkkj0n4vSQcVPjQzs+LxOHu4DfgG6J/2ZwOXFCwiM7MGUJ8LjjdG+ST7LSPiKmAZQEQsgRJ/kmFmZace57NvlPIZevmNpDZkD2WRtCXwdUGjMjMrsiaaw/OWT7IfBjwBdJd0F9nyWicUMigzs2JrXuLZfo3JPiLGSZoM9CPrvjkrIj4veGRmZkXUVLtn8pXvFMf/AexJ1pXTEnigYBGZmTWAEh95ueZkL+mPQE9gZCr6iaQDIuK0gkZmZlZEbtln35TdJq12jqTbgakFjcrMrMhKPNfnNfRyOrBZzn73VGZmVjLKduilpEfI+ujbAW9KmpD2+wITihOemVlxNC/xTvuaunGuLloUZmYNrLRTfc0ToT1TzEDMzBpSU53zJl/5TITWT9JESV9K+kbSCkkLixGcmVmxlPrcOPmMxrkeOBq4D9gFOB7YqpBBmZkVW1N98JqvfEbjEBHTgeYRsSIibgMGFjYsM7PicsselkhqBUyRdBXwMXl+SJiZNRWlPhonn6R9XDrvdGAx2Tj7wwsZlJlZsZXtOPsKETEjbS4FLgKQdC9wVAHj4t3/OayQ1VsT1WnX0xs6BGuEvnr1+rWuo9S7K/KdCK2y3es1CjOzBtZUW+z5KvUPMzOzvDRT/q81kdRR0l8l/VPSm5J2l9RZ0jhJ76SfndK5knSdpOmSXpfUJ6eeIen8dyQNWZv3V9N0CX2qO0Q2zbGZWcmo5we0fwCeiIgj0gCXdYFfAk9GxBWSzgfOB84DBgG90qsvcCPQV1JnssWjdiGbquYVSQ9HxPy6BFRTN841NRz7Z11uZmbWWNVXrpfUAdibtKJfRHxDtrzrIcA+6bTbgafJkv0hwB1pZuGX0m8Fm6Zzx0XEvFTvOLJh7xXTzddKTdMl7FuXCs3MmqLadNlLGgoMzSkaEREj0vbmwGfAbZJ2AF4BzgI2joiP0zlzgI3TdldgZk5ds1JZdeV1UtcHtGZmJaU2c+OkxD6imsMtgD7AGRHxsqQ/kHXZ5F4fkqKusdaFH9CamZElw3xfazALmBURL6f9v5Il/09S9wzp56fp+Gyy7y9V6JbKqiuvEyd7MzPqb7qEiJgDzJS0dSraH5gGPAxUjKgZAjyUth8Gjk+jcvoBC1J3zxhggKROaeTOgFRWJ/msQSvgWGCLiBguaTNgk4jwAiZmVjLqeTTOGcBdaSTOe8CJZI3rUZJOBmYAP0znPgYMJlsBcEk6l4iYJ+liYGI6b3jFw9q6yKfP/o/ASrK1aIcDi4D7gV3relMzs8amPnN9REwhGzJZ2f5VnBvAadXUcytwa33ElE+y7xsRfSS9mm4+P31amZmVjFJfvCSfZL9MUnOyQf1I2pCspW9mVjJKPNfnleyvAx4ANpJ0KXAEcGFBozIzK7ISn+E4r1kv75L0Cllfk4BDI+LNgkdmZlZEKvElx/MZjbMZ2RPiR3LLIuLDQgZmZlZMLUp8IHo+3TiPkvXXC2hN9lXgt4BtCxiXmVlRlfoUx/l042yfu59mw/xpwSIyM2sAZd9nX1lETJbUtxDBmJk1lBJv2OfVZ//znN1mZHM8fFSwiMzMGoDH2UO7nO3lZH349xcmHDOzhtG8nB/Qpi9TtYuIXxQpHjOzBtGsXIdeSmoREcsl7VHMgMzMGkKJ9+LU2LKfQNY/P0XSw8B9wOKKgxExusCxmZkVjUfjZGPr55LNelkx3j4AJ3szKxnl/IB2ozQS5x/8K8lXKOpyWmZmhVbiub7GZN8caAtVPrVwsjezklLPi5c0OjUl+48jYnjRIjEza0AlPvKyxmRf2h9zZmY5ynlunH9bPsvMrFSVdqqvIdmvzcK2ZmZNTTmPxjEzKxulneqd7M3MAGhWxqNxzMzKRjmPxjEzKxvlPBrHzKxslHaqd7I3MwPcsjczKwvNnezNzEpfaad6J3szM6C8Z700MysbZbssoZlZOSn1ln2pf4/AzCwvqsV/edUnNZf0qqS/pf3NJb0sabqkeyW1SuXrpP3p6XiPnDouSOVvSTpwbd6fk72ZGdlonHxfeToLeDNn/0rg2ojoCcwHTk7lJwPzU/m16Twk9QaOBrYFBgJ/lNS8ru/Pyd7MjKwbJ9/XmutSN+B7wM1pX2TreP81nXI7cGjaPiTtk47vn84/BLgnIr6OiPeB6cBudX1/TvZmZtQu2UsaKmlSzmtopep+D5wLrEz76wNfRMTytD8L6Jq2uwIzAdLxBen8VeVVXFNrfkBrZgZ598UDRMQIYESV9UgHAZ9GxCuS9qmX4OqBk72ZGVCPMxzvAXxf0mCgNdAe+APQUVKL1HrvBsxO588GugOzJLUAOgBzc8or5F5Ta+7GMTMjW6kq31dNIuKCiOgWET3IHrA+FRHHAuOBI9JpQ4CH0vbDaZ90/KmIiFR+dBqtsznQC5hQ1/fnlr2ZGbXrxqmj84B7JF0CvArckspvAe6UNB2YR/YBQURMlTQKmAYsB06LiBV1vbmTfQP74P33OPecs1ftz5o1k5+efia77taPS4YPY8mSJXTp0pXLr7qatm3bMnv2LA47eDA9emwOwPY77MD/Gza8ocK3tfSnYccyaO/t+GzeInY58jIADj9gJ351ymC+vfnG7HXc1Uye9iEARw/ahZ8NOWDVtdv36sLuP7qS19+ezU7bdGfERcfRZp2WjHl+KudclQ36+NVPBnPS4f35bP6XAAy7/mHGPDetyO+yaSjEQlUR8TTwdNp+jypG00TEUuDIaq6/FLi0PmJxsm9gPTbfglGjs9/mVqxYwXf33Zv9Dvguv/jZmfz8v89jl11344HRf+XPt97M6Wf+DIBu3TdbdY01bXc+8hJ/uvcZbr74+FVlU9/9iKPPuYnrL/zRaufe8/gk7nl8EgDb9uzCqN/9F6+/nXXhXvfLozjt4ruZ8MYHPHj9qQzYozdjn8+S+v/8ZTy/v/PJIr2jpqsILfsG5T77RuTll16ke/fudOnSlRkzPmDnXXYFYPfd9+DJcWMbODorhOcnv8u8BUtWK3vr/U94Z8anNV73w4E7c9+YyQBsskF72q3XmglvfADA3X+bwMH7fKcg8Zay+hxn3xgVJNlLWldSy5z9rSWdLenwQtyvVDzx+KMMHHwQAFv27MX4p7LW2NgxTzBnzserzps9exY//MGhnDTkx0x+ZVKDxGoN64gBfRj1RPZ332Wjjsz+9ItVx2Z/8gVdNuq4av+Uo/dmwr0X8Kdhx9KxXZsiR9p0qBavpqhQLfsngB4AknoCLwJbAKdJury6i3K/qHDLTVUOYS1Zy775hmfGP8WAAwcCcNHFl3LvPXdz9JGHs2TJYlq2bAXAhhtuxJj/G8+o+x/kF+eez/nnnsOXX37ZkKFbke263bdYsnQZ0979eI3n3nTf3+l98G/oe/QVzPl8IVf83O2t6hRguoRGpVB99p0i4p20PQQYGRFnpIl/XgEuqOqi3C8qLF1OFCi2Rum5557l2723Zf0NNgBg8y225H9vuhWADz54n2efeRqAVq1a0apVlvh7b7sd3btvxowP3mfb7bZvkLit+I48cOdVrXqAjz79gq45LfmuG3fko9TS/3TeolXlt45+ntHXnVKsMJueppnD81aoln1uot4PGAcQEd/wr68PW47HH3uUQYO/t2p/7ty5AKxcuZKb/vdGjjzqaADmzZvHihXZ6KtZM2cyY8YHdOvW/d8rtJIkiR8M6MN9Y15ZVTbn84UsWryU3bbvAcAxB+3G3555Hcj68yscst8Oef02UK7qe9bLxqZQLfvXJV1N9m2vnsBYAEkdC3S/Jm3JkiW89MILqw2hfOKxv3HPyLsB2P+A73LoYT8AYPKkidxw/XW0bNECNWvGhb++iA4dOzZE2FYPbr/8BPbauRcbdGzL9Ccu5uI/Pcb8BYv53XlHskGntoy+7hRef2s23z/tBgD27NOTWXPm88HsuavVc9bloxhx0Y9ps05Lxj4/bdXwykvPOpTvbN2NiGDGx/M445KRRX+PTUUT7Z3Jm7IvatVzpVIbsuk9NwVujYjXUnl/YMuIuHNNdZRbN47lp9Oupzd0CNYIffXq9Wudqie+tyDvnLPrFh2a3EdDQVr2EfEVcIWk1kBPSdsB0yPiBeCFQtzTzGytNLn0XTsFSfZpMp/LgBOBD8n+GLtLug34VUQsK8R9zczqak1z3jR1hXpA+1ugM7BFROwcEX2ALYGOwNUFuqeZWZ2V+jj7Qj2gPQjYKnIeCETEQkmnAv8k6883M2s8mmoWz1Ohkn1EFU9+I2KFJD94NbNGp6kOqcxXobpxpkk6vnKhpB+TtezNzBqVUp8bp1At+9OA0ZJOIvvGLMAuQBvgsALd08yszppqEs9XoYZezgb6StoP2DYVPxYRnmfVzBqlUu/GKdTQy9bAKWTfnn0DuCVnVXUzs0bHLfu6uR1YBvwdGARsA/ysQPcyM1trJZ7rC5bse0fE9gCSbmEtFsk1MyuKEs/2hUr2q74hGxHLVeq/H5lZk+c++7rZQdLCtC2gTdoX2Rj89tVfamZWfIVYcLwxKdRonOaFqNfMrGCc7M3MSp+7cczMykCpP1p0sjczo+R7cZzszcyAks/2TvZmZpT+4iVO9mZmlHzD3snezAwo+WzvZG9mhodempmVhRLvsi/YSlVmZk1Kfa1UJam7pPGSpkmaKumsVN5Z0jhJ76SfnVK5JF0nabqk1yX1yalrSDr/HUlD1ub9OdmbmZF14+T73xosB86JiN5AP+A0Sb2B84EnI6IX8GTah2wa+F7pNRS4EbIPB2AY0BfYDRhW8QFRF072ZmbUX8s+Ij6OiMlpexHwJtAVOIRsrQ/Sz0PT9iHAHZF5CegoaVPgQGBcRMyLiPnAOGBgXd+fk72ZGdlgnLxf0lBJk3JeQ6usU+oB7AS8DGwcER+nQ3OAjdN2V2BmzmWzUll15XXiB7RmZtTuAW1EjABG1Fyf2gL3Az+LiIW563pEREiKukVaN27Zm5kBtWvbr6EmqSVZor8rIkan4k9S9wzp56epfDbQPefybqmsuvI6cbI3MyNbvCTfV02UNeFvAd6MiN/lHHoYqBhRMwR4KKf8+DQqpx+wIHX3jAEGSOqUHswOSGV14m4cMzPqdZz9HsBxwBuSpqSyXwJXAKMknQzMAH6Yjj0GDAamA0uAEwEiYp6ki4GJ6bzhETGvrkE52ZuZUX/foI2I56i+r2f/Ks4P4LRq6roVuLU+4nKyNzMDz41jZlYOSjzXO9mbmUHpz43jZG9mBqjEs72TvZkZ7sYxMysLJd6wd7I3MwMvXmJmVhbcsjczKwNO9mZmZcDdOGZmZcAtezOzMlDiud7J3swMKPls72RvZob77M3MysKaFiVp6pzszczA3ThmZuXA3ThmZmWg1IdeKlsRyxozSUMjYkRDx2GNi/9dWG00a+gALC9DGzoAa5T878Ly5mRvZlYGnOzNzMqAk33T4H5Zq4r/XVje/IDWzKwMuGVvZlYGnOzNzMqAk30DkhSSrsnZ/4Wk36Tt30iaLWlKzqtjOrabpKclvSNpsqRHJW3fMO/CCkHSivR3/g9J90laN5V3k/RQ+rt/V9IfJLVKx9aVdJekN9J1z0lq27DvxBoLJ/uG9TVwuKQNqjl+bUTsmPP6QtLGwCjglxHRKyL6AJcDWxYraCuKr9Lf+XbAN8ApkgSMBh6MiF7AVkBb4NJ0zVnAJxGxfbruZGBZA8RujZCTfcNaTjai4uxaXHM6cHtEvFBREBHPRcSD9RybNR5/B3oC+wFLI+I2gIhYQfZv56TU8t8UmF1xUUS8FRFfN0C81gg52Te8G4BjJXWo4tjZOV0441PZtsDk4oVnDUlSC2AQ8AbZ3/0ruccjYiHwIdmHwa3AeZJelHSJpF7FjtcaLyf7Bpb+Z70DOLOKw7ndOPtWdb2klyW9KekPBQ3Uiq2NpCnAJLJkfsuaLoiIKcAWwG+BzsBESdsUMEZrQjzrZePwe7LW+m15nDsV6AM8BBARfSUdARxUsOisIXwVETvmFkiaBhxRqaw9sBkwHSAiviTr1x8taSUwGHizGAFb4+aWfSMQEfPIHrqenMfpNwAnSOqfU7ZuQQKzxuZJYF1JxwNIag5cA/w5IpZI2kNSp3SsFdAbmNFg0Vqj4mTfeFwDVB6Vk9tnP0VSj4iYAxwFXC5puqQXyFp71xc7YCuuyL7ufhhwpKR3gLeBpcAv0ylbAs9IegN4lawL6P6GiNUaH0+XYGZWBtyyNzMrA072ZmZlwMnezKwMONmbmZUBJ3szszLgZG+rqW62xTrW9ef0hS8k3Sypdw3n7lPpuwP53uODqiaSq668mjpOkFSroau1qd+sMXCyt8r+bbbF3INprpZai4j/jIhpNZyyD1DrZG9m+XGyt5r8HeiZWt1/l/QwME1Sc0m/lTRR0uuSfgKgzPWS3pL0f8BGFRWl+fd3SdsD0zz8r0l6UlIPsg+Vii+R7SVpQ0n3p3tMlLRHunZ9SWMlTZV0M6B830xaB+BFSa9KekHS1jmHu+esETAs55ofS5qQ4vrf9K3V3DrXU7aewGvpt6GjavuHbFYMnhvHqpQz2+ITqagPsF1EvC9pKLAgInaVtA7wvKSxwE7A1mRf098YmEY2E2NuvRsCNwF7p7o6R8Q8SX8CvoyIq9N5d5NNBPecpM2AMcA2wDDguYgYLul75DfFRIV/AntFxHJJBwCXAT9Ix3YDtgOWkE0g9iiwmOzbyntExDJJfwSOJZu4rsJA4KOI+F6Ku6rZS80anJO9VVYx2yJkLftbyLpXJkTE+6l8APCdiv54oAPQC9gbGJnmWf9I0lNV1N8PeLairjQvUFUOAHpn63UA0F7Zqkt7A4enax+VNL8W760DcHua+jeAljnHxkXEXABJo4E9ydYb2Jks+QO0AT6tVOcbwDWSrgT+FhF/r0U8ZkXjZG+VVTXbImSt3FVFwBkRMabSeYPrMY5mQL+IWFpFLHV1MTA+Ig5LXUdP5xyrPG9IkL3P2yPiguoqjIi3JfUhm13yEklPRsTwtQnSrBDcZ291MQY4VVJLAElbSVoPeBY4KvXpbwpUNQf/S8DekjZP13ZO5YuAdjnnjQXOqNiRtGPafBY4JpUNAjrVIu4O/GslpxMqHfuupM6S2gCHAs+TzTJ5hKSNKmKV9K3ciyR1AZZExF/I5pHvU4t4zIrGLXuri5uBHsBkZU3tz8gS5ANkS+dNI1tw48XKF0bEZ6nPf7SkZmTdIt8FHgH+KukQsiR/JnCDpNfJ/p0+S/YQ9yJgpKSpwAvpPtV5Xdmc7pBNIX0VWTfOhcCjlc6dQDZDZDfgLxExCSCdOzbFugw4jdWnDd4e+G26zzLg1BriMWswnvXSzKwMuBvHzKwMONmbmZUBJ3szszLgZG9mVgac7M3MyoCTvZlZGXCyNzMrA/8fd6jtUTt4CeoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the best model\n",
    "best_model = BERT().to(device)\n",
    "load_checkpoint(destination_folder +\"/\"+ str(12)+ 'model.pt', best_model)\n",
    "acc = evaluate(best_model, test_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c98af40b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/notebooks/../model/12metrics.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder +\"/\"+  '12metrics.pt')\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15d44f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/notebooks/../model/12acc_log.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAj7klEQVR4nO3deXgd5Xn38e+tI0uyFkvW4lW2JYMXDAHbiMWBJjaUxCyxyxuS4LYpDkl4Q0uztCkF2oBDr7RpStOElC68eWnaNMXQLMQQiAvENJSExDIYgm2MjbGDMHgRtmTL1n73j5kjH8tH8pHR6Eia3+fyXGfmmWfmPOfo+L5nfcbcHRERia+cbDdARESyS4lARCTmlAhERGJOiUBEJOaUCEREYi432w0YqMrKSq+pqcl2M0RERpQNGzbsd/eqdPNGXCKoqamhvr4+280QERlRzGxXX/N0aEhEJOaUCEREYk6JQEQk5pQIRERiTolARCTmlAhERGJOiUBEJOZG3H0EIiKjhbvT2tFNS3snR9q6ONLRSUtbF0faU17buzgaTl8ydwLnTCsb9HYoEYiIZKC72zna0UVLWxCcW9o6aWnr5Eh7V08gP9zW2RO8k/OOC+rha1AeLDeQR8JUleQrEYiIDER3t3O4vZPDrZ0cbuvkUGsHh3rGg/JDrR0cCoN6S1v/QT1TeYkcCvMTFOXlUpiXoDA/l6K8BFPK8ijKTwRleUFZcl5hr7qFeblh3aB87JgEOTkWyfekRCAiw1JbZxeHWjvDoaPntTml7HBKUD/UdmLZ4bbOjN6rJD83CNz5uRTnB4F3SllBTzAuysvtCdBF+cfKisK6xfm5xwXwvNyRdfpViUBEItHW2cWBlg7ebmnn4JF2mnsF8eNfO2nuFezbO7tP+h6FeQlKCoLgXVwwhnEFuUwaV0Bxfi4lBWMoLsilJD83qBPWKykYQ0lBbs9yRXm5kW1pjxRKBCJyUh1d3Rw80sGBI+283dLOgZZ23j4SvraklKfMbznJoZSivMRxQXl8YR7TywspCQP6uLHH5pXkJ8eD13FhkE/EPIAPFiUCkZhxdw61dfL24XYak0E9DOxvt7TTeLj9hMB+qLXvQyzF+bmMLxpDeWEe5UV5nF5VzPiiYHx8YR7lRWMoHZvHuLFBAFcQH36UCERGuM6u7p4gnslw4Eg7HV3pL1XJz82hoiiPssI8KoqDLfTUgD6+KI/ywryeQF9WOIb83MQQf2IZbEoEIsNUd7dz4Eg7bzW3sre5jT3NrexpbgunW9lzKJjef7itz0sQS8eOoaIoCNzTyguZP62M8UV5QVlhHuXFeT1b8uVFeRTmJTDTlnrcKBGIDLHkoZm9ycDeFAT1ZLBPBv69h1rTbrlXFucxoaSAiePyOWtKKRPGFVBVkt8T0CuKgyA/vnAMuYmRdfWKZIcSgcggcneajnbwZlMrbzYd5c2mVt5qamX3wVbeaj42ne6a9JKCXCaOCwL8BTPLg/GSfCaVFjBhXAETxxVQVZw/4i5NlOFPiUAkQ+7OwSMd7G46yltNrceCfDidLDvacXyQzzGYOK6ASaUFzJ1UwuLZE5hUmh8G/YKe4F+Yp/+Okh365YmkaOvs4vW3j7BjXwuv7Q+GXY1Herbu23pd257IsZ6t9jOmjOOSuROYVFrAlLKxTCotYHJpsBWvQzQynCkRSOx0dzu7m472BPrUoN9w4AjdKYflK4rymFFRyFlTS7ls3kQmlY5lSmlBGOTHUlWSr8sgZcRTIpBRyd15u6U9CPRhkH8tDPg7G1uO27IvyktQW1XEOdPK+K0FU5lZWURNZRG1FUWUFo7J4qcQGRpKBDKiNR3pYGdjENxf29/Czv0tvNZ4hNf2HaY55SaoMQljenkhtZXFvHdOFbWVRdRWFjGzsoiqknxdMimxpkQgw15zawe79h/htcYg0AfBPng9cKSjp54ZTCkdS01lIcvnTw2CfVUQ7KeWjdVxepE+KBHIsHC4rTMI8mGAf23/kZ7xxpb24+pOLi2gpqKIpWdNpraykBkVwdb99PJCCsboLleRgVIikCG391Arz//6IM//+iAbXz/A9r0t7D/cdlydCSX51FQW8ZtnTAyO11cWUlNZxIzyIsbmKdiLDKZIE4GZLQW+DiSAb7r7l3vNnwHcB1QBbwO/6+4NUbRl+95DrHnhTW5872kKJEOovbObTbubgsD/+kGe//UBGg4cBSA3x5g3ZRxL5lSFwb6ImooiaioLdU29yBCK7H+bmSWAe4DLgAZgvZmtcffNKdXuAv7N3f/VzC4B/gr4aBTteWLLXu5+chvf29DAF66ax/vPnKgThIPM3XmzqZXnfn0g3OI/wEu7m3v6lZ9cWsCC6WVct6iGhTPKOHNKqQ7liAwDUW52nQ9sd/cdAGa2GlgOpCaCecAfhePrgIeiasyn3nsa86eVcccPN/Gpf9/Ab8yq5I4PnMnpE4qjestRr7Wji1+90cRzu8LA//oB9jQHh3jyc3N419RSrls0g4XTxzN/ehmTS8dmucUikk6UiWAq8HrKdANwQa86LwD/h+Dw0dVAiZlVuHtjaiUzuwG4AWD69Omn3KALZ1bwo09fzL8/u4u/ffwVln7tp3z84lr+8NJZFOfrUER/2jq72LGvhZffau45vr/lzWY6w7uvppcXcuHMChZOH8+C6WXMnTROfeKIjBDmffVf+05XbHYNsNTdPxFOfxS4wN1vSqkzBfh7oBb4KfBB4Cx3P9jXeuvq6ry+vv4dt2//4Ta+8uOXebC+gQkl+dx2xRksnz8l9oeL2jq7eG1/C6/sOcy2PYd4Zc8htu05zM7Glp47bgvzEpxTXcbCGWUsmBZs7VcW52e34SLSLzPb4O516eZFuRn8BjAtZbo6LOvh7rsJ9ggws2Lgg/0lgcFUWZzPV645hxXnT+eONZv47AMb+c4vdrFq2ZmcOaV0KJqQVe2d3WHAPxQG/MO8svcQuxqP0BVG/ESOMaOikNkTS7jy7MnMmljCnIklnD6hWN0qiIwiUe4R5AKvAJcSJID1wG+7+6aUOpXA2+7ebWZfArrc/fb+1jtYewSpurudB+tf5ytrt3LwSDu/e+EM/uiy2ZQV5g3q+2RDe2c3OxuDgJ+6lb8zJeDnGNRUFDFrYjGzw0A/e2IJM6uK9PQpkVEiK3sE7t5pZjcBawkuH73P3TeZ2Z1AvbuvARYDf2VmTnBo6A+iak9/cnKMa8+fzuVnTearj2/l28/u4pEX3+RP3j+HD9dNG1Fbv60dXTy36wD/s30/z7zayKY3mnqO4+cYzKgoYtaEYi4/azKzJhYza0IQ8HX1jkh8RbZHEJUo9gh627y7mVVrNvHLnW9zdnUpX1x2Jgumj4/0PU9VV7fz0htNPPPqfp7Zvp/6nQdo6+wmN8eYP62M82rLmTOxhFkTizmtqlgBXySm+tsjUCLog7uz5oXd/OWjW9jT3MaHzq3m5qVzqSrJ7klRd2fH/hae2R4E/p+/2tjTudrcSSVcdHolF51ewfm1FboSSkR6ZOtk8YhmZiyfP5VLz5jIN36yjfv+5zV+/NJbfO6y2fzeohlD2oHZW02tQeB/dT8/297IW82tAFSPH8vlZ03molmVvPu0Cl25IyKnRHsEGdq+9zBffHgTT2/bz5yJJaxadiaLTquI5L2ajnbw7I7Gnq3+V/e1AFBelMei0yq46LRKLj69kukVhZG8v4iMPjo0NEjcnf/avIc7H97MGwePcvlZk5g7aRyOB9fYu+NAtzvu0O3gOPiJZe7B+o6v72ze3cyv3mii22HsmAQXzCznotMquej0SuZOKiFnBJ24FpHhQ4lgkLV2dPGPT73KvT/dccKDys0gxwwjeCX4F5SlzDMLDj/1LqupKAqP81cyf1qZ7s4VkUGhRBCR5HX4qYFdRGQ40sniiIyk+wtERPqi4w4iIjGnRCAiEnNKBCIiMadEICISc0oEIiIxp0QgIhJzSgQiIjGnRCAiEnNKBCIiMadEICISc0oEIiIxp0QgIhJzSgQiIjGnRCAiEnNKBCIiMadEICISc0oEIiIxp0QgIhJzSgQiIjGnRCAiEnNKBCIiMRdpIjCzpWa21cy2m9ktaeZPN7N1Zva8mb1oZldE2R4RETlRZInAzBLAPcDlwDxghZnN61Xtz4EH3X0BcC3wD1G1R0RE0otyj+B8YLu773D3dmA1sLxXHQfGheOlwO4I2yMiImlEmQimAq+nTDeEZalWAb9rZg3Ao8AfpluRmd1gZvVmVr9v374o2ioiElvZPlm8AviWu1cDVwDfNrMT2uTu97p7nbvXVVVVDXkjRURGsygTwRvAtJTp6rAs1ceBBwHc/edAAVAZYZtERKSXKBPBemCWmdWaWR7ByeA1ver8GrgUwMzOIEgEOvYjIjKEIksE7t4J3ASsBbYQXB20yczuNLNlYbU/Bj5pZi8A9wMr3d2japOIiJwoN8qVu/ujBCeBU8tuTxnfDFwUZRtERKR/2T5ZLCIiWaZEICISc0oEIiIxp0QgIhJzSgQiIjGnRCAiEnNKBCIiMadEICISc0oEIiIxp0QgIhJzSgQiIjGnRCAiEnNKBCIiMadEICISc0oEIiIxl1EiMLPvm9mV6Z4nLCIiI1umgf0fgN8GtpnZl81sToRtEhGRIZRRInD3J9z9d4CFwE7gCTP7mZl9zMzGRNlAERGJVsaHesysAlgJfAJ4Hvg6QWJ4PJKWiYjIkMjomcVm9gNgDvBt4APu/mY46wEzq4+qcSIig6Gjo4OGhgZaW1uz3ZTIFRQUUF1dzZgxmR+syfTh9Xe7+7p0M9y9LuN3ExHJgoaGBkpKSqipqcHMst2cyLg7jY2NNDQ0UFtbm/FymR4ammdmZckJMxtvZr8/wDaKiGRFa2srFRUVozoJAJgZFRUVA97zyTQRfNLdDyYn3P0A8MkBvZOISBaN9iSQdCqfM9NEkLCUtZtZAsgb8LuJiMRMY2Mj8+fPZ/78+UyaNImpU6f2TLe3t/e7bH19PZ/+9Kcjb2Om5wh+THBi+J/D6f8blomISD8qKirYuHEjAKtWraK4uJjPf/7zPfM7OzvJzU0fiuvq6qiri/40bKZ7BH8KrANuDIcngZujapSIyGi2cuVKPvWpT3HBBRdw880388tf/pJFixaxYMEC3v3ud7N161YAnnrqKa666iogSCLXX389ixcvZubMmdx9992D1p6M9gjcvRv4x3AQERmxvvjwJjbvbh7Udc6bMo47PnDmgJZpaGjgZz/7GYlEgubmZp5++mlyc3N54oknuO222/je9753wjIvv/wy69at49ChQ8yZM4cbb7xxQJeJ9iXT+whmAX8FzAMKkuXuPvMdt0BEJIY+9KEPkUgkAGhqauK6665j27ZtmBkdHR1pl7nyyivJz88nPz+fCRMmsGfPHqqrq99xWzI9R/AvwB3A3wFLgI+RwWElM1tKcAdyAvimu3+51/zk+gAKgQnuXpZhm0REBmygW+5RKSoq6hn/whe+wJIlS/jBD37Azp07Wbx4cdpl8vPze8YTiQSdnZ2D0pZMzxGMdfcnAXP3Xe6+CriyvwXCK4vuAS4n2JNYYWbzUuu4++fcfb67zwe+AXx/gO0XERnxmpqamDp1KgDf+ta3hvz9M00EbWEX1NvM7CYzuxooPsky5wPb3X2Hu7cDq4Hl/dRfAdyfYXtEREaNm2++mVtvvZUFCxYM2lb+QJi7n7yS2XnAFqAM+AtgHPA37v5sP8tcAyx190+E0x8FLnD3m9LUnQE8C1S7e1ea+TcANwBMnz793F27dp38k4mIhLZs2cIZZ5yR7WYMmXSf18w29NUlUCbH+RPAR9z9sLs3uPvH3P2D/SWBU3At8N10SQDA3e919zp3r6uqqhrEtxURkZMmgjA4X3wK634DmJYyXR2WpXMtOiwkIpIVmV419LyZrQH+E2hJFrp7fyd31wOzzKyWIAFcS/CUs+OY2VxgPPDzTBstIiKDJ9NEUAA0ApeklDn9XOXj7p1mdhOwluDy0fvcfZOZ3QnUu/uasOq1wGrP5GSFiIgMukzvLP7Yqazc3R8FHu1Vdnuv6VWnsm4RERkcmd5Z/C8EewDHcffrB71FIiIypDK9j+AR4Efh8CTB5aOHo2qUiMhosmTJEtauXXtc2de+9jVuvPHGtPUXL15MfX3wFOArrriCgwcPnlBn1apV3HXXXYPSvowSgbt/L2X4DvBhQI+oFBHJwIoVK1i9evVxZatXr2bFihUnXfbRRx+lrKwsopYFMt0j6G0WMGEwGyIiMlpdc801/OhHP+p5EM3OnTvZvXs3999/P3V1dZx55pnccccdaZetqalh//79AHzpS19i9uzZXHzxxT1dVQ+GTM8RHOL4cwRvETyjQERkZHnsFnjrV4O7zknvgsu/3Ofs8vJyzj//fB577DGWL1/O6tWr+fCHP8xtt91GeXk5XV1dXHrppbz44oucffbZadexYcMGVq9ezcaNG+ns7GThwoWce+65g9L8TA8Nlbj7uJRhtruf2Fm2iIiklXp4KHlY6MEHH2ThwoUsWLCATZs2sXnz5j6Xf/rpp7n66qspLCxk3LhxLFu2bNDalukewdXAT9y9KZwuAxa7+0OD1hIRkaHQz5Z7lJYvX87nPvc5nnvuOY4cOUJ5eTl33XUX69evZ/z48axcuZLW1tastC3TcwR3JJMAgLsfJHg+gYiIZKC4uJglS5Zw/fXXs2LFCpqbmykqKqK0tJQ9e/bw2GOP9bv8e97zHh566CGOHj3KoUOHePjhhwetbZneWZwuYWS6rIiIEBweuvrqq1m9ejVz585lwYIFzJ07l2nTpnHRRRf1u+zChQv5yEc+wjnnnMOECRM477zzBq1dmXZDfR9wkOBBMwB/AJS7+8pBa0mG6urqPHl9rYhIJtQN9Tvshjr0h0A78ADBA2ZaCZKBiIiMcJn2NdQC3BJxW0REJAsy2iMws8fDK4WS0+PNbG0/i4iIyAiR6aGhyvBKIQDc/QC6s1hERpC49HR/Kp8z00TQbWbTkxNmVkOa3khFRIajgoICGhsbR30ycHcaGxspKCgY0HKZXgL6Z8D/mNl/Awb8BuHD5EVEhrvq6moaGhrYt29ftpsSuYKCAqqrqwe0TKYni39sZnUEwf954CHg6EAbKCKSDWPGjKG2tjbbzRi2Mu1i4hPAZwgeQL8RuJDgGcOX9LOYiIiMAJmeI/gMcB6wy92XAAsIbjATEZERLtNE0OrurQBmlu/uLwNzomuWiIgMlUxPFjeE9xE8BDxuZgeAXVE1SkREhk6mJ4uvDkdXmdk6oBT4cWStEhGRITPgHkTd/b+jaIiIiGTHqT6zWERERgklAhGRmFMiEBGJOSUCEZGYUyIQEYm5SBOBmS01s61mtt3M0j7Yxsw+bGabzWyTmf1HlO0REZETRfYAejNLEDzj+DKgAVhvZmvcfXNKnVnArcBF7n7AzPSMAxGRIRblHsH5wHZ33+Hu7QTPOl7eq84ngXvCB93g7nsjbI+IiKQRZSKYCryeMt0QlqWaDcw2s2fM7FkzW5puRWZ2g5nVm1l9HPoTFxEZStk+WZwLzAIWAyuA/5f6bOQkd7/X3evcva6qqmpoWygiMspFmQjeAKalTFeHZakagDXu3uHurwGvECQGEREZIlEmgvXALDOrNbM84FpgTa86DxHsDWBmlQSHinZE2CYREeklskTg7p3ATcBaYAvwoLtvMrM7zWxZWG0t0Ghmm4F1wJ+4e2NUbRIRkROZu2e7DQNSV1fn9fX12W6GiMiIYmYb3L0u3bxsnywWEZEsUyIQEYk5JQIRkZhTIhARiTklAhGRmFMiEBGJOSUCEZGYUyIQEYk5JQIRkZhTIhARiTklAhGRmFMiEBGJOSUCEZGYUyIQEYk5JQIRkZhTIhARiTklAhGRmFMiEBGJOSUCEZGYUyIQEYk5JQIRkZhTIhARiTklAhGRmFMiEBGJOSUCEZGYUyIQEYk5JQIRkZhTIhARiblIE4GZLTWzrWa23cxuSTN/pZntM7ON4fCJKNsjIiInyo1qxWaWAO4BLgMagPVmtsbdN/eq+oC73xRVO0REpH9R7hGcD2x39x3u3g6sBpZH+H4iInIKokwEU4HXU6YbwrLePmhmL5rZd81sWroVmdkNZlZvZvX79u2Loq0iIrGV7ZPFDwM17n428Djwr+kqufu97l7n7nVVVVVD2kARkdEuykTwBpC6hV8dlvVw90Z3bwsnvwmcG2F7REQkjSgTwXpglpnVmlkecC2wJrWCmU1OmVwGbImwPSIikkZkVw25e6eZ3QSsBRLAfe6+yczuBOrdfQ3waTNbBnQCbwMro2qPiIikZ+6e7TYMSF1dndfX12e7GSIiI4qZbXD3unTzsn2yWEREskyJQEQk5pQIRERiTolARCTmlAhERGJOiUBEJOaUCEREYk6JQEQk5pQIRERiTolARCTmlAhERGJOiUBEJOaUCEREYk6JQEQk5pQIRERiLj6JYO/LsPF+OHog2y0RERlWIntC2bCz6fvw338NOblQ+16YtwzmXAnFVdlumYhIVsXnCWXd3bD7Odj8Q9iyBg7sBMuB6e8OksLcq6B06qC3V0RkOOjvCWXxSQSp3GHPS7B5TZAU9r0clE+tC5LCGcugvPadN1ZE4sUdvDtlCKfxPsbJoE7KeGEFFIw7paYpEZzMvleChLBlDbz5QlA28V3HksKEuYP7fiJR6e6Crg7o7oDuTujqDMa7wunuzjTjfdR1B+8KAlB3+Opd4Xgf87w72PtONy8pXczpKfPMy7z72OfoThlPtrG7K01Z5/Gvnlon2fb+ht6BPnVI+YxRufKrcN7HT2lRJYKBOLATtjwSJIXXfxGUVc6GMz4QJIXJ54BZdO8v0XDvPxB2JQNKH0Ez+Z+9J7D1Dnx9BD/3NIEyDD5d7dDZFrxHVzt0pY53hPPaM5/f3clxQTPbLCccEuFr6v+bcDzjMk4sy0kE5/wsfM1J9CpLLc8Ny3OOjfeubznBdE+7+xssfXlO6me1AY5z8jrV50HlrFP7cygRnKLmN+HlMCnsfCb4j1w2PUgIZywL/ig5A7zwKrm1dNwWScrWCqT8R7CUH0LqK32Up7ymrqf3+3hXr62h7gzLkgEtZasouWV23G5scjpdWZrl0gbF9l7jaco609VLBsVewT353Q4rBrn5kMiHxBhI5AWvufnHxhN5vYa+5o+BnDFBUEvkBuOJMceC3gnjGdS1RPAb6gluaYJlf/O0wTSsKBEMhpZG2PpokBReXRcEl8JKKCgNA2X3ibugqVt/3jVMg9EwlDPm+ECX2ytQJtIEwtxeAbEn2CXSB74TxtMEykTusTJLBEn/uC3cNFuQ/QbGlDqJvOBVZIj0lwjic/noO1VUAQs/GgytTfDKf8GrTwZbscndzJ7d0d67p8l5ub2m09RLcqfnJNEJ0yd75fjx3u+TDEYnLQuDX+8yywl2OpKBLXXXNW1Z6u5tSr3kHkzvoK4tSZEhpURwKgpK4ewPBYOIyAgXnzuLRUQkLSUCEZGYUyIQEYm5SBOBmS01s61mtt3Mbumn3gfNzM0s7RltERGJTmSJwMwSwD3A5cA8YIWZzUtTrwT4DPCLqNoiIiJ9i3KP4Hxgu7vvcPd2YDWwPE29vwD+GmiNsC0iItKHKBPBVOD1lOmGsKyHmS0Eprn7j/pbkZndYGb1Zla/b9++wW+piEiMZe1ksZnlAF8F/vhkdd39Xnevc/e6qio9P0BEZDBFeUPZG8C0lOnqsCypBDgLeMqCO0knAWvMbJm799mHxIYNG/ab2a4I2jtcVQL7s92ILNN3oO8A9B3AO/sOZvQ1I7K+hswsF3gFuJQgAawHftvdN/VR/yng8/0lgTgys/q++geJC30H+g5A3wFE9x1EdmjI3TuBm4C1wBbgQXffZGZ3mtmyqN5XREQGJtK+htz9UeDRXmW391F3cZRtERGR9HRn8fB3b7YbMAzoO9B3APoOIKLvYMQ9j0BERAaX9ghERGJOiUBEJOaUCIaYmU0zs3VmttnMNpnZZ8LycjN73My2ha/jw3Izs7vDjvteDO/GTq7rurD+NjO7Lluf6VSZWcLMnjezR8LpWjP7RfhZHzCzvLA8P5zeHs6vSVnHrWH5VjN7f5Y+yikxszIz+66ZvWxmW8xsUdx+B2b2ufD/wUtmdr+ZFYz234GZ3Wdme83spZSyQfu7m9m5ZvarcJm7zTJ45J+7axjCAZgMLAzHSwjutZgHfAW4JSy/BfjrcPwK4DGCh0NeCPwiLC8HdoSv48Px8dn+fAP8Lv4I+A/gkXD6QeDacPyfgBvD8d8H/ikcvxZ4IByfB7wA5AO1wKtAItufawCf/1+BT4TjeUBZnH4HBF3OvAaMTfn7rxztvwPgPcBC4KWUskH7uwO/DOtauOzlJ21Ttr+UuA/AD4HLgK3A5LBsMrA1HP9nYEVK/a3h/BXAP6eUH1dvuA8Ed5o/CVwCPBL+aPcDueH8RcDacHwtsCgczw3rGXArcGvKOnvqDfcBKA2DoPUqj83vgGP9kZWHf9dHgPfH4XcA1PRKBIPydw/nvZxSfly9vgYdGsqicNd2AUEX3BPd/c1w1lvAxHC8r877Ttqp3zD3NeBmoDucrgAOenAjIhz/eXo+azi/Kaw/kr+DWmAf8C/h4bFvmlkRMfoduPsbwF3Ar4E3Cf6uG4jX7yBpsP7uU8Px3uX9UiLIEjMrBr4HfNbdm1PneZDKR+11vWZ2FbDX3Tdkuy1ZlEtweOAf3X0B0EJwSKBHDH4H4wm6pq8FpgBFwNKsNmoYyMbfXYkgC8xsDEES+I67fz8s3mNmk8P5k4G9YXlfnfedrFO/4ewiYJmZ7SR4TsUlwNeBMgv6qILjP0/PZw3nlwKNjOzvoAFocPfkA5m+S5AY4vQ7+E3gNXff5+4dwPcJfhtx+h0kDdbf/Y1wvHd5v5QIhlh4Bv//A1vc/asps9YAyTP/1xGcO0iW/1549cCFQFO4C7kWeJ+ZjQ+3rN4Xlg177n6ru1e7ew3BSb+fuPvvAOuAa8Jqvb+D5HdzTVjfw/Jrw6tJaoFZBCfKhj13fwt43czmhEWXApuJ0e+A4JDQhWZWGP6/SH4HsfkdpBiUv3s4r9nMLgy/099LWVffsn3SJG4DcDHBbt+LwMZwuILgWOeTwDbgCaA8rG8Ej/x8FfgVUJeyruuB7eHwsWx/tlP8PhZz7KqhmQT/gbcD/wnkh+UF4fT2cP7MlOX/LPxutpLB1RHDaQDmA/Xhb+Ehgqs/YvU7AL4IvAy8BHyb4MqfUf07AO4nOCfSQbBn+PHB/LsDdeH3+Srw9/S6ICHdoC4mRERiToeGRERiTolARCTmlAhERGJOiUBEJOaUCEREYk6JQEYdM5toZv9hZjvMbIOZ/dzMrg7nLbawt9N+ll9lZp8f4Hse7qP8z8LeNV80s41mdkFY/lkzKxzIe4hERYlARpXwJpqHgJ+6+0x3P5fgprXqfheMpi2LgKsIeps9m+BO2mT/MJ8FlAhkWFAikNHmEqDd3f8pWeDuu9z9G70rhn3APxRurT9rZmenzD4n3JPYZmafDOsXm9mTZvZc2N/78pO0ZTKw393bwnbsd/fdZvZpgr511pnZunDd7wvf7zkz+8+wLyrMbKeZfSV8v1+a2elh+Ycs6MP/BTP76al/XSJKBDL6nAk8l2HdLwLPh1vrtwH/ljLvbIKksgi43cymAK3A1e6+EFgC/O1JHvrxX8A0M3vFzP7BzN4L4O53A7uBJe6+xMwqgT8HfjNcdz3BsxqSmtz9XQR3iX4tLLsdeL+7nwMsy/DziqSlRCCjmpndE241r08z+2KCbg1w958AFWY2Lpz3Q3c/6u77Cfq+OZ/gdv+/NLMXCboBmMqx7oJP4O6HgXOBGwi6nH7AzFamqXohwcNVnjGzjQR9zcxImX9/yuuicPwZ4Fvh3kqi729A5ORyT15FZETZBHwwOeHufxBucdcPcD29+15x4HeAKuBcd+8Ie08t6Hcl7l3AU8BTZvYrgiD/rV7VDHjc3Vdk0BYP1/up8MTzlcAGMzvX3RtP9qFE0tEegYw2PwEKzOzGlLK+Tso+TRDcMbPFBMfzk8+GWG7B83MrCDrGW0/Q7fHeMAks4fit9hOY2Rwzm5VSNB/YFY4fInhUKcCzwEUpx/+LzGx2ynIfSXn9eVjnNHf/hbvfTrC3kdolsciAaI9ARhV3dzP7LeDvzOxmgiDZAvxpmuqrgPvCQz1HONYNMAQ9gq4DKoG/CE/yfgd4ONyyryfoNbM/xcA3zKwM6CToJfKGcN69wI/NbHd4nmAlcL+Z5Yfz/5zgedYA48M2thE8ehDgb8IkYwS9Vr5wkraI9Em9j4oMY+Hhp7rwXIVIJHRoSEQk5rRHICISc9ojEBGJOSUCEZGYUyIQEYk5JQIRkZhTIhARibn/Bf6m7PWQGyftAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder +\"/\"+  '12acc_log.pt')\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6016bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_list, valid_accuracy_list, global_steps_list = load_accuracy_log(destination_folder +\"/\"+  '12acc_log.pt')\n",
    "plt.plot(global_steps_list, train_accuracy_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_accuracy_list, label='Valid')\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca6ba77",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "Seems like the best accuracy is achieved when the model is trained for just 2 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b29c270",
   "metadata": {},
   "source": [
    "### Evaluate on different number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02a50a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "array = np.zeros((8,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a07cb6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## try different subnets and compare their accuracy\n",
    "## Using the plain BERT base model trained using all 12 layers\n",
    "## Evaluating using the first 5~12 layers\n",
    "for i in range(5,13):\n",
    "    #evaluating model with i layers\n",
    "    print(\"accuracy when using \",i,\" layers\")\n",
    "    acc = evaluate(best_model, test_iter, max_encoder_num=i)\n",
    "    array[i-5] = acc\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc02a0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Train and evaluate using 5 ~ 12 layers. No progressive shrinking. Each Training Independent of one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca9b4be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.zeros((8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311c32bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Train and evaluate using 5 ~ 12 layers. No progressive shrinking. Each Training Independent of one another\n",
    "for i in range(5,12):\n",
    "    ## create a new model\n",
    "    model = BERT().to(device)\n",
    "    print(\"\\n\\n****starting with layer number of \",i,\"****\")\n",
    "    ## Train using the first i layers\n",
    "    train(model=model, optimizer=optimizer, max_encoder_num=i)\n",
    "    \n",
    "    ## Evaluate the trained model\n",
    "    best_model = BERT().to(device)\n",
    "    print(\"loading model trained with \" + str(i) + \" number of layers\")\n",
    "    load_checkpoint(destination_folder +\"/\"+ str(i)+ 'model.pt', best_model)\n",
    "    \n",
    "    ## Getting the Evaluation using the first 5 ~ 12 layers\n",
    "    for j in range(5,13):\n",
    "        acc = evaluate(best_model, test_iter, max_encoder_num=j)\n",
    "        array[i-5][j-5] = acc\n",
    "        print(\"accuracy when using \", j, \" layers : \", acc)\n",
    "    print(\"results of the model trained using \",i,\" layers \")\n",
    "    for j in range(5,13):\n",
    "        print(j, \" -> \", array[i-5][j-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14dff7c",
   "metadata": {},
   "source": [
    "## Progressive Shrinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b74151e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing bertforsequenceclassification\n",
      "initializing weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****starting with layer number of  12 ****\n",
      "/home/ilee300/workspace/nlp_ofa/notebooks/../model/12metrics.pt\n",
      "changing encoder number :  12  =>  12\n",
      "training the model with encoder number of  12\n",
      "Epoch [1/1], Step [625/1250], Train Loss: 0.3192, Valid Loss: 0.3389\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/12model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/12metrics.pt\n",
      "Epoch [1/1], Step [1250/1250], Train Loss: 0.3954, Valid Loss: 0.3453\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/12metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/12acc_log.pt\n",
      "Finished Training!\n",
      "\n",
      "\n",
      "****starting with layer number of  11 ****\n",
      "/home/ilee300/workspace/nlp_ofa/notebooks/../model/11metrics.pt\n",
      "changing encoder number :  12  =>  11\n",
      "training the model with encoder number of  11\n",
      "Epoch [1/1], Step [625/1250], Train Loss: 0.1629, Valid Loss: 0.3998\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/11model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/11metrics.pt\n",
      "Epoch [1/1], Step [1250/1250], Train Loss: 0.2655, Valid Loss: 0.3200\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/11model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/11metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/11metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/11acc_log.pt\n",
      "Finished Training!\n",
      "\n",
      "\n",
      "****starting with layer number of  10 ****\n",
      "/home/ilee300/workspace/nlp_ofa/notebooks/../model/10metrics.pt\n",
      "changing encoder number :  12  =>  10\n",
      "training the model with encoder number of  10\n",
      "Epoch [1/1], Step [625/1250], Train Loss: 0.0914, Valid Loss: 0.4121\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/10model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/10metrics.pt\n",
      "Epoch [1/1], Step [1250/1250], Train Loss: 0.1521, Valid Loss: 0.5041\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/10metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/10acc_log.pt\n",
      "Finished Training!\n",
      "\n",
      "\n",
      "****starting with layer number of  9 ****\n",
      "/home/ilee300/workspace/nlp_ofa/notebooks/../model/9metrics.pt\n",
      "changing encoder number :  12  =>  9\n",
      "training the model with encoder number of  9\n",
      "Epoch [1/1], Step [625/1250], Train Loss: 0.0836, Valid Loss: 0.5054\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/9model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/9metrics.pt\n",
      "Epoch [1/1], Step [1250/1250], Train Loss: 0.1320, Valid Loss: 0.4957\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/9model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/9metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/9metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/9acc_log.pt\n",
      "Finished Training!\n",
      "\n",
      "\n",
      "****starting with layer number of  8 ****\n",
      "/home/ilee300/workspace/nlp_ofa/notebooks/../model/8metrics.pt\n",
      "changing encoder number :  12  =>  8\n",
      "training the model with encoder number of  8\n",
      "Epoch [1/1], Step [625/1250], Train Loss: 0.1004, Valid Loss: 0.4684\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/8model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/8metrics.pt\n",
      "Epoch [1/1], Step [1250/1250], Train Loss: 0.1347, Valid Loss: 0.5071\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/8metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/8acc_log.pt\n",
      "Finished Training!\n",
      "\n",
      "\n",
      "****starting with layer number of  7 ****\n",
      "/home/ilee300/workspace/nlp_ofa/notebooks/../model/7metrics.pt\n",
      "changing encoder number :  12  =>  7\n",
      "training the model with encoder number of  7\n",
      "Epoch [1/1], Step [625/1250], Train Loss: 0.0918, Valid Loss: 0.6559\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/7model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/7metrics.pt\n",
      "Epoch [1/1], Step [1250/1250], Train Loss: 0.1242, Valid Loss: 0.5295\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/7model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/7metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/7metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/7acc_log.pt\n",
      "Finished Training!\n",
      "\n",
      "\n",
      "****starting with layer number of  6 ****\n",
      "/home/ilee300/workspace/nlp_ofa/notebooks/../model/6metrics.pt\n",
      "changing encoder number :  12  =>  6\n",
      "training the model with encoder number of  6\n",
      "Epoch [1/1], Step [625/1250], Train Loss: 0.1015, Valid Loss: 0.6885\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/6model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/6metrics.pt\n",
      "Epoch [1/1], Step [1250/1250], Train Loss: 0.1167, Valid Loss: 0.6178\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/6model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/6metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/6metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/6acc_log.pt\n",
      "Finished Training!\n",
      "\n",
      "\n",
      "****starting with layer number of  5 ****\n",
      "/home/ilee300/workspace/nlp_ofa/notebooks/../model/5metrics.pt\n",
      "changing encoder number :  12  =>  5\n",
      "training the model with encoder number of  5\n",
      "Epoch [1/1], Step [625/1250], Train Loss: 0.1027, Valid Loss: 0.6424\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/5model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/5metrics.pt\n",
      "Epoch [1/1], Step [1250/1250], Train Loss: 0.1244, Valid Loss: 0.5390\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/5model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/5metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/5metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/5acc_log.pt\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "## Train using progressive shrinking\n",
    "model = BERT().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "for i in range(12,4,-1):\n",
    "    print(\"\\n\\n****starting with layer number of \",i,\"****\")\n",
    "    ##Each layer trained for 2 epochs. -> try 1 epoch for each...\n",
    "    train(model=model, optimizer=optimizer, max_encoder_num=i,num_epochs = 1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b43f9baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing bertforsequenceclassification\n",
      "initializing weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model trained with 5 number of layers\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/notebooks/../model/5model.pt\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8677    0.7515    0.8055     12500\n",
      "           0     0.7809    0.8854    0.8299     12500\n",
      "\n",
      "    accuracy                         0.8185     25000\n",
      "   macro avg     0.8243    0.8185    0.8177     25000\n",
      "weighted avg     0.8243    0.8185    0.8177     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.81848\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8697    0.7802    0.8226     12500\n",
      "           0     0.8007    0.8831    0.8399     12500\n",
      "\n",
      "    accuracy                         0.8317     25000\n",
      "   macro avg     0.8352    0.8317    0.8312     25000\n",
      "weighted avg     0.8352    0.8317    0.8312     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.83168\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8590    0.7885    0.8222     12500\n",
      "           0     0.8045    0.8706    0.8362     12500\n",
      "\n",
      "    accuracy                         0.8295     25000\n",
      "   macro avg     0.8318    0.8295    0.8292     25000\n",
      "weighted avg     0.8318    0.8295    0.8292     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.82952\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8471    0.7870    0.8159     12500\n",
      "           0     0.8011    0.8580    0.8286     12500\n",
      "\n",
      "    accuracy                         0.8225     25000\n",
      "   macro avg     0.8241    0.8225    0.8223     25000\n",
      "weighted avg     0.8241    0.8225    0.8223     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.82248\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8506    0.7232    0.7817     12500\n",
      "           0     0.7593    0.8730    0.8121     12500\n",
      "\n",
      "    accuracy                         0.7981     25000\n",
      "   macro avg     0.8049    0.7981    0.7969     25000\n",
      "weighted avg     0.8049    0.7981    0.7969     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.79808\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8570    0.6788    0.7576     12500\n",
      "           0     0.7341    0.8867    0.8032     12500\n",
      "\n",
      "    accuracy                         0.7828     25000\n",
      "   macro avg     0.7955    0.7828    0.7804     25000\n",
      "weighted avg     0.7955    0.7828    0.7804     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.78276\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8597    0.6680    0.7518     12500\n",
      "           0     0.7285    0.8910    0.8016     12500\n",
      "\n",
      "    accuracy                         0.7795     25000\n",
      "   macro avg     0.7941    0.7795    0.7767     25000\n",
      "weighted avg     0.7941    0.7795    0.7767     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.77948\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8602    0.6628    0.7487     12500\n",
      "           0     0.7257    0.8922    0.8004     12500\n",
      "\n",
      "    accuracy                         0.7775     25000\n",
      "   macro avg     0.7929    0.7775    0.7746     25000\n",
      "weighted avg     0.7929    0.7775    0.7746     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.77752\n",
      "results of the model trained using  5  layers \n",
      "5  ->  0.81848\n",
      "6  ->  0.83168\n",
      "7  ->  0.82952\n",
      "8  ->  0.82248\n",
      "9  ->  0.79808\n",
      "10  ->  0.78276\n",
      "11  ->  0.77948\n",
      "12  ->  0.77752\n",
      "initializing bertforsequenceclassification\n",
      "initializing weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model trained with 6 number of layers\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/notebooks/../model/6model.pt\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8904    0.3002    0.4490     12500\n",
      "           0     0.5791    0.9630    0.7233     12500\n",
      "\n",
      "    accuracy                         0.6316     25000\n",
      "   macro avg     0.7348    0.6316    0.5861     25000\n",
      "weighted avg     0.7348    0.6316    0.5861     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.6316\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9028    0.7038    0.7910     12500\n",
      "           0     0.7573    0.9242    0.8325     12500\n",
      "\n",
      "    accuracy                         0.8140     25000\n",
      "   macro avg     0.8300    0.8140    0.8117     25000\n",
      "weighted avg     0.8300    0.8140    0.8117     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.814\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8994    0.7242    0.8023     12500\n",
      "           0     0.7691    0.9190    0.8374     12500\n",
      "\n",
      "    accuracy                         0.8216     25000\n",
      "   macro avg     0.8342    0.8216    0.8199     25000\n",
      "weighted avg     0.8342    0.8216    0.8199     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.82156\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8904    0.7409    0.8088     12500\n",
      "           0     0.7781    0.9088    0.8384     12500\n",
      "\n",
      "    accuracy                         0.8248     25000\n",
      "   macro avg     0.8343    0.8248    0.8236     25000\n",
      "weighted avg     0.8343    0.8248    0.8236     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.82484\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8950    0.6810    0.7735     12500\n",
      "           0     0.7426    0.9201    0.8219     12500\n",
      "\n",
      "    accuracy                         0.8006     25000\n",
      "   macro avg     0.8188    0.8006    0.7977     25000\n",
      "weighted avg     0.8188    0.8006    0.7977     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.80056\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8971    0.6274    0.7384     12500\n",
      "           0     0.7135    0.9280    0.8068     12500\n",
      "\n",
      "    accuracy                         0.7777     25000\n",
      "   macro avg     0.8053    0.7777    0.7726     25000\n",
      "weighted avg     0.8053    0.7777    0.7726     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.77772\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8972    0.6110    0.7270     12500\n",
      "           0     0.7051    0.9300    0.8021     12500\n",
      "\n",
      "    accuracy                         0.7705     25000\n",
      "   macro avg     0.8012    0.7705    0.7645     25000\n",
      "weighted avg     0.8012    0.7705    0.7645     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.77052\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8985    0.6024    0.7212     12500\n",
      "           0     0.7009    0.9319    0.8001     12500\n",
      "\n",
      "    accuracy                         0.7672     25000\n",
      "   macro avg     0.7997    0.7672    0.7607     25000\n",
      "weighted avg     0.7997    0.7672    0.7607     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.76716\n",
      "results of the model trained using  6  layers \n",
      "5  ->  0.6316\n",
      "6  ->  0.814\n",
      "7  ->  0.82156\n",
      "8  ->  0.82484\n",
      "9  ->  0.80056\n",
      "10  ->  0.77772\n",
      "11  ->  0.77052\n",
      "12  ->  0.76716\n",
      "initializing bertforsequenceclassification\n",
      "initializing weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model trained with 7 number of layers\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/notebooks/../model/7model.pt\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9154    0.2276    0.3646     12500\n",
      "           0     0.5590    0.9790    0.7116     12500\n",
      "\n",
      "    accuracy                         0.6033     25000\n",
      "   macro avg     0.7372    0.6033    0.5381     25000\n",
      "weighted avg     0.7372    0.6033    0.5381     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.60328\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8725    0.6865    0.7684     12500\n",
      "           0     0.7416    0.8997    0.8130     12500\n",
      "\n",
      "    accuracy                         0.7931     25000\n",
      "   macro avg     0.8070    0.7931    0.7907     25000\n",
      "weighted avg     0.8070    0.7931    0.7907     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.79308\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8986    0.7689    0.8287     12500\n",
      "           0     0.7980    0.9133    0.8518     12500\n",
      "\n",
      "    accuracy                         0.8411     25000\n",
      "   macro avg     0.8483    0.8411    0.8402     25000\n",
      "weighted avg     0.8483    0.8411    0.8402     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.84108\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8910    0.7886    0.8367     12500\n",
      "           0     0.8104    0.9035    0.8544     12500\n",
      "\n",
      "    accuracy                         0.8461     25000\n",
      "   macro avg     0.8507    0.8461    0.8456     25000\n",
      "weighted avg     0.8507    0.8461    0.8456     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.84608\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9004    0.7281    0.8051     12500\n",
      "           0     0.7718    0.9194    0.8392     12500\n",
      "\n",
      "    accuracy                         0.8238     25000\n",
      "   macro avg     0.8361    0.8238    0.8221     25000\n",
      "weighted avg     0.8361    0.8238    0.8221     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.82376\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9054    0.6733    0.7723     12500\n",
      "           0     0.7400    0.9297    0.8240     12500\n",
      "\n",
      "    accuracy                         0.8015     25000\n",
      "   macro avg     0.8227    0.8015    0.7982     25000\n",
      "weighted avg     0.8227    0.8015    0.7982     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.80148\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9062    0.6507    0.7575     12500\n",
      "           0     0.7275    0.9326    0.8174     12500\n",
      "\n",
      "    accuracy                         0.7917     25000\n",
      "   macro avg     0.8169    0.7917    0.7875     25000\n",
      "weighted avg     0.8169    0.7917    0.7875     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.79168\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9046    0.6414    0.7506     12500\n",
      "           0     0.7222    0.9324    0.8140     12500\n",
      "\n",
      "    accuracy                         0.7869     25000\n",
      "   macro avg     0.8134    0.7869    0.7823     25000\n",
      "weighted avg     0.8134    0.7869    0.7823     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.78688\n",
      "results of the model trained using  7  layers \n",
      "5  ->  0.60328\n",
      "6  ->  0.79308\n",
      "7  ->  0.84108\n",
      "8  ->  0.84608\n",
      "9  ->  0.82376\n",
      "10  ->  0.80148\n",
      "11  ->  0.79168\n",
      "12  ->  0.78688\n",
      "initializing bertforsequenceclassification\n",
      "initializing weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model trained with 8 number of layers\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/notebooks/../model/8model.pt\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6939    0.8798    0.7758     12500\n",
      "           0     0.8358    0.6118    0.7065     12500\n",
      "\n",
      "    accuracy                         0.7458     25000\n",
      "   macro avg     0.7648    0.7458    0.7412     25000\n",
      "weighted avg     0.7648    0.7458    0.7412     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.7458\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6392    0.9537    0.7654     12500\n",
      "           0     0.9088    0.4618    0.6124     12500\n",
      "\n",
      "    accuracy                         0.7077     25000\n",
      "   macro avg     0.7740    0.7077    0.6889     25000\n",
      "weighted avg     0.7740    0.7077    0.6889     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.70772\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6896    0.9549    0.8008     12500\n",
      "           0     0.9267    0.5702    0.7060     12500\n",
      "\n",
      "    accuracy                         0.7625     25000\n",
      "   macro avg     0.8081    0.7625    0.7534     25000\n",
      "weighted avg     0.8081    0.7625    0.7534     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.76252\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8248    0.9066    0.8638     12500\n",
      "           0     0.8964    0.8074    0.8496     12500\n",
      "\n",
      "    accuracy                         0.8570     25000\n",
      "   macro avg     0.8606    0.8570    0.8567     25000\n",
      "weighted avg     0.8606    0.8570    0.8567     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.85704\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8869    0.8400    0.8628     12500\n",
      "           0     0.8480    0.8929    0.8699     12500\n",
      "\n",
      "    accuracy                         0.8664     25000\n",
      "   macro avg     0.8675    0.8664    0.8663     25000\n",
      "weighted avg     0.8675    0.8664    0.8663     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.86644\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8933    0.8157    0.8527     12500\n",
      "           0     0.8304    0.9026    0.8650     12500\n",
      "\n",
      "    accuracy                         0.8591     25000\n",
      "   macro avg     0.8619    0.8591    0.8589     25000\n",
      "weighted avg     0.8619    0.8591    0.8589     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.85912\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8969    0.8000    0.8457     12500\n",
      "           0     0.8195    0.9081    0.8615     12500\n",
      "\n",
      "    accuracy                         0.8540     25000\n",
      "   macro avg     0.8582    0.8540    0.8536     25000\n",
      "weighted avg     0.8582    0.8540    0.8536     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.85404\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8967    0.7980    0.8445     12500\n",
      "           0     0.8180    0.9081    0.8607     12500\n",
      "\n",
      "    accuracy                         0.8530     25000\n",
      "   macro avg     0.8574    0.8530    0.8526     25000\n",
      "weighted avg     0.8574    0.8530    0.8526     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.85304\n",
      "results of the model trained using  8  layers \n",
      "5  ->  0.7458\n",
      "6  ->  0.70772\n",
      "7  ->  0.76252\n",
      "8  ->  0.85704\n",
      "9  ->  0.86644\n",
      "10  ->  0.85912\n",
      "11  ->  0.85404\n",
      "12  ->  0.85304\n",
      "initializing bertforsequenceclassification\n",
      "initializing weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model trained with 9 number of layers\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/notebooks/../model/9model.pt\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8950    0.2563    0.3985     12500\n",
      "           0     0.5660    0.9699    0.7149     12500\n",
      "\n",
      "    accuracy                         0.6131     25000\n",
      "   macro avg     0.7305    0.6131    0.5567     25000\n",
      "weighted avg     0.7305    0.6131    0.5567     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.61312\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9159    0.4401    0.5945     12500\n",
      "           0     0.6315    0.9596    0.7617     12500\n",
      "\n",
      "    accuracy                         0.6998     25000\n",
      "   macro avg     0.7737    0.6998    0.6781     25000\n",
      "weighted avg     0.7737    0.6998    0.6781     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.69984\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9092    0.5393    0.6770     12500\n",
      "           0     0.6725    0.9462    0.7862     12500\n",
      "\n",
      "    accuracy                         0.7427     25000\n",
      "   macro avg     0.7909    0.7427    0.7316     25000\n",
      "weighted avg     0.7909    0.7427    0.7316     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.74272\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8795    0.6948    0.7763     12500\n",
      "           0     0.7478    0.9048    0.8188     12500\n",
      "\n",
      "    accuracy                         0.7998     25000\n",
      "   macro avg     0.8136    0.7998    0.7976     25000\n",
      "weighted avg     0.8136    0.7998    0.7976     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.7998\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9267    0.7170    0.8084     12500\n",
      "           0     0.7692    0.9433    0.8474     12500\n",
      "\n",
      "    accuracy                         0.8301     25000\n",
      "   macro avg     0.8479    0.8301    0.8279     25000\n",
      "weighted avg     0.8479    0.8301    0.8279     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.83012\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9130    0.7423    0.8189     12500\n",
      "           0     0.7829    0.9293    0.8498     12500\n",
      "\n",
      "    accuracy                         0.8358     25000\n",
      "   macro avg     0.8480    0.8358    0.8344     25000\n",
      "weighted avg     0.8480    0.8358    0.8344     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.8358\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9138    0.7385    0.8168     12500\n",
      "           0     0.7806    0.9303    0.8489     12500\n",
      "\n",
      "    accuracy                         0.8344     25000\n",
      "   macro avg     0.8472    0.8344    0.8329     25000\n",
      "weighted avg     0.8472    0.8344    0.8329     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.8344\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9119    0.7421    0.8183     12500\n",
      "           0     0.7826    0.9283    0.8492     12500\n",
      "\n",
      "    accuracy                         0.8352     25000\n",
      "   macro avg     0.8472    0.8352    0.8338     25000\n",
      "weighted avg     0.8472    0.8352    0.8338     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.8352\n",
      "results of the model trained using  9  layers \n",
      "5  ->  0.61312\n",
      "6  ->  0.69984\n",
      "7  ->  0.74272\n",
      "8  ->  0.7998\n",
      "9  ->  0.83012\n",
      "10  ->  0.8358\n",
      "11  ->  0.8344\n",
      "12  ->  0.8352\n",
      "initializing bertforsequenceclassification\n",
      "initializing weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model trained with 10 number of layers\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/notebooks/../model/10model.pt\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5256    0.9518    0.6772     12500\n",
      "           0     0.7451    0.1408    0.2368     12500\n",
      "\n",
      "    accuracy                         0.5463     25000\n",
      "   macro avg     0.6354    0.5463    0.4570     25000\n",
      "weighted avg     0.6354    0.5463    0.4570     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.54632\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5860    0.9648    0.7291     12500\n",
      "           0     0.9005    0.3184    0.4704     12500\n",
      "\n",
      "    accuracy                         0.6416     25000\n",
      "   macro avg     0.7432    0.6416    0.5998     25000\n",
      "weighted avg     0.7432    0.6416    0.5998     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.6416\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5591    0.9868    0.7138     12500\n",
      "           0     0.9438    0.2218    0.3591     12500\n",
      "\n",
      "    accuracy                         0.6043     25000\n",
      "   macro avg     0.7515    0.6043    0.5365     25000\n",
      "weighted avg     0.7515    0.6043    0.5365     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.60428\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5241    0.9967    0.6870     12500\n",
      "           0     0.9667    0.0951    0.1732     12500\n",
      "\n",
      "    accuracy                         0.5459     25000\n",
      "   macro avg     0.7454    0.5459    0.4301     25000\n",
      "weighted avg     0.7454    0.5459    0.4301     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.54592\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6994    0.9749    0.8145     12500\n",
      "           0     0.9586    0.5810    0.7235     12500\n",
      "\n",
      "    accuracy                         0.7779     25000\n",
      "   macro avg     0.8290    0.7779    0.7690     25000\n",
      "weighted avg     0.8290    0.7779    0.7690     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.77792\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8359    0.9166    0.8744     12500\n",
      "           0     0.9077    0.8201    0.8616     12500\n",
      "\n",
      "    accuracy                         0.8683     25000\n",
      "   macro avg     0.8718    0.8683    0.8680     25000\n",
      "weighted avg     0.8718    0.8683    0.8680     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.86832\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8504    0.9062    0.8774     12500\n",
      "           0     0.8996    0.8406    0.8691     12500\n",
      "\n",
      "    accuracy                         0.8734     25000\n",
      "   macro avg     0.8750    0.8734    0.8732     25000\n",
      "weighted avg     0.8750    0.8734    0.8732     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.87336\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8529    0.9065    0.8788     12500\n",
      "           0     0.9002    0.8436    0.8710     12500\n",
      "\n",
      "    accuracy                         0.8750     25000\n",
      "   macro avg     0.8765    0.8750    0.8749     25000\n",
      "weighted avg     0.8765    0.8750    0.8749     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.87504\n",
      "results of the model trained using  10  layers \n",
      "5  ->  0.54632\n",
      "6  ->  0.6416\n",
      "7  ->  0.60428\n",
      "8  ->  0.54592\n",
      "9  ->  0.77792\n",
      "10  ->  0.86832\n",
      "11  ->  0.87336\n",
      "12  ->  0.87504\n",
      "initializing bertforsequenceclassification\n",
      "initializing weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model trained with 11 number of layers\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/notebooks/../model/11model.pt\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5736    0.9258    0.7083     12500\n",
      "           0     0.8078    0.3117    0.4498     12500\n",
      "\n",
      "    accuracy                         0.6188     25000\n",
      "   macro avg     0.6907    0.6188    0.5791     25000\n",
      "weighted avg     0.6907    0.6188    0.5791     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.61876\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6458    0.8952    0.7503     12500\n",
      "           0     0.8292    0.5090    0.6308     12500\n",
      "\n",
      "    accuracy                         0.7021     25000\n",
      "   macro avg     0.7375    0.7021    0.6905     25000\n",
      "weighted avg     0.7375    0.7021    0.6905     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.70208\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6448    0.9111    0.7552     12500\n",
      "           0     0.8486    0.4981    0.6277     12500\n",
      "\n",
      "    accuracy                         0.7046     25000\n",
      "   macro avg     0.7467    0.7046    0.6914     25000\n",
      "weighted avg     0.7467    0.7046    0.6914     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.7046\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6211    0.9414    0.7484     12500\n",
      "           0     0.8791    0.4257    0.5736     12500\n",
      "\n",
      "    accuracy                         0.6836     25000\n",
      "   macro avg     0.7501    0.6836    0.6610     25000\n",
      "weighted avg     0.7501    0.6836    0.6610     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.68356\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7214    0.9429    0.8174     12500\n",
      "           0     0.9176    0.6358    0.7512     12500\n",
      "\n",
      "    accuracy                         0.7894     25000\n",
      "   macro avg     0.8195    0.7894    0.7843     25000\n",
      "weighted avg     0.8195    0.7894    0.7843     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.78936\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8569    0.8729    0.8648     12500\n",
      "           0     0.8705    0.8542    0.8623     12500\n",
      "\n",
      "    accuracy                         0.8636     25000\n",
      "   macro avg     0.8637    0.8636    0.8635     25000\n",
      "weighted avg     0.8637    0.8636    0.8635     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.86356\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8898    0.8211    0.8541     12500\n",
      "           0     0.8339    0.8983    0.8649     12500\n",
      "\n",
      "    accuracy                         0.8597     25000\n",
      "   macro avg     0.8619    0.8597    0.8595     25000\n",
      "weighted avg     0.8619    0.8597    0.8595     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.85972\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8910    0.8106    0.8489     12500\n",
      "           0     0.8263    0.9008    0.8619     12500\n",
      "\n",
      "    accuracy                         0.8557     25000\n",
      "   macro avg     0.8586    0.8557    0.8554     25000\n",
      "weighted avg     0.8586    0.8557    0.8554     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.85572\n",
      "results of the model trained using  11  layers \n",
      "5  ->  0.61876\n",
      "6  ->  0.70208\n",
      "7  ->  0.7046\n",
      "8  ->  0.68356\n",
      "9  ->  0.78936\n",
      "10  ->  0.86356\n",
      "11  ->  0.85972\n",
      "12  ->  0.85572\n",
      "initializing bertforsequenceclassification\n",
      "initializing weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model trained with 12 number of layers\n",
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/notebooks/../model/12model.pt\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5015    0.9776    0.6629     12500\n",
      "           0     0.5570    0.0282    0.0536     12500\n",
      "\n",
      "    accuracy                         0.5029     25000\n",
      "   macro avg     0.5292    0.5029    0.3583     25000\n",
      "weighted avg     0.5292    0.5029    0.3583     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.50288\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5068    0.8746    0.6418     12500\n",
      "           0     0.5430    0.1490    0.2338     12500\n",
      "\n",
      "    accuracy                         0.5118     25000\n",
      "   macro avg     0.5249    0.5118    0.4378     25000\n",
      "weighted avg     0.5249    0.5118    0.4378     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.5118\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5096    0.8883    0.6477     12500\n",
      "           0     0.5654    0.1453    0.2312     12500\n",
      "\n",
      "    accuracy                         0.5168     25000\n",
      "   macro avg     0.5375    0.5168    0.4394     25000\n",
      "weighted avg     0.5375    0.5168    0.4394     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.5168\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5300    0.8503    0.6530     12500\n",
      "           0     0.6216    0.2459    0.3524     12500\n",
      "\n",
      "    accuracy                         0.5481     25000\n",
      "   macro avg     0.5758    0.5481    0.5027     25000\n",
      "weighted avg     0.5758    0.5481    0.5027     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.54812\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.5530    0.9830    0.7079     12500\n",
      "           0     0.9238    0.2055    0.3362     12500\n",
      "\n",
      "    accuracy                         0.5943     25000\n",
      "   macro avg     0.7384    0.5943    0.5220     25000\n",
      "weighted avg     0.7384    0.5943    0.5220     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.59428\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6139    0.9898    0.7578     12500\n",
      "           0     0.9736    0.3776    0.5442     12500\n",
      "\n",
      "    accuracy                         0.6837     25000\n",
      "   macro avg     0.7938    0.6837    0.6510     25000\n",
      "weighted avg     0.7938    0.6837    0.6510     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.68368\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6752    0.9842    0.8009     12500\n",
      "           0     0.9709    0.5265    0.6827     12500\n",
      "\n",
      "    accuracy                         0.7554     25000\n",
      "   macro avg     0.8231    0.7554    0.7418     25000\n",
      "weighted avg     0.8231    0.7554    0.7418     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.75536\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7906    0.9453    0.8610     12500\n",
      "           0     0.9320    0.7496    0.8309     12500\n",
      "\n",
      "    accuracy                         0.8474     25000\n",
      "   macro avg     0.8613    0.8474    0.8460     25000\n",
      "weighted avg     0.8613    0.8474    0.8460     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.84744\n",
      "results of the model trained using  12  layers \n",
      "5  ->  0.50288\n",
      "6  ->  0.5118\n",
      "7  ->  0.5168\n",
      "8  ->  0.54812\n",
      "9  ->  0.59428\n",
      "10  ->  0.68368\n",
      "11  ->  0.75536\n",
      "12  ->  0.84744\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Evaluate the model trained using progressive shrinking.\n",
    "array = np.zeros((8,8))\n",
    "for i in range(5,13):\n",
    "    best_model = BERT().to(device)\n",
    "    print(\"loading model trained with \" + str(i) + \" number of layers\")\n",
    "    load_checkpoint(destination_folder +\"/\"+ str(i)+ 'model.pt', best_model)\n",
    "    for j in range(5,13):\n",
    "        acc = evaluate(best_model, test_iter, max_encoder_num=j)\n",
    "        array[i-5][j-5] = acc\n",
    "        print(\"accuracy when using \", j, \" layers : \", acc)\n",
    "    print(\"results of the model trained using \",i,\" layers \")\n",
    "    for j in range(5,13):\n",
    "        print(j, \" -> \", array[i-5][j-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4a1356d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81848"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2fa4c733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81848, 0.83168, 0.82952, 0.82248, 0.79808, 0.78276, 0.77948,\n",
       "        0.77752],\n",
       "       [0.6316 , 0.814  , 0.82156, 0.82484, 0.80056, 0.77772, 0.77052,\n",
       "        0.76716],\n",
       "       [0.60328, 0.79308, 0.84108, 0.84608, 0.82376, 0.80148, 0.79168,\n",
       "        0.78688],\n",
       "       [0.7458 , 0.70772, 0.76252, 0.85704, 0.86644, 0.85912, 0.85404,\n",
       "        0.85304],\n",
       "       [0.61312, 0.69984, 0.74272, 0.7998 , 0.83012, 0.8358 , 0.8344 ,\n",
       "        0.8352 ],\n",
       "       [0.54632, 0.6416 , 0.60428, 0.54592, 0.77792, 0.86832, 0.87336,\n",
       "        0.87504],\n",
       "       [0.61876, 0.70208, 0.7046 , 0.68356, 0.78936, 0.86356, 0.85972,\n",
       "        0.85572],\n",
       "       [0.50288, 0.5118 , 0.5168 , 0.54812, 0.59428, 0.68368, 0.75536,\n",
       "        0.84744]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9cd9de3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEGCAYAAAB4lx7eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAn5klEQVR4nO3deZwcVbnG8d+TsGRhkUVQAUnAIAgiIqKCcFEEoiioyK4CItHLpnK5CldEQFFxwRU0AQIISC6LYMTIIhDgsiZAWBIWQ9gSWURWkxhI5r1/1BlTTGa6azLdXV2d5+unPl37eXsGz5ycOvUeRQRmZlZdg8oOwMzMBsYVuZlZxbkiNzOrOFfkZmYV54rczKzilis7gBo8nMbMitJAb/Dac7MK1znLr7nBgMtrpHauyFluhXXKDoGFr85h+LARpcYwd95jrLrShqXGAPDSPx/hXW/aptQY7nn6Fg4YsUepMQCc+9il3PLmcuPY5qlLeflLu5QaA8AqY6/iX/dMKjWGIe/62MBv0rVo4PcoSVtX5GZmLRNdZUew1FyRm5kBdLkiNzOrtHCL3Mys4hYtLDuCpeaK3MwM/LDTzKzy3LViZlZxfthpZlZtfthpZlZ1bpGbmVXcotfKjmCpOWmWmRlkDzuLLnVIGi3pIUkzJR3Ty/G3Srpe0t2S7pX0sbR/hKT5kqal5TdFQneL3MwMGta1ImkwcBqwEzAbmCJpYkTMyJ12HHBRRPxa0juAScCIdOyRiNiiP2W2VYtc0hhJUyVNHTduXNnhmNmypHEt8q2BmRExKyJeBSYAu/csDVglra8K/G0goTelIpe0iqTvSzpP0n49jp3e13URMS4itoqIrcaMGdOM0MzMetfVVXjJNzrTkq+w1gGezG3PTvvyTgA+K2k2WWv8iNyxkanL5QZJ2xUJvVldK2cDfwUuBb4gaQ9gv4hYALy/SWWamS216Cr+sDMixgED6TbYFzgnIn4i6QPAeZI2A54C3hoR/5D0HuBySZtGxMu1btasrpUNI+KYiLg8InYD7gKuk7RGk8ozMxuYfrTI65gDrJfbXjftyzsYuAggIm4FhgBrRsSCiPhH2n8n8AiwUb0Cm1WRryjp3/eOiJOBM4AbAVfmZtZ+GtdHPgUYJWmkpBWAfYCJPc55AtgRQNImZBX53yW9MT0sRdIGwChgVr0Cm9W18kfgw8BfundExDmSngZ+2aQyzcyWXoOSZkXEQkmHA1cBg4HxETFd0knA1IiYCPwXcIakr5E9+DwwIkLS9sBJkl4DuoAvR8Tz9cpsSkUeEV/vY/+Vkr7XjDLNzAakga/oR8QksoeY+X3H59ZnANv2ct2lZM8W+6WM4YcnllCmmVltjesjb7mmtMgl3dvXIWDtZpRpZjYgnlhiCWsDuwAv9Ngv4JYmlWlmtvTasKVdVLMq8iuAlSJiWs8DkiY3qUwzs6UW4RmCXiciDq5xbL++jpmZlcYtcjOzivPEEmZmFVfhFrkiouwY+tK2gZlZ29FAbzD/6tML1zlDdz50wOU1Up8tcklH1bowIk5tfDiv980R5Xenn/zY73hwo4+VGsPGD0/ioY0/WmoMAG9/8M/c8uY9So1hm6cuZd7Pv1xqDADDvvIbXn38rlJjWGH9LVnwyG2lxgCw4obvZ8GDN5Qbw8b/MfCbdGjXysoti8LMrGwV7lrpsyKPCL+BaWbLjgpX5HVf0Ze0kaRrJd2ftjeXdFzzQzMza6EGztnZakVyrZwBHAu8BhAR95KlZTQz6xyLFhZf2kyR4YfDIuIO6XUPadvvm5iZDUSFu1aKVOTPSdqQNBxQ0mfIpiMyM+scbdhlUlSRivwwsrnpNpY0B3gU+GxTozIza7VObpFHxCzgI5KGA4Mi4pXmh2Vm1mKdWJH39UJQd195K14IMjNrmfZ9y72uIi8EvR14L4snD/0EcEczgzIza7mF1R3DUfeFIEk3Alt2d6lIOgH4U0uiMzNrlQo/7Cwyjnxt4NXc9qs0abo2SWMkTZU0ddy4cc0owsysdw2cs1PSaEkPSZop6Zhejr9V0vWS7pZ0r6SP5Y4dm657SNIuRUIvMmrlt8Adki4jyzC2O3BOkZv3RtKfI6LXDFARMY5shAxAfPN7k5e2GDOz/mlQH7mkwcBpwE7AbGCKpIkRMSN32nHARRHxa0nvACYBI9L6PsCmwFuAv0jaKOpMX1Rk1MrJkv4MbEc2lvygiLi7zhfZsq9DwBb1yjQza7nGjVrZGpiZRvwhaQJZAzhfkQewSlpfFfhbWt8dmBARC4BHJc1M97u1VoFFJ5ZYBHSlwot82ynADfSeI/gNBcs0M2udflTkksYAY3K7xqUeBYB1gCdzx2YD7+txixOAqyUdAQwHPpK7Np+beHbaV1PdilzSV4BDgEvJKubzJY2LiF/WuOwB4EsR8dde7vdkL+ebmZUqFhWffLlHN/DS2Bc4JyJ+IukDwHmSNlvamxVpkR8MvC8i5gJIOoWsmV+rIj+Bvh+kHtGfAM3MWqJxXStzgPVy2+umfXkHA6MBIuJWSUOANQteu4Qio1ZE1rXSbRF1plWKiEsi4qE+Dq9WoEwzs9ZqXBrbKcAoSSMlrUD28HJij3OeAHYEkLQJMAT4ezpvH0krShoJjKLAeztFWuRnA7enUSsAnwTOKnBdX05M9zQzax9djRm1EhELJR0OXAUMBsZHxHRJJwFTI2Ii8F/AGZK+Rvbs8cDIJlCeLukisgejC4HD6o1YgWKjVk6VNBn4YNpVZNTKvX0doklj0M3MBqSBuVYiYhLZkML8vuNz6zOAbfu49mTg5P6UV3TUyqNkfx2WAyRpy4ioNfPs2sAuwAs99gu4pT8Bmpm1RD8edrabIqNWvgMcCDxCykmePj9c47IrgJUiYlov95vc3yDNzJquE7Mf5uwFbBgRr9Y9M4mIg2sc26/ofczMWqZBfeRlKFKR30/2Es+zzQ3FzKxEFU6aVaQi/z5wt6T7gQXdOyNit6ZFZWbWahVukSvqJIqRNB0YC9xH7vX8iLihuaFR3Z+qmbVazXdbipj7/QMK1znDjz13wOU1UpEW+byI+EXTI+nFZmu/v4xiX+f+Z27j9PXKnaL00CfP59ARe5UaA8Dpj11U+u/k/mduY+53y58ydvhx5/Pq36aXGsMKb9mU155dIgtGyy2/1ihee25WuTGsucHAb9LJo1aAmyR9n+yNo3zXSq3hh2Zm1VLhrpUiFfm702e+KVZv+KGZWbV08vDDiPhQKwIxMytVh7fIzcw6X4cPPzQz63xukZuZVVss7MBRK5I+XevCiPh948MxMytJh7bIP5E+1wK2Aa5L2x8iy2DoitzMOkcn9pFHxEEAkq4G3hERT6XtNwPntCQ6M7NW6dAWebf1uivx5BngrU2Kx8ysFNHhFfm1kq4CLkzbewN/aV5IZmYl6MSHnd0i4nBJnwK2T7vGRcRlta5ZWpLGAGMAxo4d24wizMx61+EtcoC7gFci4i+ShklaOSJe6etkSasCx5JN1LwW2Sv9zwJ/AH4QES/2dl1EjAPGdW/+4lvjC4ZnZjZAFa7IB9U7QdIhwCVkqWwB1gEur3PZRWTzde4QEatHxBpko11eSMfMzNpKRBRe6pE0WtJDkmZKOqaX4z+VNC0tD0t6MXdsUe7YxCKxF2mRHwZsDdyevuxfJa1V55oREXFKfkdEPA2cIukLRQIzM2upBrXIJQ0GTgN2AmYDUyRNjIgZ3edExNdy5x/B4uSEAPMjYov+lFm3RQ4syM/XKWk56k/68Likr0taO3fd2pK+ATzZnwDNzFqiK4ovtW0NzIyIWanunADsXuP8fVk8mGSpFKnIb5D0P8BQSTsBFwN/rHPN3sAa6drnJT0PTAZWB/YcQLxmZk0RC7sKL5LGSJqaW8bkbrUOr2+wzk77liBpfWAki1+4BBiS7nmbpE8Wib1I18oxwMFkU719CZgEnFnrgoh4AfhGWnoGfhBwdpHgzMxaph8vdvYYmDEQ+wCXRER+7OP6ETFH0gbAdZLui4hHat2kyPDDLuCMtDTCibgiN7M208AXguYA6+W21037erMP2XPIxXFEzEmfsyRNJus/H1hFLmlb4ARg/XS+sjKiz0nyJN3b1yFg7T6OmZmVp3EV+RRglKSRZBX4PsB+PU+StDGwGnBrbt9qZPMkL5C0JrAt8MN6BRbpWjkL+BpwJ1D01ae1gV3IhhvmiSzhlplZe2lQzqyIWCjpcOAqYDAwPiKmSzoJmBoR3UMK9wEmxOvHM24CjJXURfYM8wf50S59KVKRvxQRf+7XN4ErgJUiYlrPA+mfCmZmbaWRuVYiYhLZ88T8vuN7bJ/Qy3W3AO/sb3lFKvLrJf2ILG3tglyBd/V1QUQcXOPYEv/EMDMrWyys7pudRSry96XPrXL7Avhw48MxMytJddORFxq18qFWBGJmVqYKzyuB+sobIOmzEXG+pKN6Ox4RpzY1svpvj5qZddNAb/CPXf+jcJ2zxp9uGHB5jVSrRT48fa7cikB6c/SIfcsq+t9+/NiFzNhw11JjeMcjf+KFPXcoNQaA1S6ezPyzji41hqEH/5j519d8H601cXzoi/zr5gtKjWHItvvzr5vOKzUGgCHbfa70OIZs97kB36PKLfJaU72NTZ8nti4cM7NyxMKyI1h6RV4IGkL2iv6mwJDu/RHhLIZm1jGq3CIvkjTrPOBNZC/43ED2ummfk0qYmVVRdBVf2k2RivxtEfEtYG5EnAvsyuIhiWZmnSFUfGkzRcaRv5Y+X5S0GfA02fRtZmYdox1b2kUVqcjHpUQuxwETgZWAbzU1KjOzFouu9mtpF1WzIpc0CHg55Re/Eegz46GZWZV1LapuRV6zjzzlIv96i2IxMytNlR92Fula+Yuko4H/BeZ274yI55sWlZlZi3Vs10qyd/rMz2IRuJvFzDpIH9lKKqFIRb5JRPwrvyO9JFRTmm/u02RTHi0CHgZ+FxEvL02gZmbNVOUWeZFx5L3N6FNzlh9JRwK/IXsT9L3AimQV+m2Sdqhx3b9nph43rhHzmpqZFdO1SIWXdtNni1zSm4B1gKGS3s3i7GKrAMPq3PcQYIuIWCTpVGBSROwgaSzwB7LJRJfQY2bqOPp71xf/JmZmA1DlFnmtrpVdgAPJXsn/CYsr8peB/yl470VkrfGVACLiCUnLL22wZmbNEm34xmZRtbIfngucK2mPiLi0n/c9E5gi6XZgO+AUAElvBDzaxczaTjsOKyyqbh/5UlTiRMTPgX3JZpH+ZEScnfb/PSK273eUZmZN1hUqvNQjabSkhyTNlHRML8d/KmlaWh6W9GLu2AGS/pqWA4rEXmTUylKJiOnA9Gbd38yskRrVtSJpMHAasBMwm6x3YmJEzFhcVnwtd/4RpOeGklYHvk02R3IAd6ZrX6hVZpFRK2ZmHa+Bo1a2BmZGxKyIeBWYAOxe4/x9gQvT+i7ANRHxfKq8rwFG1yuwbkUuaZikb0k6I22PkvTxeteZmVVJdKnwUsc6wJO57dlp3xIkrQ+MBK7r77V5RVrkZwMLgA+k7TnAdwtcZ2ZWGf3pI8+/85KWMUtZ7D7AJRGxaCCxF+kj3zAi9pa0L0BEzJNU3XE6Zma96E8feY93XnqaQ/YCZLd1077e7MPr05/MAXboce3kevEUaZG/KmkoWcc7kjYka6GbmXWMiOJLHVOAUZJGSlqBrLKe2PMkSRsDqwG35nZfBewsabU0D8TOaV9NRVrk3wauBNaTdAGwLdmLQmZmHaPIsMIiImKhpMPJKuDBwPiImC7pJGBqRHRX6vsAEyIW/2mIiOclfYfsjwHASUUyzdatyCPiGkl3Ae8ne7vzKxHxXL++mZlZm+tq4Cv6ETEJmNRj3/E9tk/o49rxwPj+lFd0HPkQ4IV0/jskERE39qcgM7N21qgWeRkUdTp8JJ1ClpN8OtD9EmtExG5Njq3C2YHNrMUGXAtPWedTheuc9865rK1q/SIt8k8Cb4+Ilj/gfHH/D7e6yCW84YLrmPmOXUqN4W0zruKVr36i1BgAVv7ZH1nw8P+VGsOKG32QV2ffV2oMACus+04WPHJbqTGsuOH7WfBA+RlCV9zkQyyYfm25MWy644DvUeUWeZGKfBawPB6pYmYdrMpdALXykf+S7LvNA6ZJupZcZR4RRzY/PDOz1ljUVd2MJbVa5FPT550sOQayyn+8zMyWUOEstnXzkSPpKykt7b9J+kqzAzMza6UY+PPS0hT5t0Rv+XAPbHAcZmal6oriS7up1Ue+L7AfMFJSvmtlZTzLj5l1mK4Kt8hr9ZHfAjwFrEk2Z2e3V4B7mxmUmVmrVblrpVYf+ePA4yxOX2tm1rEWdWJFbma2LOnIUStmZsuSKlfkNUetSBqcUtf2i6QVJH1e0kfS9n6SfiXpMEnLL22wZmbNEqjw0m5qtsgjYpGk9SWtkCYRLersdO9hkg4AVgJ+D+xINjFpb0MazcxK08Asti1XNNfKzWkI4tzunRFxao1r3hkRm0tajmzqorekPwrnA/f0dVGa924MwNixY9mryDcwM2uATh1+2O2RtAwiG0NexKA0xdFwYBiwKtnY8xXJEnD1qsc8ePHiDRMKFmdmNjADmv24ZEVmCDoRQNJKafufBe57FvAg2TRH3wQuljSLbJYh185m1na6KjynfN2KXNJmwHnA6mn7OeDzETG9r2si4qeS/jet/03Sb4GPAGdExB0NidzMrIHa8M37wop0rYwDjoqI6wEk7QCcAWxT66KI+Ftu/UXgkqUN0sys2ao8/LBIRT68uxIHiIjJkoY3MSYzs5ar8qiVItkPZ0n6lqQRaTmObCSLmVnHWIQKL/VIGi3pIUkzJR3Txzl7SZohabqk3+X2L5I0LS0954LoVZEW+ReAE8nGgQdwU9pnZtYxGtUilzQYOA3YCZgNTJE0MSJm5M4ZBRwLbBsRL0haK3eL+RGxRX/KrJXG9ryI+BzZg01P62ZmHa2BfeRbAzMjYhaApAnA7sCM3DmHAKdFxAsAEfHsQAqs1bXyHklvAb4gaTVJq+eXgRRqZtZuoh+LpDGSpuaWMblbrQM8mduenfblbQRsJOlmSbdJGp07NiTd8zZJnywSe62uld8A1wIbkM3bmf+HR6T9ZmYdoT9dKz1eXlwaywGjgB2AdYEbJb0zjfBbPyLmSNoAuE7SfRHxSK2b9dkij4hfRMQmwPiI2CAiRuYWV+Jm1lG6+rHUMQdYL7e9btqXNxuYGBGvRcSjwMNkFTsRMSd9zgImA++uV2DdUSsR8Z/14zYzq7ZFKr7UMQUYJWlkSlWyD9Bz9MnlZK1xJK1J1tUyK3Vjr5jbvy2v71vvlSLa9n2mtg3MzNrOgMecnL7eZwvXOYc+eX7N8iR9DPgZWZqS8RFxsqSTgKkRMVGSyKbQHE2W5uXkiJggaRtgLFnDfxDws4g4q148bV2RHzqi/PyHpz92EfNOO7zUGIYd9iv+dcfFpcYAMGTrPfnXtCvKjWGLjzP/z78oNQaAoR89kvlnf73cGA76IfN+eWipMQAMO+J05p16SLkxHHXGgCvyX/WjIj+8TkXeanW7ViQNlzQorW8kaTdPDmFmnaY/o1baTZE3O28kGw6zDnA18DngnGYGZWbWal0qvrSbIhW5ImIe8Gng9IjYE9i0uWGZmbVWA0ettFyRV/Ql6QPA/sDBad/g5oVkZtZ6HT2xBPAVspwAl0XE9DRI/fo615iZVUo7dpkUVbMiT8lfdouI3br3pUHqzr1iZh2lHbtMiqpZkacJkz/YqmDMzMrSjqNRiirStXJ3yol7MTC3e2dE/L5pUZmZtVhXhavyIhX5EOAfwIdz+4IsP7mZWUfo6IedEXFQKwIxMytTlfvIi7zZuZGkayXdn7Y3T9O91brmSEnr1TrHzKyddPoLQWeQDT98DSAi7iXL5lXLd4DbJd0k6VBJbxxYmGZmzdVFFF7aTZGKfFhE3NFj38I618wiy8H7HeA9wAxJV0o6QNLKfV2Un3Vj3LiB5Gw3M+ufKudaKfKw8zlJG5Lil/QZ4Kk610REdJHlZrk6Jdn6KLAv8GOg1xZ6j1k34tDv/aVAeGZmA1flPvIiFflhZJXrxpLmAI+Sva5fy+t6kSLiNbLE6hMlDVuaQM3MmmlRW7a1iylSkT8eER+RNBwYFBGvFLhm774OpARcZmZtpcot8iJ95H+V9CPgrQUrcSLi4YGFZWbWWp3+sPNdZBODniXptvRAcpUmx2Vm1lJVfthZZPLlVyLijIjYBvgG8G3gKUnnSnpb0yM0M2uBjs5HnjIg7gocBIwgmzD0AmA7YBLZ7M9mZpVW5YedhfrIgd2BH0XEuyPi1Ih4JiIuAa5sbnhmZq3RyD5ySaMlPSRppqRj+jhnL0kzJE2X9Lvc/gMk/TUtBxSJvciolc0j4p+9HYgI5yU3s47QqPZ46sU4DdgJmA1MkTQxImbkzhlF9sb8thHxgqS10v7Vybqvt0oh3ZmufaFWmUUq8oWSDiObp3NI986I+EK/vp2ZWRtr4GiUrYGZaRIeJE0g69WYkTvnEOC07go6Ip5N+3cBromI59O11wCjgQtrFVika+U84E2pgBvIXr0vNAzRzKwq+vOwM59OJC1jcrdaB3gytz077cvbCNhI0s1pNODofly7hCIt8rdFxJ6Sdo+Ic1Nfzk0FrjMzq4zoR4u8RzqRpbEcMArYgaxxfKOkdw7kZvW8lj5flLQZ8DSw1tIW2B+nP3ZRK4qpa9hhvyo7BIZsvWfZIQAwZIuPlx0CQz/aHo9mhh70w7JDYNgRp5cdAgDDjjqj7BAGrIGjVuYA+TTe66Z9ebOB21P6kkclPUxWsc8hq9zz106uV2CRinycpNWAb5HlS1kJOL7AdQP2w/U/24piavr64+cz//ffKzWGoZ/+H+b/6WelxgAwdNevMv+qcv+oDd3lcOafdXSpMQAMPfjHzP1uuf99Dj/ufOZ+s/w/8MNPvph//venSo1hpR9dNuB7NHB8+BRglKSRZBXzPsB+Pc65nCyJ4NmS1iTrapkFPAJ8L9W5ADuTPRStqcgMQWem1RuADep/BzOz6umKxrTII2KhpMOBq4DBwPiImC7pJGBqRExMx3aWNINslrn/joh/AEj6DtkfA4CTuh981tJnRS7pqDrBnlrkS5mZVUEjXweKiElkL0zm9x2fWw/gqLT0vHY8ML4/5dVqkfc5AYSZWadpx2RYRfVZkUfEia0MxMysTP0ZtdJuijzsNDPreAtdkZuZVZtb5GZmFdeO6WmLKpLG9g3A58lS2P77fCfMMrNOEg0afliGIi3yScBtwH1U+4+WmVmfOnLUSs6QiKg5ptzMrOo6fWKJ8yQdIunNklbvXmpdIOl93fN6Shoq6URJf5R0iqRVGxK5mVkDdfrky68CPwJuBe5My9Q614wH5qX1nwOrAqekfWcvVaRmZk0UEYWXdlOka+W/yFLZPteP+w6KiIVpfauI2DKt/5+kaX1dlHL6jgEYO3ZsP4ozMxuYKj8ALNIin8ni1nVR90s6KK3fI2krAEkbsTgt7hIiYlxEbBURW40ZM6av08zMGi768b92U6RFPheYJul6YEH3zjrDD78I/FzSccBzwK2SniSb+eKLA4jXzKwp2rHvu6giFfnlaSksIl4CDkwPPEemcmZHxDP9DdDMrBUWRXU7V4rkIz93aW8eES8D9yzt9WZmrdKOXSZFFXmz81F6SdUbEZ5kwsw6RqMmlihDka6VrXLrQ4A9gZrjyM3Mqqa61XixrpV/9Nj1M0l30qJ5O83MWqGjH3ZK2jK3OYishe6siWbWUTq6Igd+kltfCDwG7NWUaMzMStLpo1Y+1IpAzMzK1MhRK5JGk6UnGQycGRE/6HH8QLLUJ3PSrl9FxJnp2CKybLMAT0TEbvXKK9K1siKwB0vmIz+p3rVmZlXRqBwqkgYDpwE7AbOBKZImRsSMHqf+b0Qc3sst5kfEFv0ps0jXyh+Al8iSZS2oc66ZWSU1sI98a2BmRMwCkDQB2B3oWZE3TJGKfN2IGN2sAMzM2kF/WuT5BH/JuIgYl9bXIUtH0m028L5ebrOHpO2Bh4GvRUT3NUMkTSV7JvmDiLi8bjz1gpc0DvhlRNxX88TGq+4jZDNrNQ30Bpu/6QOF65x7n761z/IkfQYYHRFfTNufA96X70aRtAbwz4hYIOlLwN4R8eF0bJ2ImCNpA+A6YMeIeKRWPEVa5B8ky5vyKFnXioCIiM0LXDsg8yf+uNlF1DV0t6OZP3l8uTHs8AXmXzuu/onNjmPHMcz/08/KjWHXrzL/zPInrBr6xVOZd8pB9U9somHfOJu5J3++1BgAhn/zt8w9af9yYzj+ggHfo4Fvds4B1sttr8vih5rAEu/nnAn8MHdsTvqcJWky8G5gwBX5RwucY2ZWaQ0ctTIFGCVpJFkFvg+wX/4ESW+OiKfS5m7AA2n/asC81FJfE9iWXCXflyLDDx/v11cwM6ugRrXII2KhpMOBq8iGH46PiOmSTgKmRsRE4EhJu5H1gz8PHJgu3wQYK6mL7AXMH/Qy2mUJfkPTzIzGjiOPiEnApB77js+tHwsc28t1twDv7G95rsjNzOj87IdmZh2vo1/RNzNbFnT0xBJmZsuCcIvczKzaOj2NrZlZx2tU0qwytKQil/RBskQy90fE1a0o08ysP6rcIh/UjJtKuiO3fgjwK2Bl4NuSjmlGmWZmA7Goq6vw0m6aUpEDy+fWxwA7RcSJwM5An0kZJI2RNFXS1HHjys8tYmbLjujH/9pNs7pWBqWcAYPIMiz+HSAi5kpa2NdFKQ1kdw0e7ZA0y8yWDe4jX9KqZBNRCIjuBDGSVqIB6SbNzBqtyn3kTanII2JEH4e6gE81o0wzs4Fwi7ygiJgHPNrKMs3MimjHh5hFeRy5mRnuWjEzqzx3rZiZVZzT2JqZVVw7jg8vyhW5mRlukZuZVV6X09iamVWbH3aamVWcK3Izs4qrbjWeJbQqO4amkTQmJeJapmNolzjaIYZ2iaMdYmiXONohhqprVhrbdjGm7ABojxigPeJohxigPeJohxigPeJohxgqrdMrcjOzjueK3Mys4jq9Im+Hfrd2iAHaI452iAHaI452iAHaI452iKHSOvphp5nZsqDTW+RmZh3PFbmZWcV1bEUu6TFJ90maJmlqSTG8QdIlkh6U9ICkD5QQw9vTz6B7eVnSV0uI42uSpku6X9KFkoaUEMNXUvnTW/kzkDRe0rOS7s/tW13SNZL+mj5XKymOPdPPo0vSViXF8KP0/5F7JV0m6Q3NjqPTdGxFnnwoIraIiKb/B9qHnwNXRsTGwLuAB1odQEQ8lH4GWwDvAeYBl7UyBknrAEcCW0XEZsBgYJ8Wx7AZcAiwNdnv4uOS3tai4s8BRvfYdwxwbUSMAq5N22XEcT/waeDGFpTfVwzXAJtFxObAw8CxLYqlY3R6RV4aSasC2wNnAUTEqxHxYqlBwY7AIxHxeAllLwcMlbQcMAz4W4vL3wS4PSLmRcRC4AayCqzpIuJG4Pkeu3cHzk3r5wKfLCOOiHggIh5qdtl1Yrg6/U4AbgPWbVU8naKTK/IArpZ0p6Qy3hwbCfwdOFvS3ZLOlDS8hDjy9gEubHWhETEH+DHwBPAU8FJEXN3iMO4HtpO0hqRhwMeA9VocQ97aEfFUWn8aWLvEWNrJF4A/lx1E1XRyRf7BiNgS+ChwmKTtW1z+csCWwK8j4t3AXFrzz+deSVoB2A24uISyVyNrgY4E3gIMl/TZVsYQEQ8ApwBXA1cC04BFrYyhL5GNAV7mxwFL+iawELig7FiqpmMr8tQKJCKeJesT3rrFIcwGZkfE7Wn7ErKKvSwfBe6KiGdKKPsjwKMR8feIeA34PbBNq4OIiLMi4j0RsT3wAll/bFmekfRmgPT5bImxlE7SgcDHgf3DL7f0W0dW5JKGS1q5ex3Ymeyf1i0TEU8DT0p6e9q1IzCjlTH0sC8ldKskTwDvlzRMksh+Fi1/8CtprfT5VrL+8d+1OoacicABaf0A4A8lxlIqSaOBrwO7RcS8suOpoo58s1PSBiwembEc8LuIOLmEOLYAzgRWAGYBB0XECyXEMZysMt0gIl5qdfkphhOBvcn+6Xw38MWIWNDiGG4C1gBeA46KiGtbVO6FwA7AmsAzwLeBy4GLgLcCjwN7RUTPB6KtiON54JfAG4EXgWkRsUuLYzgWWBH4Rzrttoj4crNi6EQdWZGbmS1LOrJrxcxsWeKK3Mys4lyRm5lVnCtyM7OKc0VuZlZxrsitJkknSDq67DiaQdLk3jL+SdouZQScJmloGbHlYuk1RrM8V+RWqpREq93sD3w/ZY2cX+/kNv0OtgxxRV5RkkakHOdnpNbj1d2tx3wrTtKakh5L6wdKujzlv35M0uGSjkpJvW6TtHqdMg+RNEXSPZIuTW9qrizpUUnLp3NW6d6WtKGkK1PispskbZzOOUfSbyTdDvxQ0n/k8qXf3f1Wbo/vms9ffbSkE9L6kZJmpFzWE9K+4Snv9R3pfrun/UMlTUg/t8uAJVrbkr4I7AV8R9IFyvxIWR7z+yTtnc7bIX2nifTyxq6knSXdKukuSRdLWknSaEkX587ZQdIVaf3Xkqam3+WJtX4PZkuICC8VXIARZG9JbpG2LwI+m9Ynk+X+huwNusfS+oHATGBlsjf5XgK+nI79FPhqL+WcAByd1tfI7f8ucERaPxv4ZFofA/wkrV8LjErr7wOuS+vnAFcAg9P2H4Ft0/pKwHK9fNf7c9tHAyek9b8BK6b1N6TP7+V+Fm8gy6kyHDgKGJ/2b55+flv18p3PAT6T1vcgy5c9mCxD4RPAm8neTpwLjOzl+jXJ8nsPT9vfAI4ne8v4idz+X+fiXD19Dk6/v817/i69eOlrcYu82h6NiGlp/U6yCq+e6yPilYj4O1lF/se0/74C12+WWqH3kXU/bJr2nwkclNYPIkvduxJZYqyLJU0DxpJVgN0ujoju7IM3A6dKOpKsMl5IcfcCF6Rsit3X7Qwck8qdDAwhexV+e+B8gIi4N11bzweBCyNiUWQJx24A3puO3RERj/ZyzfuBdwA3pxgOANZP3+tK4BOpO2ZXFudY2UvSXWTpCzZN15sV4r69asvnKlnE4q6ChSzuNus5pVr+mq7cdhf1/3s4h6zlfY+ybHU7AETEzan7YweyVvb9klYBXoxsZqLezO1eiYgfSPoTWY7wmyXtEhEP5s7Nf5+e32lXsgr6E8A3Jb0TELBH9JgwQVKdr9dvc/vYL+CaiNi3l2MTgMPJcpxMjYhXJI0k+1fGeyPiBUnnsOTvzaxPbpF3psfIpnUD+EwD77sy8FTqD9+/x7HfkmUTPBsgIl4GHpW0J0Dqa35XbzeVtGFE3BcRpwBTgI17nPIMsJaySSFWJEt3iqRBwHoRcT1Z98WqZF0zVwFHKNXckt6d7nMjsF/atxlZ90o9NwF7Sxos6Y1kfzTuqHPNbcC2SlPJpT77jdKxG8jSGR9CVqkDrEL2R+ElSWuTpRw2K8wVeWf6MfCfku4m669tlG8Bt5N1hTzY49gFwGq8PlXu/sDBku4BppNNLtGbr6aHifeSZSZ83QwxkeUwP4msAr0mV/Zg4PzU1XM38IvIptP7DrA8cK+k6Wkbsj7plSQ9kO53Z4HvfBlZF8w9wHXA1yNLUdyn1G11IHBh+k63kv44pe6kK8gq6yvSvntS/A+S/TG8uUBcZv/m7IfWEJI+A+weEZ8rOxazZY37yG3AJP2SrIX5sbJjMVsWuUVuZlZx7iM3M6s4V+RmZhXnitzMrOJckZuZVZwrcjOzivt/klG7mRIiZzcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(array,  linewidth=0.5,xticklabels=list(range(5,13)), yticklabels=list(range(5,13)))\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('num layers used for eval')\n",
    "ax.set_ylabel('num layers for the trained model')\n",
    "# ax.axis([5, 12,5,12])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f562a4",
   "metadata": {},
   "source": [
    "## Train using random number of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12fdc471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing bertforsequenceclassification\n",
      "initializing weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with random elasticity for 8 epochs.\n",
      "/home/ilee300/workspace/nlp_ofa/notebooks/../model/Nonemetrics.pt\n",
      "changing encoder number :  12  =>  10\n",
      "training for epoch  0  with encoder number of  10\n",
      "Epoch [1/8], Step [625/10000], Train Loss: 0.3570, Valid Loss: 0.3428\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/random_elasticity_model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../modelrandom_elasticity_metrics.pt\n",
      "Epoch [1/8], Step [1250/10000], Train Loss: 0.3962, Valid Loss: 0.3330\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/random_elasticity_model.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../modelrandom_elasticity_metrics.pt\n",
      "changing encoder number :  12  =>  5\n",
      "training for epoch  1  with encoder number of  5\n",
      "Epoch [2/8], Step [1875/10000], Train Loss: 0.3259, Valid Loss: 0.4095\n",
      "Epoch [2/8], Step [2500/10000], Train Loss: 0.3879, Valid Loss: 0.3645\n",
      "changing encoder number :  12  =>  11\n",
      "training for epoch  2  with encoder number of  11\n",
      "Epoch [3/8], Step [3125/10000], Train Loss: 0.1412, Valid Loss: 0.4550\n",
      "Epoch [3/8], Step [3750/10000], Train Loss: 0.2086, Valid Loss: 0.4283\n",
      "changing encoder number :  12  =>  5\n",
      "training for epoch  3  with encoder number of  5\n",
      "Epoch [4/8], Step [4375/10000], Train Loss: 0.1251, Valid Loss: 0.5496\n",
      "Epoch [4/8], Step [5000/10000], Train Loss: 0.1675, Valid Loss: 0.4205\n",
      "changing encoder number :  12  =>  11\n",
      "training for epoch  4  with encoder number of  11\n",
      "Epoch [5/8], Step [5625/10000], Train Loss: 0.0530, Valid Loss: 0.5252\n",
      "Epoch [5/8], Step [6250/10000], Train Loss: 0.0789, Valid Loss: 0.5459\n",
      "changing encoder number :  12  =>  12\n",
      "training for epoch  5  with encoder number of  12\n",
      "Epoch [6/8], Step [6875/10000], Train Loss: 0.0368, Valid Loss: 0.6822\n",
      "Epoch [6/8], Step [7500/10000], Train Loss: 0.0478, Valid Loss: 0.8152\n",
      "changing encoder number :  12  =>  11\n",
      "training for epoch  6  with encoder number of  11\n",
      "Epoch [7/8], Step [8125/10000], Train Loss: 0.0270, Valid Loss: 0.6789\n",
      "Epoch [7/8], Step [8750/10000], Train Loss: 0.0295, Valid Loss: 0.7756\n",
      "changing encoder number :  12  =>  7\n",
      "training for epoch  7  with encoder number of  7\n",
      "Epoch [8/8], Step [9375/10000], Train Loss: 0.0442, Valid Loss: 0.6424\n",
      "Epoch [8/8], Step [10000/10000], Train Loss: 0.0378, Valid Loss: 0.6781\n",
      "Accuracy log saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/random_elasticity_acc_log.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../modelrandom_elasticity_metrics.pt\n",
      "Model saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/7metrics.pt\n",
      "Accuracy log saved to ==> /home/ilee300/workspace/nlp_ofa/notebooks/../model/7acc_log.pt\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "# random.randint(5,12)\n",
    "# train using randomly selected layers\n",
    "\n",
    "model = BERT().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "print(\"Training model with random elasticity for 8 epochs.\")\n",
    "train(model=model, optimizer=optimizer, num_epochs = 8, random_elasticity=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43d04126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the model trained with random elasticity\n",
      "initializing bertforsequenceclassification\n",
      "initializing weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/notebooks/../model/random_elasticity_model.pt\n",
      "changing encoder number :  12  =>  5\n",
      "evaluating with max encoder number of  5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6485    0.7359    0.6895     12500\n",
      "           0     0.6948    0.6011    0.6446     12500\n",
      "\n",
      "    accuracy                         0.6685     25000\n",
      "   macro avg     0.6716    0.6685    0.6670     25000\n",
      "weighted avg     0.6716    0.6685    0.6670     25000\n",
      "\n",
      "accuracy when using  5  layers :  0.66852\n",
      "changing encoder number :  12  =>  6\n",
      "evaluating with max encoder number of  6\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8901    0.2979    0.4464     12500\n",
      "           0     0.5784    0.9632    0.7228     12500\n",
      "\n",
      "    accuracy                         0.6306     25000\n",
      "   macro avg     0.7342    0.6306    0.5846     25000\n",
      "weighted avg     0.7342    0.6306    0.5846     25000\n",
      "\n",
      "accuracy when using  6  layers :  0.63056\n",
      "changing encoder number :  12  =>  7\n",
      "evaluating with max encoder number of  7\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8791    0.5532    0.6791     12500\n",
      "           0     0.6740    0.9239    0.7794     12500\n",
      "\n",
      "    accuracy                         0.7386     25000\n",
      "   macro avg     0.7766    0.7386    0.7293     25000\n",
      "weighted avg     0.7766    0.7386    0.7293     25000\n",
      "\n",
      "accuracy when using  7  layers :  0.73856\n",
      "changing encoder number :  12  =>  8\n",
      "evaluating with max encoder number of  8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9192    0.5078    0.6542     12500\n",
      "           0     0.6600    0.9554    0.7807     12500\n",
      "\n",
      "    accuracy                         0.7316     25000\n",
      "   macro avg     0.7896    0.7316    0.7174     25000\n",
      "weighted avg     0.7896    0.7316    0.7174     25000\n",
      "\n",
      "accuracy when using  8  layers :  0.73156\n",
      "changing encoder number :  12  =>  9\n",
      "evaluating with max encoder number of  9\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9120    0.7121    0.7997     12500\n",
      "           0     0.7638    0.9313    0.8393     12500\n",
      "\n",
      "    accuracy                         0.8217     25000\n",
      "   macro avg     0.8379    0.8217    0.8195     25000\n",
      "weighted avg     0.8379    0.8217    0.8195     25000\n",
      "\n",
      "accuracy when using  9  layers :  0.82168\n",
      "changing encoder number :  12  =>  10\n",
      "evaluating with max encoder number of  10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8967    0.8004    0.8458     12500\n",
      "           0     0.8198    0.9078    0.8615     12500\n",
      "\n",
      "    accuracy                         0.8541     25000\n",
      "   macro avg     0.8582    0.8541    0.8537     25000\n",
      "weighted avg     0.8582    0.8541    0.8537     25000\n",
      "\n",
      "accuracy when using  10  layers :  0.85408\n",
      "changing encoder number :  12  =>  11\n",
      "evaluating with max encoder number of  11\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8933    0.8053    0.8470     12500\n",
      "           0     0.8227    0.9038    0.8614     12500\n",
      "\n",
      "    accuracy                         0.8546     25000\n",
      "   macro avg     0.8580    0.8546    0.8542     25000\n",
      "weighted avg     0.8580    0.8546    0.8542     25000\n",
      "\n",
      "accuracy when using  11  layers :  0.85456\n",
      "changing encoder number :  12  =>  12\n",
      "evaluating with max encoder number of  12\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6763    0.9546    0.7917     12500\n",
      "           0     0.9229    0.5430    0.6838     12500\n",
      "\n",
      "    accuracy                         0.7488     25000\n",
      "   macro avg     0.7996    0.7488    0.7377     25000\n",
      "weighted avg     0.7996    0.7488    0.7377     25000\n",
      "\n",
      "accuracy when using  12  layers :  0.74884\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"loading the model trained with random elasticity\")\n",
    "best_model = BERT().to(device)\n",
    "load_checkpoint(destination_folder +'/random_elasticity_model.pt', best_model)\n",
    "random_elasticity_accuracy_list = []\n",
    "for i in range(5,13):\n",
    "    acc = evaluate(best_model, test_iter, max_encoder_num=i)\n",
    "    print(\"accuracy when using \", i, \" layers : \", acc)\n",
    "    random_elasticity_accuracy_list.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a783fe05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.66852, 0.63056, 0.73856, 0.73156, 0.82168, 0.85408, 0.85456, 0.74884]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_elasticity_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "913dc236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== /home/ilee300/workspace/nlp_ofa/notebooks/../modelrandom_elasticity_metrics.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder +'random_elasticity_metrics.pt')\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "plt.xlabel('Global Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607950c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
